{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "776a782a-59c8-4089-93d5-ae416e9fbe31",
   "metadata": {},
   "source": [
    "# mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d6f86a21-f63d-45aa-8224-fc42807e106c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example mapping in Python\n",
    "image_folder = \"RoboMouths_PNGs/\" # Path to your folder\n",
    "\n",
    "rhubarb_phoneme_map = {\n",
    "    'X': image_folder + 'mouth_X.png',\n",
    "    'A': image_folder + 'mouth_B.png',  # Often map 'A' to the open 'B' shape\n",
    "    'B': image_folder + 'mouth_B.png',\n",
    "    'C': image_folder + 'mouth_C.png',\n",
    "    'D': image_folder + 'mouth_E.png',  # Rhubarb 'D' might map to a less open shape\n",
    "    'E': image_folder + 'mouth_E.png',\n",
    "    'F': image_folder + 'mouth_F.png',\n",
    "    'G': image_folder + 'mouth_G.png',\n",
    "    'H': image_folder + 'mouth_H.png',\n",
    "    # Add other Rhubarb codes if your set or needs expand (I, L, N, R, S, Th, U, W, Y, Z)\n",
    "    # and design corresponding simple robotic shapes if necessary, or map them to the closest existing ones.\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5dc1c820-2fd7-4f49-ac47-f497602401e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pydub in c:\\python312\\lib\\site-packages (0.25.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution ~ympy (C:\\Python312\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~ympy (C:\\Python312\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~ympy (C:\\Python312\\Lib\\site-packages)\n",
      "\n",
      "[notice] A new release of pip is available: 25.0.1 -> 25.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install pydub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3c2ae4b-2e83-4f8a-ac86-fe3d37c9007b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "666afbf6-22dc-4fab-bf02-0e2c1ae9e2cd",
   "metadata": {},
   "source": [
    "# AVATAR CODE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9c37a956-bf16-45ea-b9c5-c606ce4b573d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pygame 2.6.1 (SDL 2.28.4, Python 3.12.3)\n",
      "Hello from the pygame community. https://www.pygame.org/contribute.html\n",
      "  🔹 Pygame mixer initialized successfully.\n"
     ]
    },
    {
     "ename": "error",
     "evalue": "font not initialized",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31merror\u001b[0m                                     Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 712\u001b[0m\n\u001b[0;32m    708\u001b[0m BLACK \u001b[38;5;241m=\u001b[39m (\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m    709\u001b[0m \u001b[38;5;66;03m# Load a simple background or head image (optional)\u001b[39;00m\n\u001b[0;32m    710\u001b[0m \u001b[38;5;66;03m# head_image = pygame.image.load(\"robot_head.png\").convert_alpha()\u001b[39;00m\n\u001b[0;32m    711\u001b[0m \u001b[38;5;66;03m# head_rect = head_image.get_rect(center=(SCREEN_WIDTH // 2, SCREEN_HEIGHT // 2 - 50))\u001b[39;00m\n\u001b[1;32m--> 712\u001b[0m font \u001b[38;5;241m=\u001b[39m \u001b[43mpygame\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfont\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mFont\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m24\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m# Font for status messages\u001b[39;00m\n\u001b[0;32m    714\u001b[0m \u001b[38;5;66;03m# --- NEW: Load Mouth Shape Images ---\u001b[39;00m\n\u001b[0;32m    715\u001b[0m MOUTH_POS \u001b[38;5;241m=\u001b[39m (SCREEN_WIDTH \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m \u001b[38;5;241m2\u001b[39m, SCREEN_HEIGHT \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m \u001b[38;5;241m2\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m50\u001b[39m) \u001b[38;5;66;03m# Position for the mouth\u001b[39;00m\n",
      "\u001b[1;31merror\u001b[0m: font not initialized"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import json\n",
    "import faiss\n",
    "import numpy as np\n",
    "import torch\n",
    "import requests\n",
    "import random\n",
    "import yt_dlp\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "\n",
    "# --- NEW IMPORTS for Voice Agent ---\n",
    "import speech_recognition as sr\n",
    "from gtts import gTTS\n",
    "import time # For potential delays or filename uniqueness\n",
    "\n",
    "import pygame # For controllable audio playback\n",
    "import keyboard # For push-to-talk interrupt detection\n",
    "import threading # To run keyboard listener concurrently\n",
    "import queue # For communication between threads\n",
    "import nltk # For sentence splitting\n",
    "import subprocess # <-- NEW: To run Rhubarb\n",
    "from pydub import AudioSegment # <-- NEW: For MP3 to WAV conversion\n",
    "import io # <-- NEW: To handle audio data in memory potentially\n",
    "\n",
    "# -------------------------\n",
    "# General Debugging Utility\n",
    "# -------------------------\n",
    "debug_mode = True  # Enable debugging\n",
    "def debug_print(message, level=1):\n",
    "    if debug_mode:\n",
    "        prefix = \"  \" * level\n",
    "        print(f\"{prefix}🔹 {message}\")\n",
    "\n",
    "# -------------------------------------\n",
    "# --- Existing Code (Keep As Is) ---\n",
    "# Configuration & Data Loading\n",
    "IMAGE_DIR = \"images\"\n",
    "FIGURES_JSON = \"output.json\"\n",
    "\n",
    "# Data for textual content\n",
    "with open(\"knowledgebase.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    kb_data = json.load(f)\n",
    "with open(\"metadata.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    metadata = json.load(f)\n",
    "\n",
    "# Normalize function\n",
    "def normalize_title(title):\n",
    "    return title.strip().lower()\n",
    "\n",
    "# Create normalized KB lookup\n",
    "normalized_kb = {}\n",
    "for chapter, topics in kb_data.items():\n",
    "    for title, content in topics.items():\n",
    "        norm_key = (chapter, normalize_title(title))\n",
    "        normalized_kb[norm_key] = content\n",
    "\n",
    "# Initialize embedding model\n",
    "model = SentenceTransformer(\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "# Load FAISS index (text)\n",
    "index = faiss.read_index(\"textbook_faiss.index\") # Assuming your text index is named \"textbook_faiss.index\"\n",
    "\n",
    "# search function\n",
    "def search(query, top_k=5, similarity_threshold=0.98, mode=\"hybrid\"):\n",
    "    norm_query = normalize_title(query)\n",
    "    results = []\n",
    "    seen_embeddings = []\n",
    "    seen_titles = set()\n",
    "\n",
    "    def get_exact_matches():\n",
    "        for item in metadata:\n",
    "            title = item[\"title\"]\n",
    "            chapter = item[\"chapter\"]\n",
    "            norm_title = normalize_title(title)\n",
    "            if norm_query in norm_title:\n",
    "                norm_key = (chapter, norm_title)\n",
    "                content = normalized_kb.get(norm_key)\n",
    "                if content:\n",
    "                    seen_titles.add(norm_key)\n",
    "                    return [{\n",
    "                        \"title_key\": title,\n",
    "                        \"chapter\": chapter,\n",
    "                        \"score\": 0.0,\n",
    "                        \"content\": content\n",
    "                    }]\n",
    "        return []\n",
    "\n",
    "    def get_semantic_matches():\n",
    "        query_embedding = model.encode([query], convert_to_numpy=True)\n",
    "        distances, indices = index.search(query_embedding, top_k)\n",
    "        semantic_results = []\n",
    "\n",
    "        for i in range(len(indices[0])):\n",
    "            idx = indices[0][i]\n",
    "            raw_title = metadata[idx][\"title\"]\n",
    "            chapter = metadata[idx][\"chapter\"]\n",
    "            norm_key = (chapter, normalize_title(raw_title))\n",
    "            content = normalized_kb.get(norm_key)\n",
    "\n",
    "            if content and norm_key not in seen_titles:\n",
    "                content_embedding = model.encode(content, convert_to_tensor=True)\n",
    "\n",
    "                # Check for semantic duplication\n",
    "                is_duplicate = False\n",
    "                for prev_emb in seen_embeddings:\n",
    "                    if util.cos_sim(content_embedding, prev_emb).item() >= similarity_threshold:\n",
    "                        is_duplicate = True\n",
    "                        break\n",
    "\n",
    "                if not is_duplicate:\n",
    "                    seen_embeddings.append(content_embedding)\n",
    "                    seen_titles.add(norm_key)\n",
    "                    semantic_results.append({\n",
    "                        \"title_key\": raw_title,\n",
    "                        \"chapter\": chapter,\n",
    "                        \"score\": distances[0][i],\n",
    "                        \"content\": content\n",
    "                    })\n",
    "        return semantic_results\n",
    "\n",
    "    # MODE HANDLING\n",
    "    if mode == \"exact\":\n",
    "        results = get_exact_matches()\n",
    "    elif mode == \"semantic\":\n",
    "        results = get_semantic_matches()\n",
    "    else:  # hybrid\n",
    "        results = get_exact_matches()\n",
    "        if not results:\n",
    "            results = get_semantic_matches()\n",
    "\n",
    "    return results\n",
    "\n",
    "# Function to generate a brief, general explanation (no KB search)\n",
    "def generate_general_explanation(topic):\n",
    "    \"\"\"Generates a brief, general explanation for a topic using the LLM (no KB search).\"\"\"\n",
    "    debug_print(f\"Generating general explanation for: {topic}\", 2)\n",
    "    prompt = f\"\"\"\n",
    "You are an AI science teacher providing a brief overview of a topic that is outside the current syllabus.\n",
    "Provide a clear, concise explanation of \"{topic}\" suitable for an 8th grader.\n",
    "Keep it brief, ideally 3-5 sentences.\n",
    "DO NOT mention specific textbook chapters, sections, or figures.\n",
    "DO NOT ask questions back.\n",
    "Output plain text only.\n",
    "\n",
    "Your General Explanation:\n",
    "\"\"\"\n",
    "    try:\n",
    "        response = requests.post(\n",
    "            LLM_API_URL,\n",
    "            headers={\"Authorization\": f\"Bearer {LLM_API_KEY}\"},\n",
    "            json={\n",
    "                \"model\": \"llama3-70b-8192\",\n",
    "                \"messages\": [{\"role\": \"user\", \"content\": prompt}],\n",
    "                \"max_tokens\": 200, # Limit tokens for brevity\n",
    "                \"temperature\": 0.7\n",
    "            }\n",
    "        )\n",
    "        response.raise_for_status()\n",
    "        result = response.json()\n",
    "        if \"choices\" in result and result[\"choices\"]:\n",
    "            explanation_text = result[\"choices\"][0][\"message\"][\"content\"].strip()\n",
    "            debug_print(\"LLM generated general explanation.\", 3)\n",
    "            return explanation_text\n",
    "        else:\n",
    "            debug_print(f\"LLM response format issue for general explanation: {result}\", 3)\n",
    "            return f\"I can't give a detailed explanation of {topic} right now.\"\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"❌ Error calling LLM for general explanation: {e}\")\n",
    "        return \"Sorry, I encountered an error while trying to explain.\"\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Unexpected error during general explanation generation: {e}\")\n",
    "        return \"An unexpected error occurred.\"\n",
    "# Check if topic is \"in syllabus\" (based on search results)\n",
    "# Check if topic is \"in syllabus\" (based on search results and relevance threshold)\n",
    "def is_in_syllabus(query):\n",
    "    \"\"\"Checks if the query yields sufficiently relevant results from the knowledge base.\"\"\"\n",
    "    debug_print(f\"Checking if '{query}' is in syllabus (with threshold)...\", 2)\n",
    "\n",
    "    # You will need to tune this threshold value based on your data.\n",
    "    # A lower distance_threshold means the match must be more similar (closer).\n",
    "    # Start with a value and adjust after testing.\n",
    "    distance_threshold = 0.8 # Example distance threshold - lower is better. Needs tuning.\n",
    "\n",
    "    # Call the search function to get the best match and its score (distance)\n",
    "    search_results = search(query, mode=\"hybrid\", top_k=1)\n",
    "\n",
    "    if search_results: # Check if search returned any result\n",
    "        best_match = search_results[0]\n",
    "        best_score = best_match[\"score\"] # This is the distance\n",
    "\n",
    "        debug_print(f\"Best match score (distance): {best_score} (Threshold is {distance_threshold})\", 2)\n",
    "\n",
    "        # Check if the distance is below the threshold\n",
    "        if best_score < distance_threshold:\n",
    "            debug_print(\"Found sufficiently relevant syllabus content.\", 2)\n",
    "            return True, best_match[\"content\"] # Return True and the content\n",
    "        else:\n",
    "            debug_print(\"Closest match score is above the distance threshold. Not considered in syllabus.\", 2)\n",
    "            return False, None\n",
    "    else:\n",
    "        debug_print(\"No results found by search function.\", 2) # Should rarely happen with top_k=1 unless index is empty\n",
    "        return False, None\n",
    "\n",
    "# Groq LLM API configuration\n",
    "LLM_API_KEY = \"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\"\n",
    "LLM_API_URL = \"https://api.groq.com/openai/v1/chat/completions\"\n",
    "\n",
    "# Load figures data\n",
    "def load_figures():\n",
    "    with open(FIGURES_JSON, \"r\", encoding=\"utf-8\") as f:\n",
    "        return json.load(f)\n",
    "\n",
    "figures_data = load_figures()\n",
    "\n",
    "# Initialize image model & FAISS (figures)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "image_model = SentenceTransformer(\"sentence-transformers/all-MiniLM-L6-v2\").to(device)\n",
    "\n",
    "FAISS_INDEX_FILE = \"subchapter_faiss.index\"\n",
    "METADATA_FILE = \"subchapter_metadata.json\"\n",
    "\n",
    "# Load figure metadata\n",
    "index_figures = faiss.read_index(FAISS_INDEX_FILE)\n",
    "\n",
    "# Load metadata mapping (Index → Subchapter)\n",
    "with open(METADATA_FILE, \"r\", encoding=\"utf-8\") as f:\n",
    "    metadata_figures = json.load(f)\n",
    "\n",
    "# search_exact_subchapter function\n",
    "def search_exact_subchapter(query, top_k=1):\n",
    "    \"\"\"Find the most relevant subchapter using FAISS.\"\"\"\n",
    "    debug_print(f\"Searching for exact subchapter match: {query}\")\n",
    "    query_embedding = image_model.encode([query], convert_to_numpy=True).astype('float32')\n",
    "    _, indices = index_figures.search(query_embedding.reshape(1, -1), top_k)\n",
    "    # Pick only the closest match\n",
    "    best_match_index = str(indices[0][0])\n",
    "    best_subchapter = metadata_figures.get(best_match_index, None)\n",
    "    debug_print(f\"Best match subchapter: {best_subchapter}\", 2)\n",
    "    return best_subchapter\n",
    "\n",
    "# get_image_path function\n",
    "def get_image_path(figure_ref):\n",
    "    \"\"\"Find image path with multiple fallback patterns.\"\"\"\n",
    "    debug_print(f\"Locating image for: {figure_ref}\", 2)\n",
    "    base_name = figure_ref.replace(\" \", \"_\")\n",
    "    attempts = [\n",
    "        f\"{base_name}.png\",\n",
    "        f\"{base_name}.jpg\",\n",
    "        f\"figure_{base_name}.png\"\n",
    "    ]\n",
    "    for attempt in attempts:\n",
    "        test_path = os.path.join(IMAGE_DIR, attempt)\n",
    "        if os.path.exists(test_path):\n",
    "            debug_print(f\"✅ Found image at: {test_path}\", 3)\n",
    "            return test_path\n",
    "    debug_print(\"❌ No valid image path found\", 3)\n",
    "    return None\n",
    "\n",
    "# fetch_figures_only function (maybe less relevant now, but keep)\n",
    "def fetch_figures_only(subchapter_name): # Changed parameter name to be more explicit\n",
    "    \"\"\"Retrieve only figures (images + raw descriptions) for a given subchapter.\"\"\"\n",
    "    debug_print(f\"Retrieving figures for subchapter: {subchapter_name}\")\n",
    "    figures = [fig for fig in figures_data if fig[\"subchapter\"] == subchapter_name]\n",
    "    if not figures:\n",
    "        debug_print(f\"No relevant figures found for subchapter: {subchapter_name}\")\n",
    "        return \"No relevant figures found.\"\n",
    "    figure_blocks = []\n",
    "    for fig in figures:\n",
    "        fig_path = get_image_path(fig['figure'])\n",
    "        if fig_path:\n",
    "            figure_blocks.append({\n",
    "                \"name\": fig['figure'],\n",
    "                \"path\": fig_path,\n",
    "                \"desc\": fig['description']\n",
    "            })\n",
    "    return figure_blocks\n",
    "\n",
    "# retrieve_and_expand_figures function (generates HTML, less relevant for voice)\n",
    "def retrieve_and_expand_figures(query):\n",
    "    \"\"\"\n",
    "    Retrieve figures related to the query by using the title of the\n",
    "    most relevant text content and generate HTML to display them.\n",
    "    \"\"\"\n",
    "    search_results = search(query, mode=\"hybrid\", top_k=1)\n",
    "    if not search_results:\n",
    "        return \"<p>No relevant text found for image retrieval.</p>\"\n",
    "\n",
    "    best_text_match = search_results[0]\n",
    "    subchapter_name = best_text_match[\"title_key\"] # Use the title_key as the subchapter name\n",
    "\n",
    "    blocks = fetch_figures_only(subchapter_name)\n",
    "    if isinstance(blocks, str):\n",
    "        # An error message was returned\n",
    "        return f\"<p>{blocks}</p>\"\n",
    "\n",
    "    figure_html = \"<div style='margin-top: 20px;'><h3>📊 Visual Aids</h3>\"\n",
    "    # Limit to 3 figures\n",
    "    for fig in blocks[:3]:\n",
    "        clean_desc = fig['desc']  # Optionally, you can process the description further\n",
    "        figure_html += f\"\"\"\n",
    "        <div style='margin-bottom: 20px; border: 1px solid #ddd; padding: 10px; border-radius: 5px;'>\n",
    "            <img src='{fig['path']}' style='max-width: 100%; height: auto; display: block; margin: 0 auto;'>\n",
    "            <p style='text-align: center; font-style: italic;'>{clean_desc or 'Visual demonstration'}</p>\n",
    "        </div>\n",
    "        \"\"\"\n",
    "    figure_html += \"</div>\"\n",
    "    return figure_html\n",
    "\n",
    "# fetch_animated_videos function (keep for potential future use)\n",
    "def fetch_animated_videos(topic, num_videos=1):\n",
    "    search_query = f\"ytsearch{num_videos}:{topic} animation explained in english\"\n",
    "    print(f\"Searching for: {search_query}\")\n",
    "\n",
    "    ydl_opts = {\n",
    "        \"quiet\": True,\n",
    "        \"extract_flat\": True,\n",
    "        \"force_generic_extractor\": True\n",
    "    }\n",
    "\n",
    "    with yt_dlp.YoutubeDL(ydl_opts) as ydl:\n",
    "        info = ydl.extract_info(search_query, download=False)\n",
    "\n",
    "        if \"entries\" in info and len(info[\"entries\"]) > 0:\n",
    "            video = info[\"entries\"][0]\n",
    "            print(f\"Found video: {video['title']}\")\n",
    "            if video.get(\"duration\", 301) <= 300:\n",
    "                return {\n",
    "                    \"title\": video[\"title\"],\n",
    "                    \"url\": video[\"url\"],\n",
    "                    \"id\": video[\"id\"]\n",
    "                }\n",
    "    return None\n",
    "\n",
    "# generate_topic_hook function\n",
    "def generate_topic_hook(topic):\n",
    "    \"\"\"Generate a short, engaging hook for the topic using the LLM.\"\"\"\n",
    "    prompt = f\"\"\"\n",
    "You are a science educator. Create a SHORT (1-2 sentences), engaging hook for the topic *{topic}* for 8th-grade students using one of these techniques:\n",
    "- A surprising fact/question\n",
    "- A relatable analogy/metaphor\n",
    "- A real-world application\n",
    "- A mini thought experiment\n",
    "\n",
    "Return ONLY the hook.\n",
    "\"\"\"\n",
    "    response = requests.post(\n",
    "        LLM_API_URL,\n",
    "        headers={\"Authorization\": f\"Bearer {LLM_API_KEY}\"},\n",
    "        json={\n",
    "            \"model\": \"llama3-70b-8192\",\n",
    "            \"messages\": [{\"role\": \"user\", \"content\": prompt}],\n",
    "            \"max_tokens\": 1000,\n",
    "            \"temperature\": 0.9\n",
    "        }\n",
    "    )\n",
    "    hook = response.json()[\"choices\"][0][\"message\"][\"content\"].strip()\n",
    "    return hook\n",
    "\n",
    "# generate_funny_intro function\n",
    "def generate_funny_intro(topic):\n",
    "    \"\"\"Generate an introduction that begins with a funny story or meme about the topic.\"\"\"\n",
    "    prompt = f\"\"\"\n",
    "You are a creative and humorous science educator. Tell a short, funny story or describe a relatable meme about *{topic}* to engage 8th-grade students. Avoid using video introductions. Return ONLY the story.\n",
    "\"\"\"\n",
    "    response = requests.post(\n",
    "        LLM_API_URL,\n",
    "        headers={\"Authorization\": f\"Bearer {LLM_API_KEY}\"},\n",
    "        json={\n",
    "            \"model\": \"llama3-70b-8192\",\n",
    "            \"messages\": [{\"role\": \"user\", \"content\": prompt}],\n",
    "            \"max_tokens\": 1000,\n",
    "            \"temperature\": 0.9\n",
    "        }\n",
    "    )\n",
    "    funny_intro = response.json()[\"choices\"][0][\"message\"][\"content\"].strip()\n",
    "    return funny_intro\n",
    "\n",
    "# generate_dynamic_intro function (generates HTML, less relevant for voice)\n",
    "def generate_dynamic_intro(topic):\n",
    "    \"\"\"Generate an introductory paragraph with a funny story or meme.\"\"\"\n",
    "    funny_intro = generate_funny_intro(topic)\n",
    "    hook = generate_topic_hook(topic)\n",
    "    return f\"\"\"\n",
    "<p>{funny_intro}</p>\n",
    "<p>{hook}</p>\n",
    "<p>Today, we're exploring the fascinating world of <strong>{topic}</strong>! 🔍<br>\n",
    "Quick prediction: What do you think happens when...? Let's find out in our lesson!</p>\n",
    "\"\"\"\n",
    "\n",
    "# -------------------------------------\n",
    "\n",
    "# === NEW VOICE AGENT CORE FUNCTIONS ===\n",
    "\n",
    "# 1. Text-to-Speech (TTS) Function\n",
    "TTS_TEMP_FILE = \"temp_ai_speech.mp3\" # Keep a single temp file name\n",
    "\n",
    "# 2. Speech-to-Text (ASR) Function\n",
    "def listen_to_student(timeout_seconds=10, phrase_time_limit_seconds=5):\n",
    "    \"\"\"Listens for student's speech using the microphone.\"\"\"\n",
    "    r = sr.Recognizer()\n",
    "    with sr.Microphone() as source:\n",
    "        # Adjust for ambient noise once at the start potentially\n",
    "        # r.adjust_for_ambient_noise(source, duration=1)\n",
    "        debug_print(\"Listening for student...\")\n",
    "        print(\"🎤 (Speak now)\") # User feedback\n",
    "        try:\n",
    "            # Listen with timeout and phrase time limit\n",
    "            audio = r.listen(source, timeout=timeout_seconds, phrase_time_limit=phrase_time_limit_seconds)\n",
    "            debug_print(\"Processing speech...\")\n",
    "            # Recognize speech using Google Web Speech API\n",
    "            text = r.recognize_google(audio)\n",
    "            debug_print(f\"Student said: {text}\", 2)\n",
    "            print(f\"👂 You said: {text}\") # User feedback\n",
    "            return text.lower() # Return lowercase for easier processing\n",
    "        except sr.WaitTimeoutError:\n",
    "            debug_print(\"No speech detected within timeout.\", 2)\n",
    "            print(\"묵 No speech detected.\")\n",
    "            return None\n",
    "        except sr.UnknownValueError:\n",
    "            debug_print(\"Google Speech Recognition could not understand audio.\", 2)\n",
    "            print(\"❓ Sorry, I couldn't understand that.\")\n",
    "            return None\n",
    "        except sr.RequestError as e:\n",
    "            debug_print(f\"Could not request results from Google Speech Recognition service; {e}\", 2)\n",
    "            print(f\"🚫 Could not connect to speech service: {e}\")\n",
    "            return None\n",
    "        except Exception as e:\n",
    "            print(f\"❌ An unexpected error occurred during listening: {e}\")\n",
    "            return None\n",
    "\n",
    "# 3. Natural Language Understanding (NLU) Function (using LLM)\n",
    "def understand_intent_and_topic(text):\n",
    "    \"\"\"Uses the LLM to determine intent and extract the topic from student input.\"\"\"\n",
    "    if not text:\n",
    "        return None, None\n",
    "\n",
    "    prompt = f\"\"\"\n",
    "Analyze the following student input to identify the primary intent and the specific topic or question.\n",
    "Input: \"{text}\"\n",
    "\n",
    "Possible Intents:\n",
    "- REQUEST_EXPLANATION (e.g., \"tell me about X\", \"explain Y\")\n",
    "- ASK_QUESTION (e.g., \"what is X?\", \"how does Y work?\", \"why is Z like that?\")\n",
    "- GREETING (e.g., \"hello\", \"hi\")\n",
    "- FAREWELL (e.g., \"goodbye\", \"bye\")\n",
    "- RESUME (e.g., \"resume\", \"continue\", \"go on\") # Explicitly add RESUME intent\n",
    "- OTHER (If none of the above fit)\n",
    "\n",
    "Identify the main intent and extract the core topic or question discussed.\n",
    "\n",
    "Return the result ONLY as a JSON object with keys \"intent\" and \"topic_or_question\".\n",
    "If no specific topic is mentioned for explanation or question, set \"topic_or_question\" to null or an empty string.\n",
    "If the intent is RESUME, set \"topic_or_question\" to null or an empty string.\n",
    "\n",
    "Example 1:\n",
    "Input: \"Explain magnetic fields\"\n",
    "Output: {{\"intent\": \"REQUEST_EXPLANATION\", \"topic_or_question\": \"magnetic fields\"}}\n",
    "\n",
    "Example 2:\n",
    "Input: \"hi there\"\n",
    "Output: {{\"intent\": \"GREETING\", \"topic_or_question\": null}}\n",
    "\n",
    "Example 3:\n",
    "Input: \"why is the sky blue?\"\n",
    "Output: {{\"intent\": \"ASK_QUESTION\", \"topic_or_question\": \"why is the sky blue?\"}}\n",
    "\n",
    "Example 4:\n",
    "Input: \"tell me more\"\n",
    "Output: {{\"intent\": \"REQUEST_EXPLANATION\", \"topic_or_question\": \"\"}} # Or maybe requires context\n",
    "\n",
    "Example 5:\n",
    "Input: \"resume\"\n",
    "Output: {{\"intent\": \"RESUME\", \"topic_or_question\": null}}\n",
    "\n",
    "\n",
    "Input to analyze: \"{text}\"\n",
    "Output:\n",
    "\"\"\"\n",
    "    debug_print(\"Sending NLU request to LLM...\", 2)\n",
    "    try:\n",
    "        response = requests.post(\n",
    "            LLM_API_URL,\n",
    "            headers={\"Authorization\": f\"Bearer {LLM_API_KEY}\"},\n",
    "            json={\n",
    "                \"model\": \"llama3-70b-8192\", # Or your preferred model\n",
    "                \"messages\": [{\"role\": \"user\", \"content\": prompt}],\n",
    "                \"max_tokens\": 100,\n",
    "                \"temperature\": 0.1, # Low temp for deterministic classification\n",
    "                \"response_format\": {\"type\": \"json_object\"} # Request JSON output if API supports\n",
    "            }\n",
    "        )\n",
    "        response.raise_for_status() # Raise HTTPError for bad responses (4xx or 5xx)\n",
    "        result = response.json()\n",
    "\n",
    "        # Extract JSON content - handle potential variations in LLM output\n",
    "        json_string = result[\"choices\"][0][\"message\"][\"content\"].strip()\n",
    "        # Sometimes LLMs wrap JSON in backticks or ```json ... ```\n",
    "        json_string = re.sub(r\"^```json\\s*\", \"\", json_string)\n",
    "        json_string = re.sub(r\"\\s*```$\", \"\", json_string)\n",
    "\n",
    "        debug_print(f\"NLU Raw Response: {json_string}\", 3)\n",
    "\n",
    "        parsed_result = json.loads(json_string)\n",
    "        intent = parsed_result.get(\"intent\")\n",
    "        topic = parsed_result.get(\"topic_or_question\")\n",
    "        debug_print(f\"NLU Parsed: Intent={intent}, Topic={topic}\", 2)\n",
    "        return intent, topic\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"❌ Error calling LLM for NLU: {e}\")\n",
    "        return \"ERROR\", None\n",
    "    except json.JSONDecodeError as e:\n",
    "        print(f\"❌ Error decoding NLU JSON response: {e}\")\n",
    "        print(f\"Raw response was: {json_string}\") # Log the problematic response\n",
    "        return \"ERROR\", None\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Unexpected error during NLU: {e}\")\n",
    "        return \"ERROR\", None\n",
    "\n",
    "\n",
    "# 4. Function to Generate Spoken Explanation (Adapting existing logic)\n",
    "# Function to generate the full, rich lesson text for voice (from previous turn)\n",
    "def generate_full_lesson_text(topic_query):\n",
    "    \"\"\"\n",
    "    Retrieves relevant content, generates intro/hook, and uses LLM to create a\n",
    "    rich, expanded explanation based on textbook content for voice output.\n",
    "    \"\"\"\n",
    "    debug_print(f\"Generating full lesson text for: {topic_query}\")\n",
    "    # 1. Retrieve relevant textbook content\n",
    "    search_results = search(topic_query, mode=\"hybrid\", top_k=1) # Get best match\n",
    "    if not search_results:\n",
    "        debug_print(\"No relevant text found via search for lesson.\", 2)\n",
    "        return \"Sorry, I couldn't find detailed information on that specific topic in my knowledge base.\"\n",
    "\n",
    "    best_match = search_results[0]\n",
    "    retrieved_content = best_match[\"content\"]\n",
    "    cleaned_title = re.sub(r\"^\\d+(\\.\\d+)\\s\", \"\", best_match[\"title_key\"]).strip()\n",
    "    debug_print(f\"Retrieved content for lesson '{cleaned_title}'\", 2)\n",
    "\n",
    "    # 2. Generate Intro and Hook (re-using existing functions)\n",
    "    funny_intro = generate_funny_intro(cleaned_title)\n",
    "    hook = generate_topic_hook(cleaned_title)\n",
    "\n",
    "    # 3. Combine Intro, Hook, and Textbook Content for LLM Prompt\n",
    "    # Create a prompt that guides the LLM to act as a teacher and expand\n",
    "    prompt_text = f\"\"\"\n",
    "You are an engaging, fun-loving, and knowledgeable 8th-grade science teacher speaking directly to a student.\n",
    "\n",
    "Start with an engaging introduction similar to this (do not include explicit labels like 'Funny Story' or 'Hook'):\n",
    "\"{funny_intro}\"\n",
    "\"{hook}\"\n",
    "\"Today, we're exploring the fascinating world of {cleaned_title}!\"\n",
    "\n",
    "Then, based only on the following textbook content, provide a detailed, smooth, and engaging explanation for voice:\n",
    "- Expand each idea from the textbook content with real-life analogies, fun facts, surprising trivia, and interesting stories kids can relate to.\n",
    "- Break down complex terms into simple, visual language.\n",
    "- Ensure smooth transitions between different points.\n",
    "- DO NOT include HTML tags. Output plain text only.\n",
    "- DO NOT include explicit section headers like \"Introduction\", \"Explanation\", etc. just make it flow naturally.\n",
    "- DO NOT include greetings or sign-offs at the very beginning or end of the overall response.\n",
    "\n",
    "Textbook Content:\n",
    "\"{retrieved_content}\"\n",
    "\n",
    "Your Spoken Explanation:\n",
    "\"\"\"\n",
    "    debug_print(\"Sending LLM request for full lesson explanation...\", 2)\n",
    "    try:\n",
    "        response = requests.post(\n",
    "            LLM_API_URL,\n",
    "            headers={\"Authorization\": f\"Bearer {LLM_API_KEY}\"},\n",
    "            json={\n",
    "                \"model\": \"llama3-70b-8192\", # Use a capable model\n",
    "                \"messages\": [{\"role\": \"user\", \"content\": prompt_text}],\n",
    "                \"max_tokens\": 1500, # Allow for a longer explanation\n",
    "                \"temperature\": 0.8 # Use a higher temp for more creativity/engagement\n",
    "            }\n",
    "        )\n",
    "        response.raise_for_status()\n",
    "        result = response.json()\n",
    "        if \"choices\" in result and result[\"choices\"]:\n",
    "            explanation_text = result[\"choices\"][0][\"message\"][\"content\"].strip()\n",
    "            debug_print(\"LLM generated full lesson text.\", 3)\n",
    "            return explanation_text\n",
    "        else:\n",
    "            debug_print(f\"LLM response format issue for lesson: {result}\", 3)\n",
    "            return f\"I found information on {cleaned_title}, but had trouble creating a detailed lesson right now.\"\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"❌ Error calling LLM for lesson generation: {e}\")\n",
    "        return \"Sorry, I encountered an error while preparing the lesson explanation.\"\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Unexpected error during lesson generation: {e}\")\n",
    "        return \"An unexpected error occurred while creating the lesson.\"\n",
    "\n",
    "\n",
    "# 5. Function to Generate Spoken Answer (NEW for QA)\n",
    "# Function to Generate Spoken Answer (CORRECTED and MODIFIED for Conciseness)\n",
    "# The syllabus check logic is moved before calling this function in the main loop.\n",
    "def generate_spoken_answer(question, context_content=None):\n",
    "    \"\"\"\n",
    "    Generates a concise spoken answer (ideally 2-4 sentences) to a student's question\n",
    "    using the LLM, optionally using retrieved context.\n",
    "    \"\"\"\n",
    "    debug_print(f\"Generating concise spoken answer for question: {question}\", 2) # Add level 2 for function start\n",
    "\n",
    "    prompt = f\"\"\"\n",
    "You are an AI science teacher answering a student's question. Provide a clear, concise answer suitable for an 8th grader.\n",
    "The answer MUST be brief, ideally *2 to 4 sentences long*.\n",
    "\n",
    "Student's Question: \"{question}\"\n",
    "\n",
    "Context from knowledge base (if available and deemed relevant by search):\n",
    "\"{context_content if context_content else 'No specific syllabus context found for this question. Answer from general knowledge.'}\"\n",
    "\n",
    "Your Concise Spoken Answer (2-4 sentences):\n",
    "\"\"\"\n",
    "    debug_print(\"Sending LLM request for concise answer...\", 2)\n",
    "    try:\n",
    "        response = requests.post(\n",
    "            LLM_API_URL,\n",
    "            headers={\"Authorization\": f\"Bearer {LLM_API_KEY}\"},\n",
    "            json={\n",
    "                \"model\": \"llama3-70b-8192\",\n",
    "                \"messages\": [{\"role\": \"user\", \"content\": prompt}],\n",
    "                \"max_tokens\": 150, # Limit tokens to encourage brevity (adjust if needed)\n",
    "                \"temperature\": 0.6 # Keep it factual\n",
    "            }\n",
    "        )\n",
    "        response.raise_for_status()\n",
    "        result = response.json()\n",
    "        if \"choices\" in result and result[\"choices\"]:\n",
    "            answer_text = result[\"choices\"][0][\"message\"][\"content\"].strip()\n",
    "            # Simple check to try and enforce sentence count (LLM might ignore) - This is a fallback\n",
    "            sentences = re.split(r'(?<=[.!?])\\s+', answer_text) # Split after punctuation and space\n",
    "            if len(sentences) > 4:\n",
    "                answer_text = \". \".join(sentences[:4]).strip() + (\"...\" if len(sentences) > 4 else \"\") # Join first 4 and add ellipsis if more existed\n",
    "\n",
    "            # This is the line where an indentation error was previously seen in your screenshot.\n",
    "            # Ensure its indentation matches the 'if' block above it.\n",
    "            debug_print(f\"LLM generated spoken answer ({len(re.split(r'(?<=[.!?])\\s+', answer_text))} sentences approx).\", 3)\n",
    "\n",
    "            return answer_text\n",
    "        else:\n",
    "            debug_print(f\"LLM response format issue for answer: {result}\", 3)\n",
    "            return \"I'm having a bit of trouble formulating an answer right now.\"\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"❌ Error calling LLM for answer generation: {e}\")\n",
    "        return \"Sorry, I encountered an error while trying to answer.\"\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Unexpected error during answer generation: {e}\")\n",
    "        return \"An unexpected error occurred while answering.\"\n",
    "\n",
    "\n",
    "# === MODIFIED MAIN EXECUTION FLOW ===\n",
    "\n",
    "# (Remove or comment out the old HTML generation and display)\n",
    "# def generate_text_lesson(query): ... # Keep the function, but we won't call it directly for voice yet\n",
    "# def generate_ai_teacher_lesson(query): ... # Keep, but don't call\n",
    "# final_lesson = generate_ai_teacher_lesson(\"MAGNETIC FIELD AND FIELD LINES\") # Comment out\n",
    "\n",
    "\n",
    "# === PHASE 2: STATE MANAGEMENT & AUDIO CONTROL ===\n",
    "\n",
    "# -- State Definitions --\n",
    "STATE_IDLE = \"IDLE\"\n",
    "STATE_SPEAKING_EXPLANATION = \"SPEAKING_EXPLANATION\" # More specific\n",
    "STATE_SPEAKING_ANSWER = \"SPEAKING_ANSWER\"           # More specific\n",
    "STATE_SPEAKING_GREETING = \"SPEAKING_GREETING\"       # More specific\n",
    "STATE_SPEAKING_TRANSITION = \"SPEAKING_TRANSITION\" # More specific\n",
    "STATE_LISTENING = \"LISTENING\"\n",
    "STATE_PROCESSING = \"PROCESSING\"\n",
    "STATE_HANDLING_INTERRUPTION = \"HANDLING_INTERRUPTION\"\n",
    "STATE_CHECK_RESUME = \"CHECK_RESUME\" # New state to check if resume is needed\n",
    "\n",
    "# -- Global State Variables --\n",
    "current_state = STATE_IDLE\n",
    "interrupt_flag = threading.Event()\n",
    "audio_thread = None # Not strictly needed with current pygame approach, but could be useful later\n",
    "interrupt_queue = queue.Queue()\n",
    "\n",
    "# --- Variables for Storing Interruption Context ---\n",
    "interrupted_context = {\n",
    "    \"type\": None, # 'explanation', 'answer', etc.\n",
    "    \"topic\": None,\n",
    "    \"full_text\": None,\n",
    "    \"sentences\": [],\n",
    "    \"resume_index\": 0,\n",
    "    \"saved\": False # Flag to indicate if context is actively saved for resume\n",
    "}\n",
    "\n",
    "# -- Pygame Mixer Initialization (Keep as is) --\n",
    "try:\n",
    "    pygame.mixer.init()\n",
    "    debug_print(\"Pygame mixer initialized successfully.\")\n",
    "except pygame.error as e:\n",
    "    # ... (keep existing error handling) ...\n",
    "    print(f\"❌ Critical Error: Failed to initialize pygame mixer: {e}\")\n",
    "    exit()\n",
    "\n",
    "# --- NEW: Pygame Display Setup ---\n",
    "SCREEN_WIDTH = 600\n",
    "SCREEN_HEIGHT = 400\n",
    "screen = pygame.display.set_mode((SCREEN_WIDTH, SCREEN_HEIGHT))\n",
    "pygame.display.set_caption(\"AI Teacher Voice Agent\")\n",
    "WHITE = (255, 255, 255)\n",
    "BLACK = (0, 0, 0)\n",
    "# Load a simple background or head image (optional)\n",
    "# head_image = pygame.image.load(\"robot_head.png\").convert_alpha()\n",
    "# head_rect = head_image.get_rect(center=(SCREEN_WIDTH // 2, SCREEN_HEIGHT // 2 - 50))\n",
    "font = pygame.font.Font(None, 24) # Font for status messages\n",
    "\n",
    "# --- NEW: Load Mouth Shape Images ---\n",
    "MOUTH_POS = (SCREEN_WIDTH // 2, SCREEN_HEIGHT // 2 + 50) # Position for the mouth\n",
    "mouth_images = {}\n",
    "# Map Rhubarb codes to your image files (adjust filenames as needed)\n",
    "# Using a simplified mapping here\n",
    "rhubarb_map = {\n",
    "    \"A\": \"B\", # Idle -> Open\n",
    "    \"B\": \"B\", # Open\n",
    "    \"C\": \"C\", # Wide\n",
    "    \"D\": \"B\", # Open variation -> Open\n",
    "    \"E\": \"E\", # Mid Open\n",
    "    \"F\": \"F\", # Teeth-Lip\n",
    "    \"G\": \"G\", # Puckered\n",
    "    \"H\": \"H\", # Lips together\n",
    "    \"X\": \"X\"  # Rest/Closed\n",
    "}\n",
    "missing_mouth_image = None\n",
    "try:\n",
    "    # Load images based on the *mapped* codes we'll use\n",
    "    mouth_shapes_to_load = set(rhubarb_map.values())\n",
    "    for shape_code in mouth_shapes_to_load:\n",
    "         filename = f\"mouth_{shape_code}.png\" # Assumes files like mouth_B.png, etc.\n",
    "         try:\n",
    "             img = pygame.image.load(filename).convert_alpha()\n",
    "             # Optional: Scale images if needed\n",
    "             # img = pygame.transform.scale(img, (100, 50)) # Example scale\n",
    "             mouth_images[shape_code] = img\n",
    "             debug_print(f\"Loaded mouth image: {filename}\", 2)\n",
    "         except pygame.error as e:\n",
    "              print(f\"⚠️ Warning: Could not load mouth image {filename}: {e}\")\n",
    "              if shape_code == \"X\": # Crucial fallback for Rest\n",
    "                  missing_mouth_image = pygame.Surface((80, 30)) # Create blank surface\n",
    "                  missing_mouth_image.fill(BLACK)\n",
    "                  mouth_images[\"X\"] = missing_mouth_image\n",
    "                  print(\"    Using fallback black rectangle for Rest/X shape.\")\n",
    "    # Ensure 'X' (Rest) exists, even if using fallback\n",
    "    if \"X\" not in mouth_images:\n",
    "         print(\"⚠️ Error: Rest mouth shape 'mouth_X.png' not found and no fallback created!\")\n",
    "         # Assign a default if possible or handle error\n",
    "         if \"B\" in mouth_images: mouth_images[\"X\"] = mouth_images[\"B\"] # Fallback badly\n",
    "         else: mouth_images[\"X\"] = pygame.Surface((80, 30)); mouth_images[\"X\"].fill(BLACK)\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"❌ Error loading mouth images: {e}\")\n",
    "# Store the current mouth image to display\n",
    "current_mouth_image = mouth_images.get(\"X\") # Default to Rest\n",
    "current_mouth_rect = None\n",
    "if current_mouth_image:\n",
    "    current_mouth_rect = current_mouth_image.get_rect(center=MOUTH_POS)\n",
    "\n",
    "\n",
    "# -- Keyboard Listener Function (Keep as is) --\n",
    "INTERRUPT_KEY = 'space'\n",
    "def keyboard_listener():\n",
    "    print(f\"--- Press '{INTERRUPT_KEY.upper()}' to interrupt AI speech ---\")\n",
    "    def on_key_press(event):\n",
    "        if event.name == INTERRUPT_KEY and event.event_type == keyboard.KEY_DOWN:\n",
    "            if not interrupt_flag.is_set():\n",
    "                debug_print(f\"Interrupt key '{INTERRUPT_KEY}' pressed!\", 1)\n",
    "                interrupt_queue.put(\"INTERRUPT\")\n",
    "                interrupt_flag.set() # Set the global flag\n",
    "\n",
    "    keyboard.hook(on_key_press)\n",
    "    keyboard.wait()\n",
    "\n",
    "# -- Modified stop_speech Function (Keep as is) --\n",
    "def stop_speech():\n",
    "    if pygame.mixer.get_init() and pygame.mixer.music.get_busy():\n",
    "        pygame.mixer.music.stop()\n",
    "        pygame.mixer.music.unload()\n",
    "        debug_print(\"Speech stopped via pygame.\", 2)\n",
    "\n",
    "# -- Sentence Splitting Function --\n",
    "def split_into_sentences(text):\n",
    "    \"\"\"Splits text into sentences using NLTK.\"\"\"\n",
    "    try:\n",
    "        # Download punkt tokenizer if not already present\n",
    "        try:\n",
    "            nltk.data.find('tokenizers/punkt')\n",
    "            # debug_print(\"NLTK 'punkt' tokenizer found.\", 2) # Reduce noise\n",
    "        except nltk.downloader.DownloadError:\n",
    "            debug_print(\"NLTK 'punkt' tokenizer not found. Downloading...\", 2)\n",
    "            nltk.download('punkt')\n",
    "            debug_print(\"NLTK 'punkt' tokenizer downloaded.\", 2)\n",
    "\n",
    "        # Simple replacements to help NLTK, especially after lists, etc.\n",
    "        text = re.sub(r'\\n\\s*\\n', '. ', text) # Replace double newlines with periods\n",
    "        text = re.sub(r'([a-zA-Z])\\.\\s*\\n', r'\\1. ', text) # Handle period followed by newline\n",
    "        text = re.sub(r'\\.\\s+', '. ', text) # Normalize spacing after periods\n",
    "        sentences = nltk.sent_tokenize(text)\n",
    "        # Filter out potentially empty sentences from artifacts\n",
    "        sentences = [s.strip() for s in sentences if s.strip()]\n",
    "        # debug_print(f\"Split into {len(sentences)} sentences.\", 3) # Reduce noise\n",
    "        return sentences\n",
    "    except Exception as e:\n",
    "        debug_print(f\"Error splitting text into sentences: {e}\", 2)\n",
    "        # Fallback: split by paragraphs or just return the whole text as one \"sentence\"\n",
    "        return [s.strip() for s in text.split('\\n\\n') if s.strip()]\n",
    "\n",
    "\n",
    "# --- MODIFIED speak Function (Handles Sentences & Interruption Context) ---\n",
    "TTS_TEMP_FILE = \"temp_ai_speech.mp3\" # Keep a single temp file name\n",
    "\n",
    "def cleanup_temp_files(extensions=('.mp3', '.wav', '.json', '.tsv')):\n",
    "    \"\"\"\n",
    "    Deletes temporary files starting with 'temp_ai_speech_' and\n",
    "    ending with specified extensions.\n",
    "\n",
    "    It iterates through files in the script's directory and attempts\n",
    "    to delete each matching file using a retry mechanism, similar to\n",
    "    the original second function, but applied to all identified temp files.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # --- Get the directory where the script is located (from original function 1) ---\n",
    "        # Use os.getcwd() as a fallback if __file__ is not defined (less common)\n",
    "        try:\n",
    "            temp_dir = os.path.dirname(os.path.abspath(__file__))\n",
    "        except NameError:\n",
    "             # __file__ might not be defined in interactive sessions like IDLE or notebooks\n",
    "             temp_dir = os.getcwd()\n",
    "             debug_print(\"Warning: __file__ not defined, using os.getcwd() for temp file cleanup directory.\", 2)\n",
    "\n",
    "        debug_print(f\"Checking for temp files to clean in: {temp_dir}\", 3)\n",
    "\n",
    "        # --- Iterate through all files in the directory (from original function 1) ---\n",
    "        for filename in os.listdir(temp_dir):\n",
    "            file_path = os.path.join(temp_dir, filename)\n",
    "\n",
    "            # Check if it matches the temporary file pattern and one of the extensions\n",
    "            # Also ensure it's actually a file, not a directory\n",
    "            if (filename.startswith(\"temp_ai_speech_\") and\n",
    "                filename.endswith(extensions) and\n",
    "                os.path.isfile(file_path)): # Added check to only target files\n",
    "\n",
    "                debug_print(f\"Found potential temp file: {filename}\", 3)\n",
    "\n",
    "                # --- Apply the retry logic to THIS specific file (adapted from original function 2) ---\n",
    "                successfully_removed = False\n",
    "                debug_print(f\"Attempting to clean up temp file: {filename}\", 3) # Match log from original func 2\n",
    "                for attempt in range(5): # Retry up to 5 times\n",
    "                    try:\n",
    "                        debug_print(f\"Attempt {attempt+1} to remove {filename}...\", 4) # More detailed log\n",
    "                        os.remove(file_path)\n",
    "                        debug_print(f\"Cleaned up temp file: {filename}\", 3) # Match log from original func 2\n",
    "                        successfully_removed = True\n",
    "                        break # Success for *this* file, move to the next file in the outer loop\n",
    "                    except OSError as e:\n",
    "                        # This often happens if the file is in use by another process\n",
    "                        debug_print(f\"Attempt {attempt+1} failed for {filename} (OSError): {e} (File likely in use)\", 3) # Match log from original func 2\n",
    "                        time.sleep(0.1) # Wait a bit before retrying\n",
    "                    except Exception as e:\n",
    "                        # Catch any other unexpected errors during removal\n",
    "                        debug_print(f\"Attempt {attempt+1} failed for {filename} (unexpected error): {e}\", 3) # Match log style\n",
    "                        time.sleep(0.1) # Wait a bit before retrying\n",
    "\n",
    "                if not successfully_removed:\n",
    "                    debug_print(f\"Failed to remove temp file {filename} after multiple attempts.\", 3) # Match log from original func 2\n",
    "                # --- End of retry logic for the current file ---\n",
    "\n",
    "            # The outer loop continues to the next file regardless of\n",
    "            # whether the current one was deleted or failed after retries.\n",
    "\n",
    "    except Exception as e:\n",
    "         # Catch errors that happen during directory listing, path joining, etc.\n",
    "         debug_print(f\"Error during temp file cleanup process: {e}\", 2) # Match log from original func 2\n",
    "\n",
    "\n",
    "# --- NEW: Function to Run Rhubarb Lip Sync ---\n",
    "RHUBARB_EXECUTABLE = r\"C:\\Rhubarb\" # Or full path e.g., r\"C:\\path\\to\\rhubarb.exe\"\n",
    "\n",
    "def get_lip_sync_data(wav_filepath, text_content):\n",
    "    \"\"\"Runs Rhubarb Lip Sync and returns the parsed timing data.\"\"\"\n",
    "    debug_print(f\"Running Rhubarb on: {wav_filepath}\", 2)\n",
    "    output_format = \"json\" # Or 'tsv'\n",
    "    output_filepath = wav_filepath.replace(\".wav\", f\".{output_format}\")\n",
    "    dialog_filepath = wav_filepath.replace(\".wav\", \".txt\")\n",
    "\n",
    "    # Create dialog file\n",
    "    try:\n",
    "        with open(dialog_filepath, \"w\", encoding=\"utf-8\") as f:\n",
    "            f.write(text_content)\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Error writing dialog file {dialog_filepath}: {e}\")\n",
    "        return None\n",
    "\n",
    "    # Construct Rhubarb command\n",
    "    # Adjust recognizer based on language if needed: -r phonetic --extendedShapes GHX\n",
    "    command = [\n",
    "        RHUBARB_EXECUTABLE,\n",
    "        \"-f\", output_format,\n",
    "        \"-o\", output_filepath,\n",
    "        \"--dialogFile\", dialog_filepath,\n",
    "        wav_filepath\n",
    "    ]\n",
    "    debug_print(f\"Rhubarb command: {' '.join(command)}\", 3)\n",
    "\n",
    "    try:\n",
    "        # Run Rhubarb as subprocess\n",
    "        process = subprocess.run(command, capture_output=True, text=True, check=True)\n",
    "        debug_print(\"Rhubarb executed successfully.\", 3)\n",
    "        # debug_print(f\"Rhubarb stdout: {process.stdout}\", 4) # Optional verbose debug\n",
    "        # debug_print(f\"Rhubarb stderr: {process.stderr}\", 4) # Optional verbose debug\n",
    "\n",
    "        # Read the output JSON file\n",
    "        with open(output_filepath, \"r\", encoding=\"utf-8\") as f:\n",
    "            rhubarb_data = json.load(f)\n",
    "        \n",
    "        # Clean up dialog file immediately\n",
    "        try: os.remove(dialog_filepath)\n",
    "        except: pass # Ignore cleanup error\n",
    "\n",
    "        return rhubarb_data[\"mouthCues\"] # Return the list of {\"start\": time, \"end\": time, \"value\": \"A\"/\"B\"/...}\n",
    "\n",
    "    except FileNotFoundError:\n",
    "         print(f\"❌ Error: '{RHUBARB_EXECUTABLE}' command not found. Is Rhubarb installed and in PATH?\")\n",
    "         return None\n",
    "    except subprocess.CalledProcessError as e:\n",
    "        print(f\"❌ Error running Rhubarb: {e}\")\n",
    "        print(f\"    Rhubarb stdout: {e.stdout}\")\n",
    "        print(f\"    Rhubarb stderr: {e.stderr}\")\n",
    "        return None\n",
    "    except json.JSONDecodeError as e:\n",
    "         print(f\"❌ Error parsing Rhubarb output file {output_filepath}: {e}\")\n",
    "         return None\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Unexpected error getting lip sync data: {e}\")\n",
    "        return None\n",
    "\n",
    "\n",
    "# --- MODIFIED speak Function (Integrates Lip Sync) ---\n",
    "def speak(text_or_sentences, speech_type=\"generic\", topic=None):\n",
    "    \"\"\"\n",
    "    Generates TTS (WAV), runs Rhubarb, plays audio sentence by sentence,\n",
    "    and updates global mouth shape based on timings.\n",
    "    \"\"\"\n",
    "    global current_state, interrupted_context, current_mouth_image, current_mouth_rect\n",
    "\n",
    "    if not pygame.mixer.get_init():\n",
    "        print(\"❌ Mixer not initialized, cannot speak.\")\n",
    "        print(f\"(Fallback) AI says: {text_or_sentences}\")\n",
    "        current_state = STATE_IDLE\n",
    "        return\n",
    "\n",
    "    cleanup_temp_files()\n",
    "\n",
    "    is_list = isinstance(text_or_sentences, list)\n",
    "    sentences = text_or_sentences if is_list else split_into_sentences(text_or_sentences)\n",
    "    full_original_text = \" \".join(sentences)\n",
    "\n",
    "    if not sentences:\n",
    "        debug_print(\"No sentences to speak.\", 2)\n",
    "        current_state = STATE_IDLE; return\n",
    "\n",
    "    # Set State based on Type\n",
    "    # ... (state setting logic remains the same) ...\n",
    "    if speech_type == \"explanation\": current_state = STATE_SPEAKING_EXPLANATION\n",
    "    elif speech_type == \"answer\": current_state = STATE_SPEAKING_ANSWER\n",
    "    elif speech_type == \"transition\": current_state = STATE_SPEAKING_TRANSITION\n",
    "    else: current_state = STATE_SPEAKING_GREETING\n",
    "\n",
    "    debug_print(f\"Starting to speak ({current_state}). Total sentences: {len(sentences)}\")\n",
    "\n",
    "    interrupt_flag.clear()\n",
    "    tts_finished_event.clear()\n",
    "    interrupted_mid_speech = False\n",
    "    start_index = 0\n",
    "\n",
    "    if speech_type == \"explanation\" and interrupted_context.get(\"resuming\"):\n",
    "        start_index = interrupted_context[\"resume_index\"]\n",
    "        debug_print(f\"Resuming explanation from sentence index: {start_index}\", 2)\n",
    "        interrupted_context[\"resuming\"] = False\n",
    "\n",
    "    # --- Sentence Iteration Loop ---\n",
    "    for i in range(start_index, len(sentences)):\n",
    "        sentence = sentences[i]\n",
    "        if not sentence: continue\n",
    "\n",
    "        # --- Generate Unique Filenames (MP3, WAV, JSON) ---\n",
    "        base_filename = f\"temp_ai_speech_{i}\"\n",
    "        mp3_filename = f\"{base_filename}.mp3\"\n",
    "        wav_filename = f\"{base_filename}.wav\"\n",
    "        # rhubarb_output_filename = f\"{base_filename}.json\" # No longer needed separately\n",
    "\n",
    "        debug_print(f\"Speaking sentence {i+1}/{len(sentences)}: '{sentence[:50]}...'\", 2)\n",
    "\n",
    "        # --- Generate MP3 and Convert to WAV ---\n",
    "        lip_sync_cues = None\n",
    "        try:\n",
    "            # Generate MP3\n",
    "            tts = gTTS(text=sentence, lang='en', slow=False)\n",
    "            if os.path.exists(mp3_filename): os.remove(mp3_filename)\n",
    "            tts.save(mp3_filename)\n",
    "\n",
    "            # Convert MP3 to WAV using Pydub\n",
    "            debug_print(f\"Converting {mp3_filename} to {wav_filename}\", 3)\n",
    "            audio = AudioSegment.from_mp3(mp3_filename)\n",
    "            audio.export(wav_filename, format=\"wav\")\n",
    "            debug_print(f\"WAV file created.\", 3)\n",
    "\n",
    "            # --- Get Lip Sync Data ---\n",
    "            lip_sync_cues = get_lip_sync_data(wav_filename, sentence)\n",
    "            if lip_sync_cues is None:\n",
    "                print(f\"⚠️ Warning: Could not get lip sync cues for sentence {i}. Lip sync will be static.\")\n",
    "\n",
    "        except FileNotFoundError as e:\n",
    "             print(f\"❌ Error: FFmpeg/Libav not found or MP3 file missing? ({e}). Cannot convert to WAV.\")\n",
    "             interrupted_mid_speech = True; break\n",
    "        except Exception as e:\n",
    "            print(f\"❌ Error generating/converting audio for sentence {i}: {e}\")\n",
    "            interrupted_mid_speech = True; break\n",
    "\n",
    "        # --- Playback and Lip Sync Animation ---\n",
    "        try:\n",
    "            pygame.mixer.music.load(wav_filename) # Load WAV\n",
    "            pygame.mixer.music.play()\n",
    "            start_time_ms = pygame.time.get_ticks() # Get time playback *starts*\n",
    "\n",
    "            cue_index = 0\n",
    "            current_mouth_image = mouth_images.get(\"X\") # Start with Rest before sound begins\n",
    "\n",
    "            # Monitor loop\n",
    "            while pygame.mixer.music.get_busy() and not interrupt_flag.is_set():\n",
    "                # --- Lip Sync Logic ---\n",
    "                playback_time_sec = pygame.mixer.music.get_pos() / 1000.0 # Current position in seconds\n",
    "                \n",
    "                active_cue_found = False\n",
    "                if lip_sync_cues:\n",
    "                    # Find the current viseme cue based on playback time\n",
    "                    # Note: This linear search is ok for few cues per sentence,\n",
    "                    # but could be optimized for very long audio.\n",
    "                    for idx in range(len(lip_sync_cues)):\n",
    "                         cue = lip_sync_cues[idx]\n",
    "                         if cue[\"start\"] <= playback_time_sec < cue[\"end\"]:\n",
    "                             rhubarb_code = cue[\"value\"] # A, B, C...\n",
    "                             mapped_code = rhubarb_map.get(rhubarb_code, \"X\") # Map to our available images\n",
    "                             current_mouth_image = mouth_images.get(mapped_code)\n",
    "                             if current_mouth_image:\n",
    "                                  current_mouth_rect = current_mouth_image.get_rect(center=MOUTH_POS)\n",
    "                             active_cue_found = True\n",
    "                             # debug_print(f\"Time: {playback_time_sec:.2f} -> Cue: {rhubarb_code} -> Img: {mapped_code}\", 4) # Verbose\n",
    "                             break # Found the active cue for this time slice\n",
    "\n",
    "                if not active_cue_found:\n",
    "                    # If no cue is active (e.g., gap between cues, or end of audio), default to Rest\n",
    "                    current_mouth_image = mouth_images.get(\"X\")\n",
    "                    if current_mouth_image:\n",
    "                        current_mouth_rect = current_mouth_image.get_rect(center=MOUTH_POS)\n",
    "\n",
    "                # --- Interrupt Check --- (remains the same)\n",
    "                try:\n",
    "                    interrupt_signal = interrupt_queue.get_nowait()\n",
    "                    if interrupt_signal == \"INTERRUPT\": interrupt_flag.set()\n",
    "                except queue.Empty: pass\n",
    "\n",
    "                # --- Pygame Display Update ---\n",
    "                # We need to handle pygame events and draw the screen *continuously*\n",
    "                # This should ideally be in the main loop, but for simplicity,\n",
    "                # we do a quick draw here during speech playback.\n",
    "                screen.fill(WHITE) # Clear screen\n",
    "                # Draw optional head image here\n",
    "                # screen.blit(head_image, head_rect)\n",
    "                # Draw the current mouth image\n",
    "                if current_mouth_image and current_mouth_rect:\n",
    "                    screen.blit(current_mouth_image, current_mouth_rect)\n",
    "                # Draw status text (optional)\n",
    "                # status_text = font.render(f\"State: {current_state}\", True, BLACK)\n",
    "                # screen.blit(status_text, (10, 10))\n",
    "                pygame.display.flip() # Update the display\n",
    "\n",
    "                # Handle pygame events to prevent window freeze\n",
    "                for event in pygame.event.get():\n",
    "                     if event.type == pygame.QUIT:\n",
    "                         print(\"Pygame window closed by user.\")\n",
    "                         # Need a way to signal the main loop to exit cleanly\n",
    "                         # For now, just stop speech and set flag\n",
    "                         interrupt_flag.set() # Use interrupt flag to stop\n",
    "                         interrupted_mid_speech = True\n",
    "                         break # Exit inner event loop\n",
    "                if interrupted_mid_speech: break # Exit playback loop if QUIT detected\n",
    "\n",
    "                time.sleep(0.01) # Short sleep, drawing takes time\n",
    "\n",
    "\n",
    "            # --- Post Sentence Playback ---\n",
    "            # Reset mouth to Rest when sentence audio finishes\n",
    "            current_mouth_image = mouth_images.get(\"X\")\n",
    "            if current_mouth_image:\n",
    "                current_mouth_rect = current_mouth_image.get_rect(center=MOUTH_POS)\n",
    "                # Redraw one last time in Rest pose\n",
    "                screen.fill(WHITE)\n",
    "                if current_mouth_image and current_mouth_rect: screen.blit(current_mouth_image, current_mouth_rect)\n",
    "                pygame.display.flip()\n",
    "\n",
    "\n",
    "            # Check if loop exited due to interruption\n",
    "            if interrupt_flag.is_set():\n",
    "                debug_print(f\"Interrupt detected while speaking sentence {i+1}.\", 1)\n",
    "                stop_speech() # This stops audio\n",
    "                interrupted_mid_speech = True\n",
    "                # Reset mouth visually on interrupt too\n",
    "                current_mouth_image = mouth_images.get(\"X\")\n",
    "                if current_mouth_image: current_mouth_rect = current_mouth_image.get_rect(center=MOUTH_POS)\n",
    "\n",
    "\n",
    "                # --- SAVE CONTEXT IF IT WAS AN EXPLANATION --- (logic remains same)\n",
    "                if current_state == STATE_SPEAKING_EXPLANATION:\n",
    "                     # ... (save context logic) ...\n",
    "                    interrupted_context[\"type\"] = \"explanation\"; interrupted_context[\"topic\"] = topic\n",
    "                    interrupted_context[\"full_text\"] = full_original_text; interrupted_context[\"sentences\"] = sentences\n",
    "                    interrupted_context[\"resume_index\"] = i; interrupted_context[\"saved\"] = True\n",
    "                    debug_print(f\"Explanation context saved. Resume index: {i}\", 2)\n",
    "                else:\n",
    "                     # ... (clear context logic) ...\n",
    "                     debug_print(f\"Interrupted during non-explanation speech ({current_state}). No context saved for resume.\", 2)\n",
    "                     interrupted_context = {\"saved\": False}\n",
    "\n",
    "                break # Exit the sentence loop\n",
    "\n",
    "        except pygame.error as e:\n",
    "            print(f\"❌ Error during pygame playback/drawing for sentence {i}: {e}\")\n",
    "            interrupted_mid_speech = True; break\n",
    "        except Exception as e:\n",
    "             print(f\"❌ Unexpected error during sentence playback/drawing loop {i}: {e}\")\n",
    "             interrupted_mid_speech = True; break\n",
    "\n",
    "    # --- Post-Loop Handling --- (logic remains the same)\n",
    "    if not interrupted_mid_speech:\n",
    "        debug_print(\"Finished speaking all sentences naturally.\", 2)\n",
    "        tts_finished_event.set()\n",
    "        current_state = STATE_IDLE\n",
    "    else:\n",
    "        debug_print(f\"Exited speak function due to interruption/error (Flag: {interrupt_flag.is_set()}).\", 2)\n",
    "\n",
    "\n",
    "# === MAIN INTERACTION LOOP ===\n",
    "\n",
    "# Initialize keyboard listener in a separate thread\n",
    "keyboard_thread = threading.Thread(target=keyboard_listener, daemon=True)\n",
    "keyboard_thread.start()\n",
    "debug_print(\"Keyboard listener thread started.\")\n",
    "\n",
    "# Initial greeting\n",
    "speak(\"Hello! I am your AI science teacher.\", speech_type=\"greeting\")\n",
    "# After speak returns, check the interrupt flag and handle state transition\n",
    "if interrupt_flag.is_set():\n",
    "    debug_print(\"Greeting interrupted.\", 1)\n",
    "    current_state = STATE_HANDLING_INTERRUPTION\n",
    "    interrupt_flag.clear() # Clear the flag after handling\n",
    "else:\n",
    "    debug_print(\"Greeting finished normally.\", 1)\n",
    "    current_state = STATE_IDLE\n",
    "\n",
    "def run_voice_teacher():\n",
    "    global current_state, interrupt_flag, interrupted_context, current_mouth_image, current_mouth_rect\n",
    "\n",
    "    listener_thread = threading.Thread(target=keyboard_listener, daemon=True)\n",
    "    listener_thread.start()\n",
    "    debug_print(\"Keyboard listener thread started.\")\n",
    "\n",
    "    interrupted_context = {\"saved\": False}\n",
    "    \n",
    "    # Keep track if main loop should run\n",
    "    running = True\n",
    "\n",
    "    # Initial Greeting\n",
    "    speak(\"Hello! Press SPACE to interrupt. What topic today?\", speech_type=\"greeting\")\n",
    "    # Don't wait here in main loop, speak() handles its own duration/interrupts\n",
    "\n",
    "    current_state = STATE_LISTENING\n",
    "\n",
    "    # --- Main State-Driven Loop ---\n",
    "    while running:\n",
    "        # --- Pygame Event Handling ---\n",
    "        for event in pygame.event.get():\n",
    "            if event.type == pygame.QUIT:\n",
    "                print(\"QUIT event detected in main loop.\")\n",
    "                running = False # Signal loop to stop\n",
    "                interrupt_flag.set() # Signal any active speak() to stop too\n",
    "                stop_speech() # Force stop audio\n",
    "                break # Exit event loop\n",
    "        if not running: break # Exit main loop if QUIT detected\n",
    "\n",
    "        # --- Check for Interruptions ---\n",
    "        if interrupt_flag.is_set() and current_state != STATE_HANDLING_INTERRUPTION:\n",
    "            # We only enter interrupt handling state *once* per flag set\n",
    "            debug_print(\"Handling interrupt detected by main loop.\")\n",
    "            stop_speech() # Ensure stopped\n",
    "            current_state = STATE_HANDLING_INTERRUPTION\n",
    "            print(f\"\\n🎤 You interrupted! Ask your question or give a command:\")\n",
    "\n",
    "            interruption_input = listen_to_student()\n",
    "            # Don't clear flag immediately, clear it after handling OR if listening fails\n",
    "\n",
    "            if interruption_input:\n",
    "                current_state = STATE_PROCESSING\n",
    "                intent, topic_or_question = understand_intent_and_topic(interruption_input)\n",
    "                interrupt_flag.clear() # Clear flag *after* successful listen + NLU\n",
    "\n",
    "                # Handle interruption command (answer, farewell, etc.)\n",
    "                # ... (existing logic for handling intent inside interrupt) ...\n",
    "                if intent == \"ASK_QUESTION\" and topic_or_question:\n",
    "                    speak(\"Okay, you asked...\", speech_type=\"generic\")\n",
    "                    context_topic_for_answer = interrupted_context.get(\"topic\") if interrupted_context.get(\"saved\") else None\n",
    "                    answer = generate_spoken_answer(topic_or_question, context_topic_for_answer)\n",
    "                    speak(answer, speech_type=\"answer\")\n",
    "                elif intent == \"FAREWELL\":\n",
    "                     speak(\"Okay, goodbye!\", speech_type=\"greeting\")\n",
    "                     running = False # Signal exit after saying goodbye\n",
    "                else:\n",
    "                    speak(\"Okay, how can I help now?\", speech_type=\"generic\")\n",
    "                \n",
    "                # Attempt Resumption if needed (only if not exiting)\n",
    "                if running and interrupted_context.get(\"saved\"):\n",
    "                    # ... (existing resumption logic: generate transition, speak transition, speak remaining) ...\n",
    "                     debug_print(\"Attempting to resume previous explanation...\")\n",
    "                     resume_topic = interrupted_context[\"topic\"]\n",
    "                     resume_sentences = interrupted_context[\"sentences\"]\n",
    "                     resume_idx = interrupted_context[\"resume_index\"]\n",
    "                     transition = generate_transition_phrase(resume_topic)\n",
    "                     speak(transition, speech_type=\"transition\")\n",
    "                     remaining_sentences = resume_sentences[resume_idx:]\n",
    "                     interrupted_context[\"resuming\"] = True\n",
    "                     speak(remaining_sentences, speech_type=\"explanation\", topic=resume_topic)\n",
    "                     if not interrupt_flag.is_set(): interrupted_context = {\"saved\": False}\n",
    "\n",
    "                elif running:\n",
    "                    # No context, just go back to listening\n",
    "                     debug_print(\"No explanation context to resume.\")\n",
    "                     current_state = STATE_LISTENING\n",
    "                     print(\"\\nWaiting for your next command...\")\n",
    "\n",
    "            else: # listen_to_student failed during interruption\n",
    "                speak(\"I didn't catch that.\", speech_type=\"generic\")\n",
    "                # Decide whether to retry listening for interruption or resume/go idle\n",
    "                if interrupted_context.get(\"saved\"):\n",
    "                    # Assume they might want to resume if they interrupted\n",
    "                    interrupt_flag.clear() # Clear flag and let resumption logic try next loop\n",
    "                    # state remains HANDLING_INTERRUPTION until resume attempted\n",
    "                    debug_print(\"Didn't catch interruption command, will attempt resume.\")\n",
    "                else:\n",
    "                    interrupt_flag.clear() # Clear flag\n",
    "                    current_state = STATE_LISTENING\n",
    "                    print(\"\\nWaiting for your next command...\")\n",
    "\n",
    "\n",
    "        # --- Handle Regular States ---\n",
    "        elif current_state == STATE_LISTENING:\n",
    "             if interrupted_context.get(\"saved\"):\n",
    "                 debug_print(\"Clearing old interruption context before listening.\")\n",
    "                 interrupted_context = {\"saved\": False}\n",
    "\n",
    "             debug_print(\"State: LISTENING for command\")\n",
    "             # Only listen if mixer is NOT busy (don't interrupt listening)\n",
    "             if not pygame.mixer.music.get_busy():\n",
    "                student_input = listen_to_student()\n",
    "                if student_input:\n",
    "                    current_state = STATE_PROCESSING\n",
    "                    intent, topic_or_question = understand_intent_and_topic(student_input)\n",
    "                    # Clear flag before starting new action\n",
    "                    interrupt_flag.clear()\n",
    "                    tts_finished_event.clear()\n",
    "\n",
    "                    # --- Handle Intents --- (call speak for each)\n",
    "                    if intent == \"REQUEST_EXPLANATION\" and topic_or_question:\n",
    "                        speak(f\"Okay, explaining {topic_or_question}.\", speech_type=\"generic\")\n",
    "                        explanation = generate_spoken_explanation(topic_or_question)\n",
    "                        speak(explanation, speech_type=\"explanation\", topic=topic_or_question)\n",
    "                    # ... (other intents: ASK_QUESTION, GREETING, FAREWELL) ...\n",
    "                    elif intent == \"ASK_QUESTION\" and topic_or_question:\n",
    "                         speak(\"Let me see...\", speech_type=\"generic\")\n",
    "                         answer = generate_spoken_answer(topic_or_question, None)\n",
    "                         speak(answer, speech_type=\"answer\")\n",
    "                    elif intent == \"GREETING\":\n",
    "                         speak(random.choice([\"Hi!\", \"Hello!\"]), speech_type=\"greeting\")\n",
    "                    elif intent == \"FAREWELL\":\n",
    "                         speak(random.choice([\"Goodbye!\", \"Bye now!\"]), speech_type=\"greeting\")\n",
    "                         running = False # Exit after saying goodbye\n",
    "                    # ... etc ...\n",
    "                    else:\n",
    "                         speak(\"Sorry, I didn't get that.\", speech_type=\"generic\")\n",
    "\n",
    "                # else: listen_to_student returned None, loop continues in LISTENING\n",
    "\n",
    "        elif current_state == STATE_IDLE:\n",
    "             current_state = STATE_LISTENING\n",
    "             # debug_print(\"State: IDLE -> LISTENING\") # Reduce noise\n",
    "\n",
    "        # --- Update Pygame Display ---\n",
    "        screen.fill(WHITE) # Clear screen each frame\n",
    "        # Draw head, status text, etc. if needed\n",
    "        # Draw the current mouth image (updated by speak or reset)\n",
    "        if current_mouth_image and current_mouth_rect:\n",
    "            screen.blit(current_mouth_image, current_mouth_rect)\n",
    "        pygame.display.flip() # Update the display\n",
    "\n",
    "        # Allow loop to breathe\n",
    "        time.sleep(0.02) # Main loop sleep\n",
    "# Main loop\n",
    "def main_interaction_loop():\n",
    "    global current_state, interrupted_context, interrupt_flag\n",
    "\n",
    "    while True:\n",
    "        if current_state == STATE_IDLE:\n",
    "            print(\"\\nAI is ready. What science topic would you like to learn about or ask a question?\")\n",
    "            student_input = listen_to_student()\n",
    "\n",
    "            if student_input:\n",
    "                current_state = STATE_PROCESSING # Temporarily go to processing state\n",
    "                debug_print(\"Understanding student input...\", 1)\n",
    "                intent, topic = understand_intent_and_topic(student_input)\n",
    "                debug_print(f\"Understood: Intent={intent}, Topic={topic}\", 1)\n",
    "\n",
    "                # --- Handle input when SAVED context exists ---\n",
    "                # This block handles inputs received *after* an explanation was interrupted\n",
    "                if interrupted_context.get(\"saved\"):\n",
    "                    debug_print(\"Saved context found. Evaluating input in post-interruption state.\", 1)\n",
    "\n",
    "                    handled_input = False # Flag to check if the input was explicitly handled by this block\n",
    "\n",
    "                    if intent == \"ASK_QUESTION\" and topic: # Added 'and topic' check for clarity\n",
    "                        debug_print(\"Input is a question after interruption with saved context. Answering and will then resume.\", 1)\n",
    "\n",
    "                        # Handle the question - Integrate syllabus check and concise answer\n",
    "                        in_syllabus, syllabus_content = is_in_syllabus(topic)\n",
    "\n",
    "                        if not in_syllabus:\n",
    "                            speak(\"That topic doesn't seem to be in our current syllabus, but I can try to give you a general answer.\", speech_type=\"answer\")\n",
    "                            # Use question topic as context for general answer if available\n",
    "                            answer = generate_spoken_answer(topic, context_content=topic) # Use question topic as context\n",
    "                        else:\n",
    "                            # Use retrieved syllabus content as context\n",
    "                            answer = generate_spoken_answer(topic, context_content=syllabus_content)\n",
    "\n",
    "                        speak(answer, speech_type=\"answer\")\n",
    "                        handled_input = True\n",
    "                        # After speak returns, state transition below handles CHECK_RESUME if not interrupted\n",
    "\n",
    "                    elif intent == \"ASK_QUESTION\" and not topic: # Handle ASK_QUESTION with no topic when context is saved\n",
    "                        debug_print(\"Input is ASK_QUESTION with no topic after interruption with saved context. Asking for clarification.\", 1)\n",
    "                        speak(\"Please ask me a specific question.\", speech_type=\"answer\")\n",
    "                        handled_input = True\n",
    "                        # After speak returns, state transition below handles CHECK_RESUME if not interrupted (if clarification was interrupted)\n",
    "\n",
    "\n",
    "                    elif intent == \"RESUME\":\n",
    "                        debug_print(\"Input is an explicit resume command. Will resume via CHECK_RESUME.\", 1)\n",
    "                        # No speech needed here, just transition\n",
    "                        current_state = STATE_CHECK_RESUME\n",
    "                        handled_input = True\n",
    "                        continue # Skip the rest of the handling and go to CHECK_RESUME\n",
    "\n",
    "\n",
    "                    elif intent == \"REQUEST_EXPLANATION\" and topic:\n",
    "                        # If a new explanation is requested after interruption with saved context\n",
    "                        if topic.lower() == interrupted_context.get(\"topic\", \"\").lower():\n",
    "                            debug_print(\"Input is request for the SAME explanation topic. Treating as resume via CHECK_RESUME.\", 1)\n",
    "                            # No speech needed here, just transition\n",
    "                            current_state = STATE_CHECK_RESUME\n",
    "                            handled_input = True\n",
    "                            continue # Skip the rest of the handling and go to CHECK_RESUME\n",
    "                        else:\n",
    "                            debug_print(f\"Input is request for a NEW explanation topic ('{topic}'). Will acknowledge and then resume the original explanation.\", 1)\n",
    "                            # Acknowledge the new request briefly, but prioritize resuming the old one.\n",
    "                            speak(f\"Okay, I can look into {topic} later. Let's get back to...\", speech_type=\"transition\")\n",
    "                            # Saved context is NOT cleared here.\n",
    "                            handled_input = True\n",
    "                            # After speak returns, state transition below handles CHECK_RESUME if not interrupted\n",
    "\n",
    "\n",
    "                    elif intent == \"OTHER\":\n",
    "                        debug_print(\"Input is 'OTHER' after interruption with saved context. Asking for clarification.\", 1)\n",
    "                        speak(\"I'm not sure about that. Were you trying to ask a question or resume the explanation?\", speech_type=\"answer\")\n",
    "                        # After speak returns, check interrupt flag\n",
    "                        if interrupt_flag.is_set():\n",
    "                            debug_print(\"Clarification question interrupted.\", 1)\n",
    "                            current_state = STATE_HANDLING_INTERRUPTION\n",
    "                            interrupt_flag.clear()\n",
    "                        else:\n",
    "                            debug_print(\"Clarification question finished normally.\", 1)\n",
    "                            current_state = STATE_IDLE # Wait for clarification\n",
    "                        handled_input = True # Mark as handled\n",
    "\n",
    "\n",
    "                    # If the input wasn't one of the explicitly handled cases above\n",
    "                    if not handled_input:\n",
    "                        debug_print(f\"Input is '{intent}' after interruption with saved context. Not explicitly handled. Providing default response and will then resume.\", 1)\n",
    "                        # For intents like GREETING, FAREWELL, or other unhandled ones when context is saved.\n",
    "                        # We provide a response but preserve the context and then transition to CHECK_RESUME (unless FAREWELL).\n",
    "                        if intent == \"GREETING\":\n",
    "                            speak(random.choice([\"Hello again!\", \"Hi!\", \"Greetings!\"]), speech_type=\"greeting\")\n",
    "                            # After speak returns, state transition below handles CHECK_RESUME if not interrupted\n",
    "                        elif intent == \"FAREWELL\":\n",
    "                            speak(random.choice([\"Goodbye!\", \"See you later!\"]), speech_type=\"farewell\")\n",
    "                            break # Exit loop\n",
    "                        elif intent == \"ERROR\": # If NLU returned ERROR for some reason\n",
    "                            speak(\"Sorry, I still didn't get that. Could you try rephrasing?\", speech_type=\"answer\")\n",
    "                            # After speak returns, state transition below handles CHECK_RESUME if not interrupted\n",
    "                        else: # Any other unhandled intent when context is saved\n",
    "                            speak(\"I'm not sure about that. Let me get back to what we were discussing.\", speech_type=\"answer\")\n",
    "                            # After speak returns, state transition below handles CHECK_RESUME if not interrupted\n",
    "\n",
    "                        handled_input = True # Mark as handled\n",
    "\n",
    "\n",
    "                    # --- State Transition after handling input when saved context exists ---\n",
    "                    # After processing the input when saved context is present,\n",
    "                    # the next state should lead to checking for resume,\n",
    "                    # UNLESS the intent was FAREWELL (handled above).\n",
    "                    if intent != \"FAREWELL\":\n",
    "                        # The state transition logic here handles the outcome of the 'speak' call\n",
    "                        # that happened within the handling block above (if any speak call occurred).\n",
    "                        # This ensures that after the response to the interrupting input,\n",
    "                        # the system proceeds to check for resume.\n",
    "                        if interrupt_flag.is_set():\n",
    "                            # The speech within the handling block was interrupted\n",
    "                            debug_print(\"Speech during post-interruption handling was interrupted. Transitioning to HANDLING_INTERRUPTION.\", 1)\n",
    "                            current_state = STATE_HANDLING_INTERRUPTION\n",
    "                            interrupt_flag.clear()\n",
    "                            continue # Go to next loop iteration to handle interruption\n",
    "                        else:\n",
    "                            # Speech finished normally, proceed to check for resume\n",
    "                            debug_print(\"Speech during post-interruption handling finished normally. Transitioning to CHECK_RESUME.\", 1)\n",
    "                            current_state = STATE_CHECK_RESUME\n",
    "                            continue # Go to next loop iteration\n",
    "\n",
    "\n",
    "                # --- Handle input when NO saved context exists ---\n",
    "                # This block is for entirely new requests\n",
    "                else:\n",
    "                    debug_print(\"No saved context found. Handling input as a new request.\", 1)\n",
    "                    # Process the intent as a completely new request\n",
    "                    if intent == \"REQUEST_EXPLANATION\":\n",
    "                        if topic:\n",
    "                            debug_print(f\"Handling new REQUEST_EXPLANATION for topic: {topic}\", 1)\n",
    "\n",
    "                            # Check syllabus for the explanation topic\n",
    "                            in_syllabus, syllabus_content = is_in_syllabus(topic)\n",
    "\n",
    "                            if not in_syllabus:\n",
    "                                # Speak out-of-syllabus transition\n",
    "                                speak(f\"That topic, '{topic}', doesn't seem to be in our current syllabus, but I can try a general overview.\", speech_type=\"transition\")\n",
    "                                # After speak returns, check interrupt flag\n",
    "                                if interrupt_flag.is_set():\n",
    "                                    debug_print(\"Out-of-syllabus transition interrupted.\", 1)\n",
    "                                    current_state = STATE_HANDLING_INTERRUPTION\n",
    "                                    interrupt_flag.clear()\n",
    "                                    continue # Go to next loop iteration to handle interruption\n",
    "                                else:\n",
    "                                    debug_print(\"Out-of-syllabus transition finished normally.\", 1)\n",
    "                                    # Stay in PROCESSING to generate explanation\n",
    "\n",
    "                                # Generate a general explanation (no KB content used here)\n",
    "                                explanation = generate_general_explanation(topic)\n",
    "\n",
    "\n",
    "                            else: # in_syllabus is True\n",
    "                                # Speak transition\n",
    "                                speak(f\"Okay, let's learn about {topic}.\", speech_type=\"transition\")\n",
    "                                # After speak returns, check interrupt flag\n",
    "                                if interrupt_flag.is_set():\n",
    "                                    debug_print(\"Transition interrupted.\", 1)\n",
    "                                    current_state = STATE_HANDLING_INTERRUPTION\n",
    "                                    interrupt_flag.clear()\n",
    "                                    continue # Go to next loop iteration to handle interruption\n",
    "                                else:\n",
    "                                    debug_print(\"Transition finished normally.\", 1)\n",
    "                                    # Stay in PROCESSING to generate explanation\n",
    "\n",
    "                                # Generate detailed explanation based on syllabus content\n",
    "                                explanation = generate_full_lesson_text(syllabus_content) # Pass syllabus content\n",
    "\n",
    "\n",
    "                            # Now speak the generated explanation (either general or detailed)\n",
    "                            # Pass the topic to speak for context saving (for potential future interruptions)\n",
    "                            # Start from index 0 for a new explanation\n",
    "                            speak(explanation, speech_type=\"explanation\", topic=topic, start_sentence_index=0)\n",
    "\n",
    "                            # After speak returns, check interrupt flag\n",
    "                            if interrupt_flag.is_set():\n",
    "                                debug_print(\"Explanation interrupted.\", 1)\n",
    "                                current_state = STATE_HANDLING_INTERRUPTION\n",
    "                                interrupt_flag.clear()\n",
    "                                continue # Go to next loop iteration to handle interruption\n",
    "                        else:\n",
    "                                debug_print(\"Explanation finished normally.\", 1)\n",
    "                                # Explanation finished normally, clear any saved context\n",
    "                                interrupted_context.clear()\n",
    "                                interrupted_context = { # Reinitialize context\n",
    "                                    \"type\": None, \"topic\": None, \"full_text\": None,\n",
    "                                    \"sentences\": [], \"resume_index\": 0, \"saved\": False\n",
    "                                }\n",
    "                                current_state = STATE_IDLE # Back to idle after speaking\n",
    "\n",
    "                    elif intent == \"ASK_QUESTION\": # This specific block handles no topic in the question\n",
    "                        speak(\"Please ask me a specific question.\", speech_type=\"answer\")\n",
    "                        # After speak returns, check interrupt flag\n",
    "                        if interrupt_flag.is_set():\n",
    "                            debug_print(\"Prompt interrupted.\", 1)\n",
    "                            current_state = STATE_HANDLING_INTERRUPTION\n",
    "                            interrupt_flag.clear()\n",
    "                        else:\n",
    "                            debug_print(\"Prompt finished normally.\", 1)\n",
    "                            current_state = STATE_IDLE\n",
    "\n",
    "\n",
    "                    elif intent == \"GREETING\":\n",
    "                        speak(random.choice([\"Hello!\", \"Hi there!\", \"Greetings!\"]), speech_type=\"greeting\")\n",
    "                        # After speak returns, check interrupt flag\n",
    "                        if interrupt_flag.is_set():\n",
    "                            debug_print(\"Greeting response interrupted.\", 1)\n",
    "                            current_state = STATE_HANDLING_INTERRUPTION\n",
    "                            interrupt_flag.clear()\n",
    "                        else:\n",
    "                            debug_print(\"Greeting response finished normally.\", 1)\n",
    "                            current_state = STATE_IDLE\n",
    "\n",
    "\n",
    "                    elif intent == \"FAREWELL\":\n",
    "                        speak(random.choice([\"Goodbye!\", \"See you later!\", \"Farewell!\"]), speech_type=\"farewell\")\n",
    "                        break # Exit loop\n",
    "\n",
    "                    elif intent == \"RESUME\":\n",
    "                        # Resume command when no context exists\n",
    "                        speak(\"There is no explanation to resume.\", speech_type=\"answer\")\n",
    "                        # After speak returns, check interrupt flag\n",
    "                        if interrupt_flag.is_set():\n",
    "                            debug_print(\"Resume failed message interrupted.\", 1)\n",
    "                            current_state = STATE_HANDLING_INTERRUPTION\n",
    "                            interrupt_flag.clear()\n",
    "                        else:\n",
    "                            debug_print(\"Resume failed message finished normally.\", 1)\n",
    "                            current_state = STATE_IDLE\n",
    "\n",
    "                    elif intent == \"OTHER\":\n",
    "                        speak(\"Hmm, I'm not sure how to respond to that. Could you try rephrasing?\", speech_type=\"answer\")\n",
    "                        # After speak returns, check interrupt flag\n",
    "                        if interrupt_flag.is_set():\n",
    "                            debug_print(\"Generic response interrupted.\", 1)\n",
    "                            current_state = STATE_HANDLING_INTERRUPTION\n",
    "                            interrupt_flag.clear()\n",
    "                        else:\n",
    "                            debug_print(\"Generic response finished normally.\", 1)\n",
    "                            current_state = STATE_IDLE\n",
    "\n",
    "                    elif intent == \"ERROR\":\n",
    "                        speak(\"Sorry, I had trouble understanding that. Could you repeat or rephrase?\", speech_type=\"answer\")\n",
    "                        # After speak returns, check interrupt flag\n",
    "                        if interrupt_flag.is_set():\n",
    "                            debug_print(\"Error response interrupted.\", 1)\n",
    "                            current_state = STATE_HANDLING_INTERRUPTION\n",
    "                            interrupt_flag.clear()\n",
    "                        else:\n",
    "                            debug_print(\"Error response finished normally.\", 1)\n",
    "                            current_state = STATE_IDLE\n",
    "\n",
    "\n",
    "            else:\n",
    "                # No speech detected or recognized\n",
    "                pass # Stay in IDLE, loop will continue\n",
    "\n",
    "        elif current_state == STATE_HANDLING_INTERRUPTION:\n",
    "            debug_print(\"Handling interruption...\", 1)\n",
    "            # Respond to the interruption and transition to listening\n",
    "            # Check if the interrupt flag is still set upon entering this state\n",
    "            # This happens if the 'Yes?' was interrupted or if multiple interrupts were queued.\n",
    "            if interrupt_flag.is_set():\n",
    "                debug_print(\"Interrupt flag set on entering HANDLING_INTERRUPTION. Clearing flag and transitioning to IDLE.\", 1)\n",
    "                interrupt_flag.clear() # Clear the flag\n",
    "                # Decide if we should say \"Yes?\" again or just go straight to listening.\n",
    "                # Going straight to listening seems more responsive after multiple interrupts.\n",
    "                current_state = STATE_IDLE # Transition to idle to listen again\n",
    "            else:\n",
    "                # If the state is HANDLING_INTERRUPTION and the flag is NOT set,\n",
    "                # it means we just finished speaking the interruption response (\"Yes?\").\n",
    "                # Speak the interruption acknowledgement\n",
    "                speak(\"Yes?\", speech_type=\"transition\")\n",
    "                # After speaking the interruption acknowledgement, check the flag again\n",
    "                # in case the 'Yes?' was interrupted, and then transition to listening.\n",
    "                if interrupt_flag.is_set():\n",
    "                    debug_print(\"'Yes?' response interrupted.\", 1)\n",
    "                    # If \"Yes?\" is interrupted, transition back to HANDLING_INTERRUPTION\n",
    "                    # The next time HANDLING_INTERRUPTION is entered, the flag will be set,\n",
    "                    # leading to the first branch of this block (clearing flag and going to IDLE).\n",
    "                    current_state = STATE_HANDLING_INTERRUPTION # Stay/return to this state\n",
    "                    interrupt_flag.clear() # Clear for next check cycle\n",
    "                    continue # Go to next loop iteration\n",
    "                else:\n",
    "                    debug_print(\"'Yes?' response finished normally.\", 1)\n",
    "                    current_state = STATE_IDLE # Transition to idle to listen\n",
    "\n",
    "\n",
    "        elif current_state == STATE_CHECK_RESUME:\n",
    "            debug_print(\"Checking if explanation needs resuming...\", 1)\n",
    "            if interrupted_context.get(\"saved\"):\n",
    "                debug_print(f\"Saved context found. Resuming explanation from index: {interrupted_context.get('resume_index')}\", 1)\n",
    "                # Add a transition phrase before resuming\n",
    "                speak(\"Okay, getting back to our discussion.\", speech_type=\"transition\")\n",
    "                # After transition speak returns, check interrupt flag\n",
    "                if interrupt_flag.is_set():\n",
    "                    debug_print(\"Resume transition interrupted.\", 1)\n",
    "                    current_state = STATE_HANDLING_INTERRUPTION\n",
    "                    interrupt_flag.clear()\n",
    "                    continue # Go to next loop iteration to handle interruption\n",
    "                else:\n",
    "                    debug_print(\"Resume transition finished normally.\", 1)\n",
    "                    # Proceed with resuming the explanation\n",
    "\n",
    "\n",
    "                # Speak the saved sentences, starting from the resume index\n",
    "                speak(interrupted_context[\"sentences\"], speech_type=\"explanation\", topic=interrupted_context.get(\"topic\"), start_sentence_index=interrupted_context.get(\"resume_index\", 0))\n",
    "\n",
    "                # After speak returns, check interrupt flag\n",
    "                if interrupt_flag.is_set():\n",
    "                    debug_print(\"Resumed explanation interrupted.\", 1)\n",
    "                    current_state = STATE_HANDLING_INTERRUPTION\n",
    "                    interrupt_flag.clear()\n",
    "                    continue # Go to next loop iteration to handle interruption\n",
    "                else:\n",
    "                    debug_print(\"Resumed explanation finished normally.\", 1)\n",
    "                    debug_print(\"Explanation resume completed.\", 1)\n",
    "                    # Clear context after successful resume completion\n",
    "                    interrupted_context.clear()\n",
    "                    interrupted_context = {\n",
    "                        \"type\": None, \"topic\": None, \"full_text\": None,\n",
    "                        \"sentences\": [], \"resume_index\": 0, \"saved\": False\n",
    "                    }\n",
    "                    current_state = STATE_IDLE # Back to idle\n",
    "\n",
    "            else:\n",
    "                debug_print(\"No saved context to resume.\", 1)\n",
    "                # This state should ideally only be reached if saved context is expected but missing\n",
    "                # Respond that there's nothing to resume\n",
    "                speak(\"It seems there was no explanation saved to resume.\", speech_type=\"answer\")\n",
    "                # After speak returns, check interrupt flag\n",
    "                if interrupt_flag.is_set():\n",
    "                    debug_print(\"No resume message interrupted.\", 1)\n",
    "                    current_state = STATE_HANDLING_INTERRUPTION\n",
    "                    interrupt_flag.clear()\n",
    "                # If interrupted here, the handling will lead to IDLE anyway\n",
    "                else:\n",
    "                    debug_print(\"No resume message finished normally.\", 1)\n",
    "                    current_state = STATE_IDLE # Nothing to resume, go to idle\n",
    "\n",
    "\n",
    "        elif current_state in [STATE_SPEAKING_EXPLANATION, STATE_SPEAKING_ANSWER, STATE_SPEAKING_GREETING, STATE_SPEAKING_TRANSITION, STATE_PROCESSING, STATE_LISTENING]:\n",
    "            # These states are either actively managed within function calls (speak, listen, understand)\n",
    "            # or are transitional states. The logic to move out of them is handled elsewhere\n",
    "            # (within the function or by the explicit state transitions after function calls).\n",
    "            # This block primarily ensures the loop doesn't busy-wait excessively in these states.\n",
    "            try:\n",
    "                # Consume any stray interrupt signals from the queue\n",
    "                while not interrupt_queue.empty():\n",
    "                    interrupt_queue.get_nowait()\n",
    "                    debug_print(\"Consumed interrupt signal from queue.\", 3)\n",
    "            except queue.Empty:\n",
    "                pass # Should not happen due to while condition\n",
    "\n",
    "            # Add a small sleep to prevent the loop from consuming too much CPU\n",
    "            time.sleep(0.01) # Keep responsive\n",
    "\n",
    "\n",
    "        else:\n",
    "            # Should not happen, but handle unexpected states\n",
    "            print(f\"❗ Unexpected state: {current_state}. Resetting to IDLE.\")\n",
    "            current_state = STATE_IDLE\n",
    "            time.sleep(1) # Prevent rapid looping on error\n",
    "\n",
    "\n",
    "# Initial cleanup of temp files on startup\n",
    "cleanup_temp_files()\n",
    "\n",
    "\n",
    "\n",
    "# --- Start the AI Teacher ---\n",
    "if __name__ == \"__main__\":\n",
    "     # ... (Initialization and NLTK check) ...\n",
    "    print(\"Initializing AI Teacher (Phase 4)...\")\n",
    "    # ... NLTK check ...\n",
    "\n",
    "    try:\n",
    "        run_voice_teacher()\n",
    "    except KeyboardInterrupt:\n",
    "        print(\"\\nExiting AI Teacher (Ctrl+C)...\")\n",
    "    finally:\n",
    "        # ... (Pygame quit, final cleanup) ...\n",
    "        print(\"Cleaning up temporary files...\")\n",
    "        cleanup_temp_files(extensions=('.mp3', '.wav', '.json', '.tsv', '.txt')) # Add txt for dialog file\n",
    "        if pygame.get_init(): pygame.quit()\n",
    "        print(\"Pygame quit.\")\n",
    "    print(\"AI Teacher session ended.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1d42b7c1-fad9-45ea-8db0-047df45f0032",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pygame 2.6.1 (SDL 2.28.4, Python 3.12.3)\n",
      "Hello from the pygame community. https://www.pygame.org/contribute.html\n",
      "    🔹 Loaded Knowledge Base with 112 entries.\n",
      "    🔹 SentenceTransformer model loaded to cpu.\n",
      "    🔹 FAISS text index loaded.\n",
      "    🔹 Loaded Figures data with 101 entries.\n",
      "    🔹 Reusing text SentenceTransformer model for image search (assuming same).\n",
      "    🔹 FAISS figures index and metadata loaded.\n",
      "Initializing AI Teacher...\n",
      "    🔹 NLTK 'punkt' tokenizer found.\n",
      "    🔹 Pygame initialized successfully (Display, Mixer, Font).\n",
      "    🔹 Loading mouth images from folder: RoboMouths_PNGs...\n",
      "      🔹 Loaded mouth image: RoboMouths_PNGs\\mouth_X.png\n",
      "      🔹 Loaded mouth image: RoboMouths_PNGs\\mouth_H.png\n",
      "      🔹 Loaded mouth image: RoboMouths_PNGs\\mouth_C.png\n",
      "      🔹 Loaded mouth image: RoboMouths_PNGs\\mouth_B.png\n",
      "      🔹 Loaded mouth image: RoboMouths_PNGs\\mouth_G.png\n",
      "      🔹 Loaded mouth image: RoboMouths_PNGs\\mouth_F.png\n",
      "      🔹 Loaded mouth image: RoboMouths_PNGs\\mouth_E.png\n",
      "    🔹 Finished mouth image loading. Loaded 7 shapes.\n",
      "    🔹 Mouth images loaded and initial pose set.\n",
      "      🔹 Starting temp file cleanup...\n",
      "    🔹 Warning: __file__ not defined, using os.getcwd() for temp file cleanup directory.\n",
      "      🔹 Checking for temp files to clean in: C:\\Users\\neesh\\OneDrive\\Documents\\Ai teacher robot\n",
      "      🔹 Temp file cleanup finished.\n",
      "    🔹 Initial temp file cleanup completed.\n",
      "    🔹 Keyboard listener thread started. Listening for 'SPACE'...\n",
      "    🔹 Keyboard listener thread started.\n",
      "  🔹 Starting AI Teacher main loop...\n",
      "      🔹 Starting temp file cleanup...\n",
      "    🔹 Warning: __file__ not defined, using os.getcwd() for temp file cleanup directory.\n",
      "      🔹 Checking for temp files to clean in: C:\\Users\\neesh\\OneDrive\\Documents\\Ai teacher robot\n",
      "      🔹 Temp file cleanup finished.\n",
      "      🔹 Split text into 3 sentences.\n",
      "    🔹 Starting to speak (SPEAKING_GREETING). Total sentences: 3. Starting index: 0\n",
      "    🔹 Processing sentence 1/3: 'Hello!...'\n",
      "      🔹 Generating TTS for sentence 1...\n",
      "      🔹 TTS MP3 saved to temp_ai_speech_0_1746404913.mp3\n",
      "      🔹 Converting temp_ai_speech_0_1746404913.mp3 to temp_ai_speech_0_1746404913.wav...\n",
      "      🔹 WAV file created: temp_ai_speech_0_1746404913.wav\n",
      "      🔹 Getting lip sync data for temp_ai_speech_0_1746404913.wav...\n",
      "    🔹 Running Rhubarb on: temp_ai_speech_0_1746404913.wav\n",
      "      🔹 Created dialog file: temp_ai_speech_0_1746404913.txt\n",
      "      🔹 Rhubarb command: C:\\Rhubarb\\rhubarb.exe -f json -o temp_ai_speech_0_1746404913.json --dialogFile temp_ai_speech_0_1746404913.txt --extendedShapes GHX temp_ai_speech_0_1746404913.wav\n",
      "❌ Error running Rhubarb (CalledProcessError): Command '['C:\\\\Rhubarb\\\\rhubarb.exe', '-f', 'json', '-o', 'temp_ai_speech_0_1746404913.json', '--dialogFile', 'temp_ai_speech_0_1746404913.txt', '--extendedShapes', 'GHX', 'temp_ai_speech_0_1746404913.wav']' returned non-zero exit status 1.\n",
      "    Rhubarb stdout: \n",
      "    Rhubarb stderr: Generating lip sync data for temp_ai_speech_0_1746404913.wav.\n",
      "Progress: [--------------------]   0%#-------------------]   6% \n",
      "[Fatal] Application terminating with error: Error processing file temp_ai_speech_0_1746404913.wav.\n",
      "Error performing speech recognition via PocketSphinx tools.\n",
      "Found Rhubarb executable at C:\\Rhubarb\\rhubarb.exe, but could not find resource file C:\\Rhubarb\\res\\sphinx\\cmudict-en-us.dict.\n",
      "Progress (cont'd): [#-------------------]   6% \n",
      "        🔹 Cleaned up dialog file temp_ai_speech_0_1746404913.txt\n",
      "⚠️ Warning: Could not get lip sync cues for sentence 1. Lip sync will be static during this sentence.\n",
      "      🔹 Loading and playing temp_ai_speech_0_1746404913.wav...\n",
      "      🔹 Sentence 1 playback finished naturally.\n",
      "      🔹 Unloaded temp_ai_speech_0_1746404913.wav after natural finish.\n",
      "        🔹 Cleaned up temp_ai_speech_0_1746404913.mp3\n",
      "        🔹 Cleaned up temp_ai_speech_0_1746404913.wav\n",
      "    🔹 Processing sentence 2/3: 'Press SPACE to interrupt....'\n",
      "      🔹 Generating TTS for sentence 2...\n",
      "      🔹 TTS MP3 saved to temp_ai_speech_1_1746404915.mp3\n",
      "      🔹 Converting temp_ai_speech_1_1746404915.mp3 to temp_ai_speech_1_1746404915.wav...\n",
      "      🔹 WAV file created: temp_ai_speech_1_1746404915.wav\n",
      "      🔹 Getting lip sync data for temp_ai_speech_1_1746404915.wav...\n",
      "    🔹 Running Rhubarb on: temp_ai_speech_1_1746404915.wav\n",
      "      🔹 Created dialog file: temp_ai_speech_1_1746404915.txt\n",
      "      🔹 Rhubarb command: C:\\Rhubarb\\rhubarb.exe -f json -o temp_ai_speech_1_1746404915.json --dialogFile temp_ai_speech_1_1746404915.txt --extendedShapes GHX temp_ai_speech_1_1746404915.wav\n",
      "❌ Error running Rhubarb (CalledProcessError): Command '['C:\\\\Rhubarb\\\\rhubarb.exe', '-f', 'json', '-o', 'temp_ai_speech_1_1746404915.json', '--dialogFile', 'temp_ai_speech_1_1746404915.txt', '--extendedShapes', 'GHX', 'temp_ai_speech_1_1746404915.wav']' returned non-zero exit status 1.\n",
      "    Rhubarb stdout: \n",
      "    Rhubarb stderr: Generating lip sync data for temp_ai_speech_1_1746404915.wav.\n",
      "Progress: [--------------------]   0%#-------------------]   6% \n",
      "[Fatal] Application terminating with error: Error processing file temp_ai_speech_1_1746404915.wav.\n",
      "Error performing speech recognition via PocketSphinx tools.\n",
      "Found Rhubarb executable at C:\\Rhubarb\\rhubarb.exe, but could not find resource file C:\\Rhubarb\\res\\sphinx\\cmudict-en-us.dict.\n",
      "Progress (cont'd): [#-------------------]   6% \n",
      "        🔹 Cleaned up dialog file temp_ai_speech_1_1746404915.txt\n",
      "⚠️ Warning: Could not get lip sync cues for sentence 2. Lip sync will be static during this sentence.\n",
      "      🔹 Loading and playing temp_ai_speech_1_1746404915.wav...\n",
      "      🔹 Sentence 2 playback finished naturally.\n",
      "      🔹 Unloaded temp_ai_speech_1_1746404915.wav after natural finish.\n",
      "        🔹 Cleaned up temp_ai_speech_1_1746404915.mp3\n",
      "        🔹 Cleaned up temp_ai_speech_1_1746404915.wav\n",
      "    🔹 Processing sentence 3/3: 'What topic today?...'\n",
      "      🔹 Generating TTS for sentence 3...\n",
      "      🔹 TTS MP3 saved to temp_ai_speech_2_1746404918.mp3\n",
      "      🔹 Converting temp_ai_speech_2_1746404918.mp3 to temp_ai_speech_2_1746404918.wav...\n",
      "      🔹 WAV file created: temp_ai_speech_2_1746404918.wav\n",
      "      🔹 Getting lip sync data for temp_ai_speech_2_1746404918.wav...\n",
      "    🔹 Running Rhubarb on: temp_ai_speech_2_1746404918.wav\n",
      "      🔹 Created dialog file: temp_ai_speech_2_1746404918.txt\n",
      "      🔹 Rhubarb command: C:\\Rhubarb\\rhubarb.exe -f json -o temp_ai_speech_2_1746404918.json --dialogFile temp_ai_speech_2_1746404918.txt --extendedShapes GHX temp_ai_speech_2_1746404918.wav\n",
      "❌ Error running Rhubarb (CalledProcessError): Command '['C:\\\\Rhubarb\\\\rhubarb.exe', '-f', 'json', '-o', 'temp_ai_speech_2_1746404918.json', '--dialogFile', 'temp_ai_speech_2_1746404918.txt', '--extendedShapes', 'GHX', 'temp_ai_speech_2_1746404918.wav']' returned non-zero exit status 1.\n",
      "    Rhubarb stdout: \n",
      "    Rhubarb stderr: Generating lip sync data for temp_ai_speech_2_1746404918.wav.\n",
      "Progress: [--------------------]   0%#-------------------]   6% \n",
      "[Fatal] Application terminating with error: Error processing file temp_ai_speech_2_1746404918.wav.\n",
      "Error performing speech recognition via PocketSphinx tools.\n",
      "Found Rhubarb executable at C:\\Rhubarb\\rhubarb.exe, but could not find resource file C:\\Rhubarb\\res\\sphinx\\cmudict-en-us.dict.\n",
      "Progress (cont'd): [#-------------------]   6% \n",
      "        🔹 Cleaned up dialog file temp_ai_speech_2_1746404918.txt\n",
      "⚠️ Warning: Could not get lip sync cues for sentence 3. Lip sync will be static during this sentence.\n",
      "      🔹 Loading and playing temp_ai_speech_2_1746404918.wav...\n",
      "      🔹 Sentence 3 playback finished naturally.\n",
      "      🔹 Unloaded temp_ai_speech_2_1746404918.wav after natural finish.\n",
      "        🔹 Cleaned up temp_ai_speech_2_1746404918.mp3\n",
      "        🔹 Cleaned up temp_ai_speech_2_1746404918.wav\n",
      "    🔹 Finished speaking all sentences naturally.\n",
      "  🔹 Initial greeting finished normally.\n",
      "\n",
      "AI is ready. What science topic would you like to learn about or ask a question?\n",
      "    🔹 State: IDLE. Transitioning to LISTENING.\n",
      "    🔹 State: LISTENING. Waiting for input.\n",
      "    🔹 Listening for student...\n",
      "🎤 (Speak now)\n",
      "    🔹 Processing speech...\n",
      "    🔹 Google Speech Recognition could not understand audio.\n",
      "❓ Sorry, I couldn't understand that.\n",
      "    🔹 State: LISTENING. Waiting for input.\n",
      "    🔹 Listening for student...\n",
      "🎤 (Speak now)\n",
      "\n",
      "Exiting AI Teacher (Ctrl+C detected)...\n",
      "  🔹 Starting final cleanup...\n",
      "    🔹 Pygame mixer not busy or not initialized, nothing to stop.\n",
      "      🔹 Starting temp file cleanup...\n",
      "    🔹 Warning: __file__ not defined, using os.getcwd() for temp file cleanup directory.\n",
      "      🔹 Checking for temp files to clean in: C:\\Users\\neesh\\OneDrive\\Documents\\Ai teacher robot\n",
      "      🔹 Temp file cleanup finished.\n",
      "    🔹 Final temp file cleanup completed.\n",
      "Pygame quit.\n",
      "AI Teacher session ended.\n",
      "  🔹 Interrupt key 'space' pressed! Signaling interruption.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import json\n",
    "import faiss\n",
    "import numpy as np\n",
    "import torch\n",
    "import requests\n",
    "import random\n",
    "import yt_dlp\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "\n",
    "# --- NEW IMPORTS for Voice Agent ---\n",
    "import speech_recognition as sr\n",
    "from gtts import gTTS\n",
    "import time # For potential delays or filename uniqueness\n",
    "\n",
    "import pygame # For controllable audio playback and display\n",
    "import keyboard # For push-to-talk interrupt detection\n",
    "import threading # To run keyboard listener concurrently\n",
    "import queue # For communication between threads\n",
    "import nltk # For sentence splitting\n",
    "import subprocess # To run Rhubarb\n",
    "from pydub import AudioSegment # For MP3 to WAV conversion\n",
    "import io # To handle audio data in memory potentially\n",
    "\n",
    "# -------------------------\n",
    "# General Debugging Utility\n",
    "# -------------------------\n",
    "debug_mode = True  # Enable debugging\n",
    "# You might want to set a global debug level\n",
    "# current_debug_level = 3\n",
    "\n",
    "def debug_print(message, level=1):\n",
    "    # Use a global debug level variable if you want to control verbosity\n",
    "    # if level <= current_debug_level:\n",
    "    if debug_mode:\n",
    "        prefix = \"  \" * level\n",
    "        print(f\"{prefix}🔹 {message}\")\n",
    "\n",
    "# -------------------------------------\n",
    "# --- Configuration & Data Loading ---\n",
    "# -------------------------------------\n",
    "\n",
    "# --- !!! USER CONFIGURATION REQUIRED !!! ---\n",
    "LLM_API_KEY = \"YOUR_GROQ_API_KEY\" # Replace with your actual API Key\n",
    "LLM_API_URL = \"https://api.groq.com/openai/v1/chat/completions\" # Or your LLM endpoint\n",
    "\n",
    "# Path to your Rhubarb executable\n",
    "# Example Windows: RHUBARB_EXECUTABLE = r\"C:\\Program Files\\Rhubarb-Lip-Sync-1.13.0-Windows\\rhubarb.exe\"\n",
    "# Example macOS/Linux (if in PATH): RHUBARB_EXECUTABLE = \"rhubarb\"\n",
    "# Example macOS (if downloaded): RHUBARB_EXECUTABLE = r\"/path/to/Rhubarb-Lip-Sync-1.13.0-macOS/rhubarb\"\n",
    "# Example Linux (if downloaded): RHUBARB_EXECUTABLE = r\"/path/to/Rhubarb-Lip-Sync-1.13.0-Linux/rhubarb\"\n",
    "RHUBARB_EXECUTABLE = r\"C:\\Rhubarb\\rhubarb.exe\" # Adjust this path!\n",
    "\n",
    "# Temporary file prefix and base name for TTS audio\n",
    "TTS_TEMP_PREFIX = \"temp_ai_speech_\"\n",
    "\n",
    "\n",
    "# Paths for existing data files\n",
    "IMAGE_DIR = \"images\"\n",
    "FIGURES_JSON = \"output.json\" # Assuming this maps figure references to descriptions and subchapters\n",
    "\n",
    "# Data for textual content (Ensure these JSON files exist and are correctly formatted)\n",
    "try:\n",
    "    with open(\"knowledgebase.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "        kb_data = json.load(f)\n",
    "    with open(\"metadata.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "        metadata = json.load(f)\n",
    "except FileNotFoundError as e:\n",
    "    print(f\"❌ Critical Error: Data file not found - {e}. Make sure knowledgebase.json and metadata.json are in the correct directory.\")\n",
    "    exit()\n",
    "except json.JSONDecodeError as e:\n",
    "    print(f\"❌ Critical Error: Could not decode data file - {e}. Check JSON file formatting.\")\n",
    "    exit()\n",
    "\n",
    "\n",
    "# Normalize function\n",
    "def normalize_title(title):\n",
    "    \"\"\"Normalizes titles for comparison.\"\"\"\n",
    "    return title.strip().lower()\n",
    "\n",
    "# Create normalized KB lookup for faster access\n",
    "normalized_kb = {}\n",
    "for chapter, topics in kb_data.items():\n",
    "    for title, content in topics.items():\n",
    "        norm_key = (chapter, normalize_title(title))\n",
    "        normalized_kb[norm_key] = content\n",
    "debug_print(f\"Loaded Knowledge Base with {len(normalized_kb)} entries.\", 2)\n",
    "\n",
    "\n",
    "# Initialize embedding model (for text search)\n",
    "try:\n",
    "    model = SentenceTransformer(\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model.to(device)\n",
    "    debug_print(f\"SentenceTransformer model loaded to {device}.\", 2)\n",
    "except Exception as e:\n",
    "    print(f\"❌ Critical Error: Could not load SentenceTransformer model: {e}\")\n",
    "    # Depending on criticality, you might exit or run in a limited mode\n",
    "    exit()\n",
    "\n",
    "\n",
    "# Load FAISS index (text) (Ensure this file exists)\n",
    "try:\n",
    "    index = faiss.read_index(\"textbook_faiss.index\")\n",
    "    debug_print(\"FAISS text index loaded.\", 2)\n",
    "except FileNotFoundError:\n",
    "    print(\"❌ Critical Error: FAISS text index 'textbook_faiss.index' not found. Run the indexing script first.\")\n",
    "    exit()\n",
    "except Exception as e:\n",
    "    print(f\"❌ Critical Error: Could not load FAISS text index: {e}\")\n",
    "    exit()\n",
    "\n",
    "\n",
    "# search function (for text content)\n",
    "def search(query, top_k=5, similarity_threshold=0.98, mode=\"hybrid\"):\n",
    "    \"\"\"\n",
    "    Searches the knowledge base using exact matching and/or semantic search (FAISS).\n",
    "    Returns relevant content entries.\n",
    "    \"\"\"\n",
    "    norm_query = normalize_title(query)\n",
    "    results = []\n",
    "    seen_embeddings = []\n",
    "    seen_titles = set() # Use set for faster lookups\n",
    "\n",
    "    debug_print(f\"Searching KB for query: '{query}' (Mode: {mode}, TopK: {top_k})\", 2)\n",
    "\n",
    "    def get_exact_matches():\n",
    "        exact_results = []\n",
    "        for item in metadata: # Iterate through metadata which is smaller\n",
    "            title = item[\"title\"]\n",
    "            chapter = item[\"chapter\"]\n",
    "            norm_title = normalize_title(title)\n",
    "            # Simple substring match in normalized title\n",
    "            if norm_query in norm_title:\n",
    "                 norm_key = (chapter, norm_title)\n",
    "                 content = normalized_kb.get(norm_key)\n",
    "                 if content:\n",
    "                     # Check if this exact content (by key) has already been added\n",
    "                     if norm_key not in seen_titles:\n",
    "                         debug_print(f\"Found exact/substring match: {title}\", 3)\n",
    "                         seen_titles.add(norm_key)\n",
    "                         exact_results.append({\n",
    "                             \"title_key\": title,\n",
    "                             \"chapter\": chapter,\n",
    "                             \"score\": 0.0, # Assign 0 score for exact match\n",
    "                             \"content\": content\n",
    "                         })\n",
    "                         # For exact matches, sometimes you only want the very first one\n",
    "                         # If you only want ONE exact match, uncomment the next line:\n",
    "                         # return exact_results\n",
    "        return exact_results\n",
    "\n",
    "\n",
    "    def get_semantic_matches():\n",
    "        semantic_results = []\n",
    "        try:\n",
    "            query_embedding = model.encode([query], convert_to_numpy=True).astype('float32')\n",
    "            # FAISS returns L2 distance, convert to similarity if needed, but distance is fine for thresholding\n",
    "            distances, indices = index.search(query_embedding, top_k)\n",
    "\n",
    "            for i in range(len(indices[0])):\n",
    "                idx = indices[0][i]\n",
    "                # Skip invalid indices if top_k is larger than index size\n",
    "                if idx == -1: continue\n",
    "\n",
    "                raw_title = metadata[idx][\"title\"]\n",
    "                chapter = metadata[idx][\"chapter\"]\n",
    "                norm_key = (chapter, normalize_title(raw_title))\n",
    "                content = normalized_kb.get(norm_key)\n",
    "                score = distances[0][i] # This is the L2 distance\n",
    "\n",
    "                # Only consider if content exists in KB and hasn't been added by exact match\n",
    "                if content and norm_key not in seen_titles:\n",
    "                    # Optional: Semantic de-duplication based on content embedding similarity\n",
    "                    # (This part from original code was complex; simplified here)\n",
    "                    # A more robust approach would require indexing chunks of content\n",
    "                    # For simplicity with title-level index, we rely on score and seen_titles\n",
    "                    debug_print(f\"Found semantic match candidate: {raw_title} (Score: {score:.4f})\", 3)\n",
    "                    seen_titles.add(norm_key) # Mark as seen to avoid adding same title multiple times\n",
    "                    semantic_results.append({\n",
    "                        \"title_key\": raw_title,\n",
    "                        \"chapter\": chapter,\n",
    "                        \"score\": score,\n",
    "                        \"content\": content\n",
    "                    })\n",
    "        except Exception as e:\n",
    "             print(f\"❌ Error during semantic search: {e}\")\n",
    "             # Return empty semantic results if an error occurs\n",
    "             return []\n",
    "\n",
    "        return semantic_results\n",
    "\n",
    "    # --- MODE HANDLING ---\n",
    "    if mode == \"exact\":\n",
    "        results = get_exact_matches()\n",
    "    elif mode == \"semantic\":\n",
    "        results = get_semantic_matches()\n",
    "    else:  # hybrid\n",
    "        # Prioritize exact matches\n",
    "        results = get_exact_matches()\n",
    "        # If no exact matches found, or if you want to blend, add semantic matches\n",
    "        if not results or mode == \"hybrid_blend\": # Added hybrid_blend idea\n",
    "             semantic_results = get_semantic_matches()\n",
    "             # Merge and sort if needed, or just append if exact matches are prioritized\n",
    "             if not results: # Only use semantic if no exact matches were found\n",
    "                 results = semantic_results\n",
    "             # If blending is desired, you'd merge results here, remove duplicates, and sort\n",
    "             # For simplicity, we'll stick to 'exact first, then semantic if no exact'\n",
    "             pass # Current logic already does this\n",
    "\n",
    "    debug_print(f\"Search returned {len(results)} results.\", 2)\n",
    "    return results\n",
    "\n",
    "# Function to generate a brief, general explanation (no KB search)\n",
    "# This is used for out-of-syllabus topics determined by is_in_syllabus\n",
    "def generate_general_explanation(topic):\n",
    "    \"\"\"Generates a brief, general explanation for a topic using the LLM (no KB search).\"\"\"\n",
    "    if not LLM_API_KEY or LLM_API_KEY == \"YOUR_GROQ_API_KEY\":\n",
    "         print(\"❌ LLM_API_KEY is not set. Cannot generate general explanation.\")\n",
    "         return f\"I can't give a general explanation of {topic} right now because my external knowledge service is not configured.\"\n",
    "\n",
    "    debug_print(f\"Generating general explanation for: {topic}\", 2)\n",
    "    prompt = f\"\"\"\n",
    "You are an AI science teacher providing a brief overview of a topic that is outside the current syllabus.\n",
    "Provide a clear, concise explanation of \"{topic}\" suitable for an 8th grader.\n",
    "Keep it brief, ideally 3-5 sentences.\n",
    "DO NOT mention specific textbook chapters, sections, or figures.\n",
    "DO NOT ask questions back.\n",
    "Output plain text only.\n",
    "\n",
    "Your General Explanation:\n",
    "\"\"\"\n",
    "    try:\n",
    "        response = requests.post(\n",
    "            LLM_API_URL,\n",
    "            headers={\"Authorization\": f\"Bearer {LLM_API_KEY}\"},\n",
    "            json={\n",
    "                \"model\": \"llama3-70b-8192\", # Or your preferred model\n",
    "                \"messages\": [{\"role\": \"user\", \"content\": prompt}],\n",
    "                \"max_tokens\": 200, # Limit tokens for brevity\n",
    "                \"temperature\": 0.7 # A bit creative but still factual\n",
    "            }\n",
    "        )\n",
    "        response.raise_for_status() # Raise HTTPError for bad responses (4xx or 5xx)\n",
    "        result = response.json()\n",
    "        if \"choices\" in result and result[\"choices\"]:\n",
    "            explanation_text = result[\"choices\"][0][\"message\"][\"content\"].strip()\n",
    "            debug_print(\"LLM generated general explanation.\", 3)\n",
    "            return explanation_text\n",
    "        else:\n",
    "            debug_print(f\"LLM response format issue for general explanation: {result}\", 3)\n",
    "            return f\"I can't give a detailed explanation of {topic} right now.\"\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"❌ Error calling LLM for general explanation: {e}\")\n",
    "        return \"Sorry, I encountered an error while trying to explain.\"\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Unexpected error during general explanation generation: {e}\")\n",
    "        return \"An unexpected error occurred.\"\n",
    "\n",
    "# Check if topic is \"in syllabus\" (based on search results and relevance threshold)\n",
    "def is_in_syllabus(query):\n",
    "    \"\"\"Checks if the query yields sufficiently relevant results from the knowledge base.\"\"\"\n",
    "    debug_print(f\"Checking if '{query}' is in syllabus (with threshold)...\", 2)\n",
    "\n",
    "    # You will need to tune this threshold value based on your data.\n",
    "    # A lower distance_threshold means the match must be more similar (closer).\n",
    "    # This threshold applies to the L2 distance returned by FAISS for semantic search.\n",
    "    # Exact matches (score 0.0) will always be considered in syllabus.\n",
    "    distance_threshold = 0.8 # Example distance threshold - lower is better. Needs tuning.\n",
    "\n",
    "    # Call the search function to get the best match and its score (distance)\n",
    "    # Use top_k=1 and hybrid mode to get the single best match (exact or semantic)\n",
    "    search_results = search(query, mode=\"hybrid\", top_k=1)\n",
    "\n",
    "    if search_results: # Check if search returned any result\n",
    "        best_match = search_results[0]\n",
    "        best_score = best_match[\"score\"] # This is the distance (0.0 for exact match)\n",
    "        syllabus_content = best_match[\"content\"]\n",
    "        cleaned_title = re.sub(r\"^\\d+(\\.\\d+)\\s\", \"\", best_match[\"title_key\"]).strip()\n",
    "\n",
    "        debug_print(f\"Best match found: '{best_match['title_key']}' (Score: {best_score:.4f}) (Threshold: {distance_threshold})\", 2)\n",
    "\n",
    "        # Check if it's an exact match (score is 0.0) or the distance is below the threshold\n",
    "        if best_score == 0.0 or best_score < distance_threshold:\n",
    "            debug_print(\"Found sufficiently relevant syllabus content.\", 2)\n",
    "            # Return True, the content, and the cleaned topic title\n",
    "            return True, syllabus_content, cleaned_title\n",
    "        else:\n",
    "            debug_print(\"Closest match score is above the distance threshold. Not considered in syllabus.\", 2)\n",
    "            return False, None, None\n",
    "    else:\n",
    "        debug_print(\"No results found by search function.\", 2) # Should rarely happen with top_k=1 unless index is empty\n",
    "        return False, None, None\n",
    "\n",
    "\n",
    "# Groq LLM API configuration (already done above with user config)\n",
    "# LLM_API_KEY = \"...\"\n",
    "# LLM_API_URL = \"...\"\n",
    "\n",
    "# Load figures data (Keep)\n",
    "try:\n",
    "    figures_data = json.load(open(FIGURES_JSON, \"r\", encoding=\"utf-8\"))\n",
    "    debug_print(f\"Loaded Figures data with {len(figures_data)} entries.\", 2)\n",
    "except FileNotFoundError:\n",
    "    debug_print(f\"Warning: Figures JSON file '{FIGURES_JSON}' not found. Figure fetching will not work.\", 2)\n",
    "    figures_data = [] # Set to empty list if file is missing\n",
    "except json.JSONDecodeError as e:\n",
    "    print(f\"❌ Error loading figures JSON '{FIGURES_JSON}': {e}. Figure fetching may not work.\")\n",
    "    figures_data = []\n",
    "\n",
    "\n",
    "# Initialize image model & FAISS (figures) - Keep if still needed for image search\n",
    "# Note: The current code doesn't seem to *use* the image FAISS index directly in the voice flow,\n",
    "# but keeping the loading logic if it's part of the larger project.\n",
    "try:\n",
    "    # Reuse the existing model if it's the same type, otherwise load a new one\n",
    "    # Assuming image_model is same as model for simplicity based on original code\n",
    "    image_model = model # Reuse the already loaded text model\n",
    "    debug_print(\"Reusing text SentenceTransformer model for image search (assuming same).\", 2)\n",
    "except Exception as e:\n",
    "    print(f\"❌ Critical Error: Could not prepare image model: {e}\")\n",
    "    # Decide if this is critical or if the voice agent can run without image search\n",
    "    # For this voice-only context, maybe not critical.\n",
    "\n",
    "FAISS_INDEX_FILE_FIGURES = \"subchapter_faiss.index\" # Renamed to avoid conflict\n",
    "METADATA_FILE_FIGURES = \"subchapter_metadata.json\" # Renamed to avoid conflict\n",
    "\n",
    "# Load figure metadata and index (Keep if still needed)\n",
    "index_figures = None\n",
    "metadata_figures = {}\n",
    "try:\n",
    "    if os.path.exists(FAISS_INDEX_FILE_FIGURES) and os.path.exists(METADATA_FILE_FIGURES):\n",
    "        index_figures = faiss.read_index(FAISS_INDEX_FILE_FIGURES)\n",
    "        with open(METADATA_FILE_FIGURES, \"r\", encoding=\"utf-8\") as f:\n",
    "            metadata_figures = json.load(f)\n",
    "        debug_print(\"FAISS figures index and metadata loaded.\", 2)\n",
    "    else:\n",
    "        debug_print(f\"Warning: Figures index '{FAISS_INDEX_FILE_FIGURES}' or metadata '{METADATA_FILE_FIGURES}' not found. Figure search will not work.\", 2)\n",
    "except Exception as e:\n",
    "    print(f\"❌ Error loading figure FAISS index or metadata: {e}. Figure search may not work.\")\n",
    "    index_figures = None # Ensure index is None if loading fails\n",
    "\n",
    "\n",
    "# search_exact_subchapter function (Keep if needed, though role in voice flow unclear)\n",
    "def search_exact_subchapter(query, top_k=1):\n",
    "    \"\"\"Find the most relevant subchapter using FAISS (for figures).\"\"\"\n",
    "    if index_figures is None or image_model is None:\n",
    "        debug_print(\"Figure search index or model not available.\", 2)\n",
    "        return None\n",
    "\n",
    "    debug_print(f\"Searching for exact subchapter match (for figures): {query}\", 2)\n",
    "    try:\n",
    "        query_embedding = image_model.encode([query], convert_to_numpy=True).astype('float32')\n",
    "        # Reshape for a single query\n",
    "        distances, indices = index_figures.search(query_embedding.reshape(1, -1), top_k)\n",
    "        # Pick only the closest match\n",
    "        best_match_index_str = str(indices[0][0]) # Index from FAISS is int, metadata key is string\n",
    "        best_subchapter = metadata_figures.get(best_match_index_str, None)\n",
    "        debug_print(f\"Best match subchapter for figures: {best_subchapter}\", 3)\n",
    "        return best_subchapter\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Error during figure subchapter search: {e}\")\n",
    "        return None\n",
    "\n",
    "\n",
    "# get_image_path function (Keep if needed)\n",
    "def get_image_path(figure_ref):\n",
    "    \"\"\"Find image path with multiple fallback patterns.\"\"\"\n",
    "    if not IMAGE_DIR or not os.path.exists(IMAGE_DIR):\n",
    "        debug_print(f\"Image directory '{IMAGE_DIR}' not found. Cannot get image path.\", 2)\n",
    "        return None\n",
    "\n",
    "    debug_print(f\"Locating image for: {figure_ref}\", 2)\n",
    "    base_name = figure_ref.replace(\" \", \"_\").replace(\":\", \"_\").replace(\"/\", \"_\") # Sanitize figure_ref for filenames\n",
    "    attempts = [\n",
    "        f\"{base_name}.png\",\n",
    "        f\"{base_name}.jpg\",\n",
    "        f\"figure_{base_name}.png\",\n",
    "        f\"figure_{base_name}.jpg\"\n",
    "    ]\n",
    "    for attempt in attempts:\n",
    "        test_path = os.path.join(IMAGE_DIR, attempt)\n",
    "        if os.path.exists(test_path):\n",
    "            debug_print(f\"✅ Found image at: {test_path}\", 3)\n",
    "            return test_path\n",
    "    debug_print(\"❌ No valid image path found\", 3)\n",
    "    return None\n",
    "\n",
    "\n",
    "# fetch_figures_only function (Keep if needed)\n",
    "def fetch_figures_only(subchapter_name): # Changed parameter name to be more explicit\n",
    "    \"\"\"Retrieve only figures (images + raw descriptions) for a given subchapter.\"\"\"\n",
    "    if not figures_data:\n",
    "         debug_print(\"Figures data not loaded. Cannot retrieve figures.\", 2)\n",
    "         return \"Figure data is not available.\"\n",
    "\n",
    "    debug_print(f\"Retrieving figures for subchapter: {subchapter_name}\", 2)\n",
    "    figures = [fig for fig in figures_data if fig.get(\"subchapter\") == subchapter_name] # Use .get for safety\n",
    "    if not figures:\n",
    "        debug_print(f\"No relevant figures found for subchapter: {subchapter_name}\", 2)\n",
    "        return \"No relevant figures found.\"\n",
    "\n",
    "    figure_blocks = []\n",
    "    for fig in figures:\n",
    "        fig_path = get_image_path(fig.get('figure')) # Use .get for safety\n",
    "        if fig_path:\n",
    "            figure_blocks.append({\n",
    "                \"name\": fig.get('figure', 'N/A'), # Use .get for safety\n",
    "                \"path\": fig_path,\n",
    "                \"desc\": fig.get('description', '') # Use .get for safety, default to empty string\n",
    "            })\n",
    "    debug_print(f\"Found {len(figure_blocks)} figures with paths.\", 2)\n",
    "    return figure_blocks\n",
    "\n",
    "# retrieve_and_expand_figures function (generates HTML, less relevant for voice - Keep but likely not used in voice loop)\n",
    "def retrieve_and_expand_figures(query):\n",
    "    \"\"\"\n",
    "    Retrieve figures related to the query by using the title of the\n",
    "    most relevant text content and generate HTML to display them.\n",
    "    \"\"\"\n",
    "    debug_print(f\"Retrieving and formatting figures for query: {query}\", 2)\n",
    "    # Find the most relevant text content first to get a potential subchapter name\n",
    "    search_results = search(query, mode=\"hybrid\", top_k=1)\n",
    "    if not search_results:\n",
    "        debug_print(\"No relevant text found for image retrieval.\", 2)\n",
    "        return \"<p>No relevant text found for image retrieval.</p>\"\n",
    "\n",
    "    best_text_match = search_results[0]\n",
    "    subchapter_name = best_text_match[\"title_key\"] # Use the title_key as the subchapter name\n",
    "\n",
    "    blocks = fetch_figures_only(subchapter_name)\n",
    "\n",
    "    if isinstance(blocks, str):\n",
    "        # An error message was returned by fetch_figures_only\n",
    "        debug_print(f\"fetch_figures_only returned an error: {blocks}\", 2)\n",
    "        return f\"<p>{blocks}</p>\"\n",
    "\n",
    "    if not blocks:\n",
    "         debug_print(\"No figure blocks returned after fetch.\", 2)\n",
    "         return \"<p>No relevant figures found.</p>\"\n",
    "\n",
    "    figure_html = \"<div style='margin-top: 20px;'><h3>📊 Visual Aids</h3>\"\n",
    "    # Limit to 3 figures for display in a web/HTML context\n",
    "    for fig in blocks[:3]:\n",
    "        # Optional: you might want to generate a short spoken description here for the voice agent\n",
    "        clean_desc = fig['desc'] # Optionally, you can process the description further for HTML\n",
    "        figure_html += f\"\"\"\n",
    "        <div style='margin-bottom: 20px; border: 1px solid #ddd; padding: 10px; border-radius: 5px;'>\n",
    "            <img src='{fig['path']}' style='max-width: 100%; height: auto; display: block; margin: 0 auto;'>\n",
    "            <p style='text-align: center; font-style: italic;'>{clean_desc or 'Visual demonstration'}</p>\n",
    "        </div>\n",
    "        \"\"\"\n",
    "    figure_html += \"</div>\"\n",
    "    debug_print(\"Generated figure HTML.\", 2)\n",
    "    return figure_html\n",
    "\n",
    "# fetch_animated_videos function (keep for potential future use in voice flow)\n",
    "def fetch_animated_videos(topic, num_videos=1):\n",
    "    \"\"\"Searches YouTube for short educational animations related to the topic.\"\"\"\n",
    "    search_query = f\"ytsearch{num_videos}:{topic} animation explained in english\"\n",
    "    debug_print(f\"Searching YouTube for: {search_query}\", 2)\n",
    "\n",
    "    ydl_opts = {\n",
    "        \"quiet\": True,\n",
    "        \"extract_flat\": True, # Get minimal info quickly\n",
    "        \"force_generic_extractor\": True, # Avoids issues with some URLs\n",
    "        \"skip_download\": True, # Never download\n",
    "        \"geo_bypass\": True, # Attempt to bypass geo-restrictions\n",
    "    }\n",
    "\n",
    "    try:\n",
    "        with yt_dlp.YoutubeDL(ydl_opts) as ydl:\n",
    "            info = ydl.extract_info(search_query, download=False)\n",
    "\n",
    "        if info and \"entries\" in info and len(info[\"entries\"]) > 0:\n",
    "             # Filter for short videos\n",
    "            short_videos = [\n",
    "                video for video in info[\"entries\"]\n",
    "                if video.get(\"duration\", 301) is not None and video.get(\"duration\", 301) <= 300 # Check if duration exists and is <= 300s\n",
    "            ]\n",
    "            if short_videos:\n",
    "                video = short_videos[0] # Pick the first short one\n",
    "                debug_print(f\"Found relevant short video: {video.get('title', 'Untitled')}\", 2)\n",
    "                return {\n",
    "                    \"title\": video.get(\"title\", \"Untitled Video\"),\n",
    "                    \"url\": video.get(\"url\", f\"https://www.youtube.com/watch?v={video.get('id')}\"), # Construct URL if missing\n",
    "                    \"id\": video.get(\"id\")\n",
    "                }\n",
    "            else:\n",
    "                 debug_print(\"No short videos found matching the search criteria.\", 2)\n",
    "\n",
    "        debug_print(\"No video entries found.\", 2)\n",
    "        return None\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Error fetching animated videos: {e}\")\n",
    "        return None\n",
    "\n",
    "\n",
    "# generate_topic_hook function (Keep for potential use in spoken explanation intro)\n",
    "def generate_topic_hook(topic):\n",
    "    \"\"\"Generate a short, engaging hook for the topic using the LLM.\"\"\"\n",
    "    if not LLM_API_KEY or LLM_API_KEY == \"YOUR_GROQ_API_KEY\":\n",
    "         print(\"❌ LLM_API_KEY is not set. Cannot generate topic hook.\")\n",
    "         return f\"Let's dive into {topic}!\" # Simple fallback\n",
    "\n",
    "    debug_print(f\"Generating topic hook for: {topic}\", 2)\n",
    "    prompt = f\"\"\"\n",
    "You are a science educator. Create a SHORT (1-2 sentences), engaging hook for the topic *{topic}* for 8th-grade students using one of these techniques:\n",
    "- A surprising fact/question\n",
    "- A relatable analogy/metaphor\n",
    "- A real-world application\n",
    "- A mini thought experiment\n",
    "\n",
    "Return ONLY the hook.\n",
    "\"\"\"\n",
    "    try:\n",
    "        response = requests.post(\n",
    "            LLM_API_URL,\n",
    "            headers={\"Authorization\": f\"Bearer {LLM_API_KEY}\"},\n",
    "            json={\n",
    "                \"model\": \"llama3-70b-8192\", # Or your preferred model\n",
    "                \"messages\": [{\"role\": \"user\", \"content\": prompt}],\n",
    "                \"max_tokens\": 100, # Sufficient for 1-2 sentences\n",
    "                \"temperature\": 0.9 # High temp for creativity\n",
    "            }\n",
    "        )\n",
    "        response.raise_for_status()\n",
    "        result = response.json()\n",
    "        if \"choices\" in result and result[\"choices\"]:\n",
    "            hook = result[\"choices\"][0][\"message\"][\"content\"].strip()\n",
    "            debug_print(\"LLM generated topic hook.\", 3)\n",
    "            return hook\n",
    "        else:\n",
    "             debug_print(f\"LLM response format issue for hook: {result}\", 3)\n",
    "             return f\"Let's learn about {topic}!\" # Simple fallback\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"❌ Error calling LLM for topic hook: {e}\")\n",
    "        return f\"Ready to explore {topic}?\" # Error fallback\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Unexpected error during hook generation: {e}\")\n",
    "        return f\"Discover {topic} with me!\" # Error fallback\n",
    "\n",
    "# generate_funny_intro function (Keep for potential use)\n",
    "def generate_funny_intro(topic):\n",
    "    \"\"\"Generate an introduction that begins with a funny story or meme about the topic using the LLM.\"\"\"\n",
    "    if not LLM_API_KEY or LLM_API_KEY == \"YOUR_GROQ_API_KEY\":\n",
    "         print(\"❌ LLM_API_KEY is not set. Cannot generate funny intro.\")\n",
    "         return \"Let's start with a little something about science.\" # Simple fallback\n",
    "\n",
    "    debug_print(f\"Generating funny intro for: {topic}\", 2)\n",
    "    prompt = f\"\"\"\n",
    "You are a creative and humorous science educator. Tell a short, funny story or describe a relatable meme about *{topic}* to engage 8th-grade students. Avoid using video introductions. Return ONLY the story.\n",
    "\"\"\"\n",
    "    try:\n",
    "        response = requests.post(\n",
    "            LLM_API_URL,\n",
    "            headers={\"Authorization\": f\"Bearer {LLM_API_KEY}\"},\n",
    "            json={\n",
    "                \"model\": \"llama3-70b-8192\", # Or your preferred model\n",
    "                \"messages\": [{\"role\": \"user\", \"content\": prompt}],\n",
    "                \"max_tokens\": 200, # Allow a short story\n",
    "                \"temperature\": 0.9 # High temp for humor\n",
    "            }\n",
    "        )\n",
    "        response.raise_for_status()\n",
    "        result = response.json()\n",
    "        if \"choices\" in result and result[\"choices\"]:\n",
    "            funny_intro = result[\"choices\"][0][\"message\"][\"content\"].strip()\n",
    "            debug_print(\"LLM generated funny intro.\", 3)\n",
    "            return funny_intro\n",
    "        else:\n",
    "             debug_print(f\"LLM response format issue for funny intro: {result}\", 3)\n",
    "             return \"Here's a fun fact to get started.\" # Simple fallback\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"❌ Error calling LLM for funny intro: {e}\")\n",
    "        return \"Let's kick off our lesson with something fun!\" # Error fallback\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Unexpected error during funny intro generation: {e}\")\n",
    "        return \"Prepare for some science fun!\" # Error fallback\n",
    "\n",
    "\n",
    "# generate_dynamic_intro function (generates HTML, less relevant for voice - Keep but likely not used)\n",
    "def generate_dynamic_intro(topic):\n",
    "    \"\"\"Generate an introductory paragraph with a funny story or meme (for HTML display).\"\"\"\n",
    "    funny_intro = generate_funny_intro(topic)\n",
    "    hook = generate_topic_hook(topic)\n",
    "    return f\"\"\"\n",
    "<p>{funny_intro}</p>\n",
    "<p>{hook}</p>\n",
    "<p>Today, we're exploring the fascinating world of <strong>{topic}</strong>! 🔍<br>\n",
    "Quick prediction: What do you think happens when...? Let's find out in our lesson!</p>\n",
    "\"\"\"\n",
    "\n",
    "# --- NEW VOICE AGENT CORE FUNCTIONS ---\n",
    "\n",
    "# 1. Text-to-Speech (TTS) Function (Handled within speak now)\n",
    "\n",
    "# 2. Speech-to-Text (ASR) Function\n",
    "def listen_to_student(timeout_seconds=8, phrase_time_limit_seconds=5): # Adjusted timeout slightly\n",
    "    \"\"\"Listens for student's speech using the microphone.\"\"\"\n",
    "    r = sr.Recognizer()\n",
    "    r.energy_threshold = 4000 # Adjust if needed, higher means less sensitive to quiet sounds\n",
    "    r.dynamic_energy_threshold = True # Recommended by speech_recognition docs\n",
    "    # r.pause_threshold = 0.8 # Seconds of non-speaking audio before a phrase is considered complete\n",
    "    # r.operation_timeout = 5 # Max seconds the recognizer will wait for a phrase to start\n",
    "\n",
    "    with sr.Microphone() as source:\n",
    "        # Adjust for ambient noise - Do this once at the start of the application if possible\n",
    "        # or if the environment changes significantly. Doing it repeatedly can cause issues.\n",
    "        # r.adjust_for_ambient_noise(source, duration=1)\n",
    "        # debug_print(f\"Adjusted for ambient noise. Energy threshold: {r.energy_threshold}\", 3)\n",
    "\n",
    "        debug_print(\"Listening for student...\", 2)\n",
    "        # Ensure mouth is in listening/idle pose\n",
    "        set_mouth_pose(\"X\") # Set mouth to Rest/Idle\n",
    "\n",
    "        print(\"🎤 (Speak now)\") # User feedback\n",
    "        try:\n",
    "            # Listen with timeout and phrase time limit\n",
    "            audio = r.listen(source, timeout=timeout_seconds, phrase_time_limit=phrase_time_limit_seconds)\n",
    "            debug_print(\"Processing speech...\", 2)\n",
    "            # Ensure mouth goes back to idle/processing pose while thinking\n",
    "            set_mouth_pose(\"X\") # Set mouth to Rest/Idle while processing\n",
    "\n",
    "            # Recognize speech using Google Web Speech API\n",
    "            text = r.recognize_google(audio)\n",
    "            debug_print(f\"Student said: {text}\", 2)\n",
    "            print(f\"👂 You said: {text}\") # User feedback\n",
    "            return text.lower() # Return lowercase for easier processing\n",
    "        except sr.WaitTimeoutError:\n",
    "            debug_print(\"No speech detected within timeout.\", 2)\n",
    "            print(\"묵 No speech detected.\")\n",
    "            return None\n",
    "        except sr.UnknownValueError:\n",
    "            debug_print(\"Google Speech Recognition could not understand audio.\", 2)\n",
    "            print(\"❓ Sorry, I couldn't understand that.\")\n",
    "            return None\n",
    "        except sr.RequestError as e:\n",
    "            debug_print(f\"Could not request results from Google Speech Recognition service; {e}\", 2)\n",
    "            print(f\"🚫 Could not connect to speech service: {e}\")\n",
    "            return None\n",
    "        except Exception as e:\n",
    "            print(f\"❌ An unexpected error occurred during listening: {e}\")\n",
    "            return None\n",
    "        finally:\n",
    "             # Ensure mouth is reset after listening attempt finishes\n",
    "             set_mouth_pose(\"X\")\n",
    "\n",
    "\n",
    "# 3. Natural Language Understanding (NLU) Function (using LLM)\n",
    "def understand_intent_and_topic(text):\n",
    "    \"\"\"Uses the LLM to determine intent and extract the topic from student input.\"\"\"\n",
    "    if not text:\n",
    "        debug_print(\"NLU received empty text.\", 2)\n",
    "        return \"NO_INPUT\", None # Explicitly handle empty input\n",
    "\n",
    "    if not LLM_API_KEY or LLM_API_KEY == \"YOUR_GROQ_API_KEY\":\n",
    "         print(\"❌ LLM_API_KEY is not set. Cannot perform NLU.\")\n",
    "         return \"ERROR\", None\n",
    "\n",
    "    debug_print(f\"Sending NLU request to LLM for text: '{text}'\", 2)\n",
    "    prompt = f\"\"\"\n",
    "Analyze the following student input to identify the primary intent and the specific topic or question.\n",
    "Input: \"{text}\"\n",
    "\n",
    "Possible Intents:\n",
    "- REQUEST_EXPLANATION (e.g., \"tell me about X\", \"explain Y\")\n",
    "- ASK_QUESTION (e.g., \"what is X?\", \"how does Y work?\", \"why is Z like that?\")\n",
    "- GREETING (e.g., \"hello\", \"hi\")\n",
    "- FAREWELL (e.g., \"goodbye\", \"bye\")\n",
    "- RESUME (e.g., \"resume\", \"continue\", \"go on\")\n",
    "- OTHER (If none of the above fit)\n",
    "- REPHRASE (e.g., \"say that again\", \"repeat\") # Added REPHRASE intent\n",
    "\n",
    "Identify the main intent and extract the core topic or question discussed.\n",
    "\n",
    "Return the result ONLY as a JSON object with keys \"intent\" and \"topic_or_question\".\n",
    "If no specific topic is mentioned for explanation or question, set \"topic_or_question\" to null.\n",
    "If the intent is GREETING, FAREWELL, RESUME, REPHRASE, or OTHER, set \"topic_or_question\" to null.\n",
    "\n",
    "Example 1:\n",
    "Input: \"Explain magnetic fields\"\n",
    "Output: {{\"intent\": \"REQUEST_EXPLANATION\", \"topic_or_question\": \"magnetic fields\"}}\n",
    "\n",
    "Example 2:\n",
    "Input: \"hi there\"\n",
    "Output: {{\"intent\": \"GREETING\", \"topic_or_question\": null}}\n",
    "\n",
    "Example 3:\n",
    "Input: \"why is the sky blue?\"\n",
    "Output: {{\"intent\": \"ASK_QUESTION\", \"topic_or_question\": \"why is the sky blue?\"}}\n",
    "\n",
    "Example 4:\n",
    "Input: \"tell me more\"\n",
    "Output: {{\"intent\": \"REQUEST_EXPLANATION\", \"topic_or_question\": null}} # No specific topic\n",
    "\n",
    "Example 5:\n",
    "Input: \"resume\"\n",
    "Output: {{\"intent\": \"RESUME\", \"topic_or_question\": null}}\n",
    "\n",
    "Example 6:\n",
    "Input: \"repeat that\"\n",
    "Output: {{\"intent\": \"REPHRASE\", \"topic_or_question\": null}}\n",
    "\n",
    "Input to analyze: \"{text}\"\n",
    "Output:\n",
    "\"\"\"\n",
    "    try:\n",
    "        response = requests.post(\n",
    "            LLM_API_URL,\n",
    "            headers={\"Authorization\": f\"Bearer {LLM_API_KEY}\"},\n",
    "            json={\n",
    "                \"model\": \"llama3-70b-8192\", # Or your preferred model\n",
    "                \"messages\": [{\"role\": \"user\", \"content\": prompt}],\n",
    "                \"max_tokens\": 100, # Should be plenty for the JSON\n",
    "                \"temperature\": 0.0, # Use 0.0 for deterministic classification\n",
    "                \"response_format\": {\"type\": \"json_object\"} # Request JSON output if API supports\n",
    "            }\n",
    "        )\n",
    "        response.raise_for_status() # Raise HTTPError for bad responses (4xx or 5xx)\n",
    "        result = response.json()\n",
    "\n",
    "        # Extract JSON content - handle potential variations in LLM output\n",
    "        json_string = result[\"choices\"][0][\"message\"][\"content\"].strip()\n",
    "        # Sometimes LLMs wrap JSON in backticks or ```json ... ```\n",
    "        json_string = re.sub(r\"^```json\\s*\", \"\", json_string)\n",
    "        json_string = re.sub(r\"\\s*```$\", \"\", json_string)\n",
    "\n",
    "        debug_print(f\"NLU Raw Response: {json_string}\", 3)\n",
    "\n",
    "        parsed_result = json.loads(json_string)\n",
    "        intent = parsed_result.get(\"intent\")\n",
    "        topic = parsed_result.get(\"topic_or_question\")\n",
    "        debug_print(f\"NLU Parsed: Intent={intent}, Topic={topic}\", 2)\n",
    "        return intent, topic\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"❌ Error calling LLM for NLU: {e}\")\n",
    "        return \"ERROR\", None\n",
    "    except json.JSONDecodeError as e:\n",
    "        print(f\"❌ Error decoding NLU JSON response: {e}\")\n",
    "        print(f\"Raw response was: {json_string}\") # Log the problematic response\n",
    "        return \"ERROR\", None\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Unexpected error during NLU: {e}\")\n",
    "        return \"ERROR\", None\n",
    "\n",
    "\n",
    "# 4. Function to Generate Spoken Explanation (Adapting existing logic)\n",
    "# This function decides *what content* to generate based on syllabus check\n",
    "def generate_spoken_explanation(topic_query):\n",
    "     \"\"\"\n",
    "     Generates the text for a spoken explanation based on syllabus check.\n",
    "     Decides between detailed KB-based explanation or general LLM explanation.\n",
    "     Returns the explanation text and the cleaned topic title (if found in syllabus).\n",
    "     \"\"\"\n",
    "     debug_print(f\"Preparing spoken explanation for topic query: {topic_query}\", 2)\n",
    "\n",
    "     # Check if the topic is in the syllabus using the refined function\n",
    "     in_syllabus, syllabus_content, cleaned_title = is_in_syllabus(topic_query)\n",
    "\n",
    "     if not in_syllabus:\n",
    "         debug_print(f\"Topic '{topic_query}' not found in syllabus based on threshold.\", 2)\n",
    "         # Generate a general explanation using the original query\n",
    "         explanation_text = generate_general_explanation(topic_query)\n",
    "         # We don't have a syllabus title for out-of-syllabus topics\n",
    "         return explanation_text, None, False\n",
    "     else:\n",
    "         debug_print(f\"Topic '{topic_query}' found in syllabus as '{cleaned_title}'.\", 2)\n",
    "         # Generate the full, rich lesson text based on the syllabus content\n",
    "         # The generate_full_lesson_text function handles adding intro/hook etc.\n",
    "         explanation_text = generate_full_lesson_text(topic_query) # Pass the original query or cleaned_title? Let's pass original query, generate_full_lesson_text will re-search/confirm\n",
    "         # Pass the cleaned title back for context saving\n",
    "         return explanation_text, cleaned_title, True\n",
    "\n",
    "\n",
    "# Function to generate the full, rich lesson text for voice (from previous turn)\n",
    "# This function is now called *after* is_in_syllabus check confirms content exists\n",
    "def generate_full_lesson_text(topic_query):\n",
    "    \"\"\"\n",
    "    Retrieves relevant content (already confirmed by is_in_syllabus),\n",
    "    generates intro/hook, and uses LLM to create a rich, expanded explanation\n",
    "    based on textbook content for voice output.\n",
    "    \"\"\"\n",
    "    if not LLM_API_KEY or LLM_API_KEY == \"YOUR_GROQ_API_KEY\":\n",
    "         print(\"❌ LLM_API_KEY is not set. Cannot generate full lesson text.\")\n",
    "         return \"I cannot generate a detailed lesson right now.\"\n",
    "\n",
    "\n",
    "    debug_print(f\"Generating full lesson text for syllabus topic: {topic_query}\", 2)\n",
    "\n",
    "    # Re-run search *just to get the content and cleaned title reliably* now that we know it's in syllabus\n",
    "    # This avoids passing large content strings around unnecessarily if called from generate_spoken_explanation\n",
    "    search_results = search(topic_query, mode=\"hybrid\", top_k=1)\n",
    "    if not search_results:\n",
    "         # This case should theoretically not happen if called after a successful is_in_syllabus\n",
    "         debug_print(\"Error: generate_full_lesson_text called but search found no content.\", 1)\n",
    "         return \"Sorry, I had trouble retrieving the lesson details.\"\n",
    "\n",
    "    best_match = search_results[0]\n",
    "    retrieved_content = best_match[\"content\"]\n",
    "    cleaned_title = re.sub(r\"^\\d+(\\.\\d+)\\s\", \"\", best_match[\"title_key\"]).strip()\n",
    "    debug_print(f\"Using retrieved content for lesson '{cleaned_title}'\", 2)\n",
    "\n",
    "    # 2. Generate Intro and Hook (re-using existing functions)\n",
    "    funny_intro = generate_funny_intro(cleaned_title)\n",
    "    hook = generate_topic_hook(cleaned_title)\n",
    "\n",
    "    # 3. Combine Intro, Hook, and Textbook Content for LLM Prompt\n",
    "    # Create a prompt that guides the LLM to act as a teacher and expand\n",
    "    prompt_text = f\"\"\"\n",
    "You are an engaging, fun-loving, and knowledgeable 8th-grade science teacher speaking directly to a student.\n",
    "\n",
    "Start with an engaging introduction similar to this (do not include explicit labels like 'Funny Story' or 'Hook'):\n",
    "\"{funny_intro}\"\n",
    "\"{hook}\"\n",
    "\"Today, we're exploring the fascinating world of {cleaned_title}!\"\n",
    "\n",
    "Then, based only on the following textbook content, provide a detailed, smooth, and engaging explanation for voice:\n",
    "- Expand each idea from the textbook content with real-life analogies, fun facts, surprising trivia, and interesting stories kids can relate to.\n",
    "- Break down complex terms into simple, visual language.\n",
    "- Ensure smooth transitions between different points.\n",
    "- DO NOT include HTML tags. Output plain text only.\n",
    "- DO NOT include explicit section headers like \"Introduction\", \"Explanation\", etc. just make it flow naturally.\n",
    "- DO NOT include greetings or sign-offs at the very beginning or end of the overall response.\n",
    "\n",
    "Textbook Content:\n",
    "\"{retrieved_content}\"\n",
    "\n",
    "Your Spoken Explanation:\n",
    "\"\"\"\n",
    "    debug_print(\"Sending LLM request for full lesson explanation...\", 2)\n",
    "    try:\n",
    "        response = requests.post(\n",
    "            LLM_API_URL,\n",
    "            headers={\"Authorization\": f\"Bearer {LLM_API_KEY}\"},\n",
    "            json={\n",
    "                \"model\": \"llama3-70b-8192\", # Use a capable model\n",
    "                \"messages\": [{\"role\": \"user\", \"content\": prompt_text}],\n",
    "                \"max_tokens\": 1500, # Allow for a longer explanation\n",
    "                \"temperature\": 0.8 # Use a higher temp for more creativity/engagement\n",
    "            }\n",
    "        )\n",
    "        response.raise_for_status()\n",
    "        result = response.json()\n",
    "        if \"choices\" in result and result[\"choices\"]:\n",
    "            explanation_text = result[\"choices\"][0][\"message\"][\"content\"].strip()\n",
    "            debug_print(\"LLM generated full lesson text.\", 3)\n",
    "            return explanation_text\n",
    "        else:\n",
    "            debug_print(f\"LLM response format issue for lesson: {result}\", 3)\n",
    "            return f\"I found information on {cleaned_title}, but had trouble creating a detailed lesson right now.\"\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"❌ Error calling LLM for lesson generation: {e}\")\n",
    "        return \"Sorry, I encountered an error while preparing the lesson explanation.\"\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Unexpected error during lesson generation: {e}\")\n",
    "        return \"An unexpected error occurred while creating the lesson.\"\n",
    "\n",
    "\n",
    "# 5. Function to Generate Spoken Answer (for QA)\n",
    "def generate_spoken_answer(question, context_content=None):\n",
    "    \"\"\"\n",
    "    Generates a concise spoken answer (ideally 2-4 sentences) to a student's question\n",
    "    using the LLM, optionally using retrieved context.\n",
    "    \"\"\"\n",
    "    if not LLM_API_KEY or LLM_API_KEY == \"YOUR_GROQ_API_KEY\":\n",
    "         print(\"❌ LLM_API_KEY is not set. Cannot generate spoken answer.\")\n",
    "         return \"I cannot answer questions right now.\"\n",
    "\n",
    "    debug_print(f\"Generating concise spoken answer for question: '{question}'\", 2)\n",
    "\n",
    "    prompt = f\"\"\"\n",
    "You are an AI science teacher answering a student's question. Provide a clear, concise answer suitable for an 8th grader.\n",
    "The answer MUST be brief, ideally *2 to 4 sentences long*.\n",
    "DO NOT ask questions back.\n",
    "Output plain text only.\n",
    "\n",
    "Student's Question: \"{question}\"\n",
    "\n",
    "Context from knowledge base (if available and deemed relevant by search):\n",
    "\"{context_content if context_content else 'No specific syllabus context found for this question. Answer from general knowledge.'}\"\n",
    "\n",
    "Your Concise Spoken Answer (2-4 sentences):\n",
    "\"\"\"\n",
    "    debug_print(\"Sending LLM request for concise answer...\", 2)\n",
    "    try:\n",
    "        response = requests.post(\n",
    "            LLM_API_URL,\n",
    "            headers={\"Authorization\": f\"Bearer {LLM_API_KEY}\"},\n",
    "            json={\n",
    "                \"model\": \"llama3-70b-8192\", # Or your preferred model\n",
    "                \"messages\": [{\"role\": \"user\", \"content\": prompt}],\n",
    "                \"max_tokens\": 150, # Limit tokens to encourage brevity (adjust if needed)\n",
    "                \"temperature\": 0.6 # Keep it factual\n",
    "            }\n",
    "        )\n",
    "        response.raise_for_status() # Raise HTTPError for bad responses (4xx or 5xx)\n",
    "        result = response.json()\n",
    "        if \"choices\" in result and result[\"choices\"]:\n",
    "            answer_text = result[\"choices\"][0][\"message\"][\"content\"].strip()\n",
    "            # Simple check to try and enforce sentence count (LLM might ignore) - This is a fallback\n",
    "            # Use NLTK for more robust sentence splitting\n",
    "            sentences = split_into_sentences(answer_text)\n",
    "            if len(sentences) > 4:\n",
    "                debug_print(f\"Answer text generated {len(sentences)} sentences, truncating to 4.\", 3)\n",
    "                answer_text = \". \".join(sentences[:4]).strip() + (\"...\" if len(sentences) > 4 else \"\") # Join first 4 and add ellipsis if more existed\n",
    "            else:\n",
    "                answer_text = \". \".join(sentences).strip() # Join back just in case splitting changed anything\n",
    "\n",
    "            debug_print(f\"LLM generated spoken answer ({len(split_into_sentences(answer_text))} sentences approx).\", 3)\n",
    "\n",
    "            return answer_text\n",
    "        else:\n",
    "            debug_print(f\"LLM response format issue for answer: {result}\", 3)\n",
    "            return \"I'm having a bit of trouble formulating an answer right now.\"\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"❌ Error calling LLM for answer generation: {e}\")\n",
    "        return \"Sorry, I encountered an error while trying to answer.\"\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Unexpected error during answer generation: {e}\")\n",
    "        return \"An unexpected error occurred while answering.\"\n",
    "STATE_IDLE = \"IDLE\" # Waiting for initial input, or after completing a task\n",
    "STATE_SPEAKING_EXPLANATION = \"SPEAKING_EXPLANATION\" # AI is speaking a full explanation\n",
    "STATE_SPEAKING_ANSWER = \"SPEAKING_ANSWER\"           # AI is speaking a concise answer\n",
    "STATE_SPEAKING_GREETING = \"SPEAKING_GREETING\"       # AI is speaking a greeting/farewell\n",
    "STATE_SPEAKING_TRANSITION = \"SPEAKING_TRANSITION\" # AI is speaking a transition phrase (\"Okay, let's learn...\")\n",
    "STATE_LISTENING = \"LISTENING\" # AI is actively listening for student input\n",
    "# STATE_PROCESSING = \"PROCESSING\" # AI is processing input (NLU, search, LLM calls) - no audio/listening\n",
    "STATE_HANDLING_INTERRUPTION = \"HANDLING_INTERRUPTION\" # AI detected interruption, asking \"Yes?\" or processing input\n",
    "STATE_CHECK_RESUME = \"CHECK_RESUME\" # AI finished handling interrupt, checking if explanation should resume\n",
    "# -- Global State Variables --\n",
    "current_state = STATE_IDLE # Starting state\n",
    "interrupt_flag = threading.Event() # Event to signal interruption across threads\n",
    "audio_thread = None # Not strictly needed with current pygame approach, but could be useful later\n",
    "interrupt_queue = queue.Queue() # Queue for communication from keyboard listener to main loop\n",
    "tts_finished_event = threading.Event() # Event signaled by speak() when audio finishes normally\n",
    "\n",
    "# --- Variables for Storing Interruption Context ---\n",
    "interrupted_context = {\n",
    "    \"type\": None, # 'explanation'\n",
    "    \"topic\": None, # Topic of the interrupted explanation\n",
    "    \"full_text\": None, # Full text of the interrupted explanation\n",
    "    \"sentences\": [], # Explanation text split into sentences\n",
    "    \"resume_index\": 0, # Index of the sentence to resume from\n",
    "    \"saved\": False # Flag to indicate if context is actively saved for resume\n",
    "}\n",
    "\n",
    "# -- Pygame Mixer Initialization (Keep as is) --\n",
    "# Initialized later in __main__\n",
    "\n",
    "# --- NEW: Pygame Display Setup ---\n",
    "SCREEN_WIDTH = 600\n",
    "SCREEN_HEIGHT = 400\n",
    "# screen = None # Initialized later in __main__\n",
    "# WHITE = (255, 255, 255)\n",
    "# BLACK = (0, 0, 0)\n",
    "# font = None # Initialized later in __main__\n",
    "\n",
    "# --- NEW: Load Mouth Shape Images ---\n",
    "MOUTH_POS = (SCREEN_WIDTH // 2, SCREEN_HEIGHT // 2 + 50) # Position for the mouth\n",
    "mouth_images = {}\n",
    "# Map Rhubarb codes to your image files (adjust filenames as needed)\n",
    "# This mapping ensures you only load images for the shapes you actually use.\n",
    "# 'A', 'D' might map to 'B' (open), 'I', 'L', 'N', 'R', 'S', 'Th', 'U', 'W', 'Y', 'Z' might map to 'E' (mid open) or 'X'\n",
    "rhubarb_map = {\n",
    "    \"A\": \"B\", # Rhubarb's A often maps to an open mouth (like B)\n",
    "    \"B\": \"B\", # Open like \"ah\"\n",
    "    \"C\": \"C\", # Wide like \"ee\"\n",
    "    \"D\": \"E\", # Less open variation, map to E\n",
    "    \"E\": \"E\", # Less open like \"uh\"\n",
    "    \"F\": \"F\", # Teeth-Lip like \"f\", \"v\"\n",
    "    \"G\": \"G\", # Puckered like \"oo\"\n",
    "    \"H\": \"H\", # Lips together like \"m\", \"b\", \"p\"\n",
    "    \"X\": \"X\", # Rest/Closed\n",
    "\n",
    "}\n",
    "\n",
    "# Placeholder for missing image (a black rectangle)\n",
    "missing_mouth_image = None\n",
    "MOUTH_IMAGE_FOLDER = \"RoboMouths_PNGs\"\n",
    "def load_mouth_images():\n",
    "    \"\"\"Loads mouth shape images into the mouth_images dictionary from a specified folder.\"\"\"\n",
    "    global mouth_images, missing_mouth_image # Declare as global to modify\n",
    "\n",
    "    debug_print(f\"Loading mouth images from folder: {MOUTH_IMAGE_FOLDER}...\", 2)\n",
    "    mouth_images = {} # Clear any previous loads\n",
    "\n",
    "    # Ensure the mouth image folder exists\n",
    "    if not os.path.exists(MOUTH_IMAGE_FOLDER):\n",
    "        print(f\"❌ Critical Error: Mouth image folder '{MOUTH_IMAGE_FOLDER}' not found.\")\n",
    "        # Create a fallback image and return only that if the folder is missing\n",
    "        missing_mouth_image = pygame.Surface((int(SCREEN_WIDTH * 0.15), int(SCREEN_HEIGHT * 0.05)))\n",
    "        missing_mouth_image.fill(BLACK)\n",
    "        mouth_images[\"X\"] = missing_mouth_image # Ensure at least a rest pose fallback\n",
    "        print(\"    Using fallback image for all mouth shapes.\")\n",
    "        return mouth_images.get(\"X\") # Return the fallback image\n",
    "\n",
    "    # Ensure a fallback image exists before trying to load others\n",
    "    missing_mouth_image = pygame.Surface((int(SCREEN_WIDTH * 0.15), int(SCREEN_HEIGHT * 0.05))) # Example size\n",
    "    missing_mouth_image.fill(BLACK)\n",
    "\n",
    "    try:\n",
    "        # Load images based on the *mapped* codes we'll use from the rhubarb_map values\n",
    "        mouth_shapes_to_load = set(rhubarb_map.values())\n",
    "\n",
    "        for shape_code in mouth_shapes_to_load:\n",
    "            # --- Construct the full file path using os.path.join ---\n",
    "            filename = f\"mouth_{shape_code}.png\"\n",
    "            full_file_path = os.path.join(MOUTH_IMAGE_FOLDER, filename)\n",
    "\n",
    "            try:\n",
    "                # Check if the file exists at the full path\n",
    "                if not os.path.exists(full_file_path):\n",
    "                    debug_print(f\"Mouth image file not found: {full_file_path}. Using fallback.\", 2)\n",
    "                    mouth_images[shape_code] = missing_mouth_image # Use fallback if file is missing\n",
    "                    continue # Skip to next shape code\n",
    "\n",
    "                img = pygame.image.load(full_file_path).convert_alpha()\n",
    "                # Optional: Scale images if needed to fit your design better\n",
    "                # img = pygame.transform.scale(img, (120, 60)) # Example scale\n",
    "\n",
    "                mouth_images[shape_code] = img\n",
    "                debug_print(f\"Loaded mouth image: {full_file_path}\", 3)\n",
    "            except pygame.error as e:\n",
    "                # Catch specific pygame loading errors\n",
    "                print(f\"⚠️ Warning: Could not load mouth image {full_file_path} using Pygame: {e}. Using fallback.\")\n",
    "                mouth_images[shape_code] = missing_mouth_image # Use fallback on pygame error\n",
    "            except Exception as e:\n",
    "                # Catch any other unexpected errors during loading loop\n",
    "                print(f\"⚠️ Warning: Unexpected error loading mouth image {full_file_path}: {e}. Using fallback.\")\n",
    "                mouth_images[shape_code] = missing_mouth_image # Use fallback on other errors\n",
    "\n",
    "\n",
    "        # --- Ensure 'X' (Rest) and 'B' (Open) have images, even if fallbacks ---\n",
    "        # If 'X' somehow wasn't in rhubarb_map values, make sure it's added\n",
    "        if \"X\" not in mouth_images:\n",
    "            debug_print(\"Adding fallback for 'X' (Rest) shape.\", 2)\n",
    "            mouth_images[\"X\"] = missing_mouth_image\n",
    "        # If 'B' somehow wasn't in rhubarb_map values, make sure it's added (useful for 'A' mapping)\n",
    "        if \"B\" not in mouth_images:\n",
    "            debug_print(\"Adding fallback for 'B' (Open) shape.\", 2)\n",
    "            mouth_images[\"B\"] = missing_mouth_image\n",
    "\n",
    "\n",
    "    except Exception as e:\n",
    "        # Catch errors outside the inner loop (less likely)\n",
    "        print(f\"❌ Error during initial mouth image loading loop setup: {e}\")\n",
    "        # Ensure at least a rest pose fallback exists\n",
    "        if \"X\" not in mouth_images:\n",
    "            mouth_images[\"X\"] = missing_mouth_image\n",
    "            print(\"    Assigned fallback for Rest pose.\")\n",
    "\n",
    "    debug_print(f\"Finished mouth image loading. Loaded {len(mouth_images)} shapes.\", 2)\n",
    "    # Store the initial mouth image to display (default to Rest)\n",
    "    return mouth_images.get(\"X\") # Return the initial image\n",
    "\n",
    "\n",
    "\n",
    "# -- Keyboard Listener Function (Keep as is) --\n",
    "INTERRUPT_KEY = 'space'\n",
    "def keyboard_listener():\n",
    "    \"\"\"Listens for the interrupt key press and signals interruption.\"\"\"\n",
    "    # This function runs in a separate thread\n",
    "    debug_print(f\"Keyboard listener thread started. Listening for '{INTERRUPT_KEY.upper()}'...\", 2)\n",
    "    try:\n",
    "        def on_key_press(event):\n",
    "            # Only trigger on key *down* event to avoid multiple triggers while held\n",
    "            if event.name == INTERRUPT_KEY and event.event_type == keyboard.KEY_DOWN:\n",
    "                # Check if an interruption is not already being actively handled\n",
    "                # This prevents spamming the queue/flag\n",
    "                if not interrupt_flag.is_set():\n",
    "                    debug_print(f\"Interrupt key '{INTERRUPT_KEY}' pressed! Signaling interruption.\", 1)\n",
    "                    # Use a queue to safely communicate with the main thread\n",
    "                    interrupt_queue.put(\"INTERRUPT\")\n",
    "                    # Set the flag. The main thread clears it after handling.\n",
    "                    interrupt_flag.set()\n",
    "\n",
    "        # Hook the keyboard events globally\n",
    "        keyboard.hook(on_key_press)\n",
    "        # Keep the thread alive\n",
    "        keyboard.wait() # This blocks the thread indefinitely until keyboard.unhook_all() or program exit\n",
    "\n",
    "    except Exception as e:\n",
    "        # Handle potential errors in the keyboard hook\n",
    "        print(f\"❌ Error in keyboard listener thread: {e}\")\n",
    "    finally:\n",
    "        debug_print(\"Keyboard listener thread exiting.\", 2)\n",
    "\n",
    "\n",
    "# -- Modified stop_speech Function (Keep as is) --\n",
    "def stop_speech():\n",
    "    \"\"\"Stops audio playback via pygame mixer and unloads.\"\"\"\n",
    "    if pygame.mixer.get_init() and pygame.mixer.music.get_busy():\n",
    "        debug_print(\"Stopping speech via pygame mixer...\", 2)\n",
    "        try:\n",
    "            pygame.mixer.music.stop()\n",
    "            pygame.mixer.music.unload() # Unload the audio file\n",
    "            debug_print(\"Speech stopped and audio unloaded.\", 2)\n",
    "        except pygame.error as e:\n",
    "            print(f\"⚠️ Warning: Pygame error during stop_speech: {e}\")\n",
    "        except Exception as e:\n",
    "            print(f\"❌ Unexpected error during stop_speech: {e}\")\n",
    "    else:\n",
    "        debug_print(\"Pygame mixer not busy or not initialized, nothing to stop.\", 2)\n",
    "\n",
    "# -- Sentence Splitting Function --\n",
    "def split_into_sentences(text):\n",
    "    \"\"\"Splits text into sentences using NLTK.\"\"\"\n",
    "    if not text:\n",
    "        return []\n",
    "\n",
    "    try:\n",
    "        # Ensure punkt tokenizer is downloaded - this check is better done once at startup\n",
    "        # try:\n",
    "        #     nltk.data.find('tokenizers/punkt')\n",
    "        # except nltk.downloader.DownloadError:\n",
    "        #     debug_print(\"NLTK 'punkt' tokenizer not found. Downloading...\", 2)\n",
    "        #     nltk.download('punkt')\n",
    "        #     debug_print(\"NLTK 'punkt' tokenizer downloaded.\", 2)\n",
    "\n",
    "        # Simple replacements to help NLTK, especially after lists, etc.\n",
    "        # Normalize line breaks and spacing around periods\n",
    "        text = text.replace('\\r\\n', ' ').replace('\\n', ' ') # Replace different line breaks with space\n",
    "        text = re.sub(r'\\s+', ' ', text).strip() # Collapse multiple spaces to one, trim whitespace\n",
    "        text = re.sub(r'([.!?])\\s*([A-Z])', r'\\1 \\2', text) # Ensure space after sentence-ending punctuation\n",
    "        text = re.sub(r'\\.\\s*(\\.)', r'..', text) # Prevent splitting on ellipsis\n",
    "\n",
    "        sentences = nltk.sent_tokenize(text)\n",
    "        # Filter out potentially empty or very short sentences from artifacts\n",
    "        sentences = [s.strip() for s in sentences if len(s.strip()) > 1 or s.strip() in \".!?\"] # Keep single punctuation marks if they somehow occur\n",
    "\n",
    "        debug_print(f\"Split text into {len(sentences)} sentences.\", 3)\n",
    "        # debug_print(f\"Sentences: {sentences}\", 4)\n",
    "        return sentences\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Error splitting text into sentences: {e}. Returning text as a single sentence.\")\n",
    "        # Fallback: split by double newline or just return the whole text as one \"sentence\"\n",
    "        fallback_sentences = [s.strip() for s in text.split('\\n\\n') if s.strip()]\n",
    "        if fallback_sentences:\n",
    "            \n",
    "            return fallback_sentences\n",
    "        else:\n",
    "            return [text.strip()] if text.strip() else []\n",
    "\n",
    "\n",
    "# --- Temp File Cleanup Function (Combined Version) ---\n",
    "def cleanup_temp_files(extensions=('.mp3', '.wav', '.json', '.tsv', '.txt')):\n",
    "    \"\"\"\n",
    "    Deletes temporary files starting with 'temp_ai_speech_' and\n",
    "    ending with specified extensions.\n",
    "\n",
    "    It iterates through files in the script's directory and attempts\n",
    "    to delete each matching file using a retry mechanism, similar to\n",
    "    the original second function, but applied to all identified temp files.\n",
    "    \"\"\"\n",
    "    debug_print(\"Starting temp file cleanup...\", 3)\n",
    "    try:\n",
    "        # --- Get the directory where the script is located ---\n",
    "        try:\n",
    "            # Use os.path.dirname(os.path.abspath(__file__)) for script's directory\n",
    "            temp_dir = os.path.dirname(os.path.abspath(__file__))\n",
    "        except NameError:\n",
    "            # Fallback if __file__ is not defined (e.g., interactive session)\n",
    "            temp_dir = os.getcwd()\n",
    "            debug_print(\"Warning: __file__ not defined, using os.getcwd() for temp file cleanup directory.\", 2)\n",
    "\n",
    "        debug_print(f\"Checking for temp files to clean in: {temp_dir}\", 3)\n",
    "\n",
    "        # --- Iterate through all files in the directory ---\n",
    "        for filename in os.listdir(temp_dir):\n",
    "            file_path = os.path.join(temp_dir, filename)\n",
    "\n",
    "            # Check if it matches the temporary file pattern and one of the extensions\n",
    "            # Also ensure it's actually a file, not a directory\n",
    "            if (filename.startswith(TTS_TEMP_PREFIX) and\n",
    "                filename.lower().endswith(tuple(ext.lower() for ext in extensions)) and # Case-insensitive extension check\n",
    "                os.path.isfile(file_path)):\n",
    "\n",
    "                debug_print(f\"Found potential temp file: {filename}\", 3)\n",
    "\n",
    "                # --- Apply the retry logic to THIS specific file ---\n",
    "                successfully_removed = False\n",
    "                debug_print(f\"Attempting to remove {filename}...\", 3)\n",
    "                for attempt in range(5): # Retry up to 5 times\n",
    "                    try:\n",
    "                        debug_print(f\"Attempt {attempt+1}/5 to remove {filename}...\", 4)\n",
    "                        os.remove(file_path)\n",
    "                        debug_print(f\"Cleaned up temp file: {filename}\", 3)\n",
    "                        successfully_removed = True\n",
    "                        break # Success for *this* file, move to the next file in the outer loop\n",
    "                    except OSError as e:\n",
    "                        # This often happens if the file is in use by another process\n",
    "                        debug_print(f\"Attempt {attempt+1} failed for {filename} (OSError): {e} (File likely in use)\", 3)\n",
    "                        time.sleep(0.1) # Wait a bit before retrying\n",
    "                    except Exception as e:\n",
    "                        # Catch any other unexpected errors during removal (e.g., permissions, FileNotFoundError if timing is weird)\n",
    "                        debug_print(f\"Attempt {attempt+1} failed for {filename} (unexpected error): {e}\", 3)\n",
    "                        time.sleep(0.1) # Wait a bit before retrying\n",
    "\n",
    "                if not successfully_removed:\n",
    "                    debug_print(f\"Failed to remove temp file {filename} after multiple attempts.\", 3)\n",
    "                # --- End of retry logic for the current file ---\n",
    "\n",
    "            # The outer loop continues to the next file regardless of\n",
    "            # whether the current one was deleted or failed after retries.\n",
    "\n",
    "    except Exception as e:\n",
    "        # Catch errors that happen during directory listing, path joining, etc.\n",
    "        debug_print(f\"Error during temp file cleanup process: {e}\", 2)\n",
    "    debug_print(\"Temp file cleanup finished.\", 3)\n",
    "    \n",
    "# --- NEW: Function to Run Rhubarb Lip Sync ---\n",
    "def get_lip_sync_data(wav_filepath, text_content):\n",
    "    \"\"\"Runs Rhubarb Lip Sync and returns the parsed timing data.\"\"\"\n",
    "    if not os.path.exists(RHUBARB_EXECUTABLE):\n",
    "        print(f\"❌ Rhubarb executable not found at '{RHUBARB_EXECUTABLE}'. Lip sync data cannot be generated.\")\n",
    "        return None\n",
    "\n",
    "    debug_print(f\"Running Rhubarb on: {os.path.basename(wav_filepath)}\", 2)\n",
    "    output_format = \"json\"\n",
    "    # Use temp file prefix for Rhubarb output file name\n",
    "    output_filepath = wav_filepath.replace(\".wav\", f\".{output_format}\")\n",
    "    # Use temp file prefix for dialog file name\n",
    "    dialog_filepath = wav_filepath.replace(\".wav\", \".txt\")\n",
    "\n",
    "    # Create dialog file - Rhubarb needs this for context/timing accuracy\n",
    "    try:\n",
    "        with open(dialog_filepath, \"w\", encoding=\"utf-8\") as f:\n",
    "            f.write(text_content)\n",
    "        debug_print(f\"Created dialog file: {os.path.basename(dialog_filepath)}\", 3)\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Error writing dialog file {dialog_filepath}: {e}\")\n",
    "        return None\n",
    "\n",
    "    # Construct Rhubarb command\n",
    "    # Adjust recognizer based on language if needed: -r phonetic or -r standard\n",
    "    # --extendedShapes GHX is often useful for the Blair set\n",
    "    command = [\n",
    "        RHUBARB_EXECUTABLE,\n",
    "        \"-f\", output_format,\n",
    "        \"-o\", output_filepath,\n",
    "        \"--dialogFile\", dialog_filepath,\n",
    "        \"--extendedShapes\", \"GHX\", # Ensure cues for G, H, X are generated\n",
    "        # \"--quiet\", # Uncomment to suppress Rhubarb's own output\n",
    "        wav_filepath # The audio file to process\n",
    "    ]\n",
    "    debug_print(f\"Rhubarb command: {' '.join(command)}\", 3)\n",
    "\n",
    "    rhubarb_data = None\n",
    "    try:\n",
    "        # Run Rhubarb as subprocess\n",
    "        process = subprocess.run(command, capture_output=True, text=True, check=True, timeout=30) # Added timeout\n",
    "        debug_print(\"Rhubarb executed successfully.\", 3)\n",
    "        # Optional verbose debug of Rhubarb's own output\n",
    "        # if process.stdout: debug_print(f\"Rhubarb stdout: {process.stdout}\", 4)\n",
    "        # if process.stderr: debug_print(f\"Rhubarb stderr: {process.stderr}\", 4)\n",
    "\n",
    "        # Read the output JSON file\n",
    "        if os.path.exists(output_filepath):\n",
    "            with open(output_filepath, \"r\", encoding=\"utf-8\") as f:\n",
    "                rhubarb_data = json.load(f)\n",
    "            debug_print(f\"Loaded Rhubarb output from {os.path.basename(output_filepath)}\", 3)\n",
    "        else:\n",
    "            print(f\"❌ Rhubarb output file not created: {output_filepath}\")\n",
    "            # Print stderr/stdout from process if available to diagnose\n",
    "            if process.stdout: print(f\"Rhubarb stdout: {process.stdout}\")\n",
    "            if process.stderr: print(f\"Rhubarb stderr: {process.stderr}\")\n",
    "\n",
    "\n",
    "    except FileNotFoundError:\n",
    "        # This specific error is caught at the top check, but defensive programming\n",
    "        print(f\"❌ Error: '{RHUBARB_EXECUTABLE}' command not found. Is Rhubarb installed and in PATH?\")\n",
    "        rhubarb_data = None\n",
    "    except subprocess.TimeoutExpired:\n",
    "        print(f\"❌ Error: Rhubarb command timed out after 30 seconds for {os.path.basename(wav_filepath)}.\")\n",
    "        rhubarb_data = None\n",
    "    except subprocess.CalledProcessError as e:\n",
    "        print(f\"❌ Error running Rhubarb (CalledProcessError): {e}\")\n",
    "        print(f\"    Rhubarb stdout: {e.stdout}\")\n",
    "        print(f\"    Rhubarb stderr: {e.stderr}\")\n",
    "        rhubarb_data = None\n",
    "    except json.JSONDecodeError as e:\n",
    "        print(f\"❌ Error parsing Rhubarb output file {output_filepath}: {e}\")\n",
    "        rhubarb_data = None\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Unexpected error getting lip sync data: {e}\")\n",
    "        rhubarb_data = None\n",
    "    finally:\n",
    "        # Clean up dialog file and Rhubarb output file immediately\n",
    "        try:\n",
    "            if os.path.exists(dialog_filepath): os.remove(dialog_filepath)\n",
    "            debug_print(f\"Cleaned up dialog file {os.path.basename(dialog_filepath)}\", 4)\n",
    "        except Exception as e: debug_print(f\"Could not clean up dialog file {os.path.basename(dialog_filepath)}: {e}\", 4)\n",
    "        # Only clean up output file here if it was successfully loaded, otherwise leave it for debugging\n",
    "        # if rhubarb_data is not None and os.path.exists(output_filepath):\n",
    "        #     try: os.remove(output_filepath)\n",
    "        #     except Exception as e: debug_print(f\"Could not clean up rhubarb output file {os.path.basename(output_filepath)}: {e}\", 4)\n",
    "        # DECISION: Cleanup temp files at the end of speak, not here, to use the robust cleanup function\n",
    "\n",
    "    # Return the list of cues or None if data was not successfully loaded\n",
    "    return rhubarb_data.get(\"mouthCues\") if rhubarb_data else None\n",
    "\n",
    "\n",
    "# --- MODIFIED speak Function (Integrates Lip Sync) ---\n",
    "def speak(text_or_sentences, speech_type=\"generic\", topic=None, start_sentence_index=0):\n",
    "    \"\"\"\n",
    "    Generates TTS (WAV), runs Rhubarb, plays audio sentence by sentence,\n",
    "    and updates global mouth shape based on timings. Handles interruption\n",
    "    and cleans up temporary audio files for each sentence after playback.\n",
    "    \"\"\"\n",
    "    global current_state, interrupted_context, current_mouth_image, current_mouth_rect\n",
    "\n",
    "    if not pygame.mixer.get_init():\n",
    "        print(\"❌ Pygame mixer not initialized, cannot speak.\")\n",
    "        print(f\"(Fallback) AI says: {text_or_sentences}\")\n",
    "        current_state = STATE_IDLE\n",
    "        return\n",
    "\n",
    "    # Clean up temp files from *previous* speak calls *before* starting new audio\n",
    "    # This attempts to clean up files that might have been left locked by the previous speak\n",
    "    # Adding a small delay here might help if files are lingering after the last unload\n",
    "    # time.sleep(0.05) # Optional small delay before cleanup\n",
    "    cleanup_temp_files() # Clean up files from *previous* speak calls\n",
    "\n",
    "    is_list = isinstance(text_or_sentences, list)\n",
    "    sentences = text_or_sentences if is_list else split_into_sentences(text_or_sentences)\n",
    "    full_original_text = \" \".join(sentences)\n",
    "\n",
    "    if not sentences:\n",
    "        debug_print(\"No sentences to speak.\", 2)\n",
    "        current_state = STATE_IDLE\n",
    "        return\n",
    "\n",
    "    # Set State based on Type\n",
    "    original_state_before_speaking = current_state # Store state before speaking starts\n",
    "    if speech_type == \"explanation\": current_state = STATE_SPEAKING_EXPLANATION\n",
    "    elif speech_type == \"answer\": current_state = STATE_SPEAKING_ANSWER\n",
    "    elif speech_type == \"transition\": current_state = STATE_SPEAKING_TRANSITION\n",
    "    elif speech_type == \"greeting\" or speech_type == \"farewell\": current_state = STATE_SPEAKING_GREETING\n",
    "    else: current_state = STATE_SPEAKING_GREETING # Default for generic/other types\n",
    "\n",
    "    debug_print(f\"Starting to speak ({current_state}). Total sentences: {len(sentences)}. Starting index: {start_sentence_index}\", 2)\n",
    "\n",
    "    interrupt_flag.clear()\n",
    "    tts_finished_event.clear()\n",
    "    interrupted_mid_speech = False\n",
    "    # start_index is passed as argument now\n",
    "    # start_index = 0 # Ensure it starts from 0 unless resuming\n",
    "\n",
    "\n",
    "    # --- Sentence Iteration Loop ---\n",
    "    for i in range(start_sentence_index, len(sentences)):\n",
    "        sentence = sentences[i]\n",
    "        if not sentence.strip(): # Skip empty sentences\n",
    "            continue\n",
    "\n",
    "        # --- Generate Unique Filenames (MP3, WAV, JSON) for this sentence ---\n",
    "        base_filename = f\"{TTS_TEMP_PREFIX}{i}_{int(time.time())}\" # Add timestamp for more uniqueness\n",
    "        mp3_filepath = f\"{base_filename}.mp3\"\n",
    "        wav_filepath = f\"{base_filename}.wav\"\n",
    "\n",
    "        debug_print(f\"Processing sentence {i+1}/{len(sentences)}: '{sentence[:70]}...'\", 2)\n",
    "\n",
    "        lip_sync_cues = None\n",
    "        audio_generated = False\n",
    "        try:\n",
    "            # --- Generate TTS MP3 using gTTS ---\n",
    "            debug_print(f\"Generating TTS for sentence {i+1}...\", 3)\n",
    "            tts = gTTS(text=sentence, lang='en', slow=False)\n",
    "            tts.save(mp3_filepath)\n",
    "            debug_print(f\"TTS MP3 saved to {os.path.basename(mp3_filepath)}\", 3)\n",
    "\n",
    "            # --- Convert MP3 to WAV using Pydub ---\n",
    "            debug_print(f\"Converting {os.path.basename(mp3_filepath)} to {os.path.basename(wav_filepath)}...\", 3)\n",
    "            audio = AudioSegment.from_mp3(mp3_filepath)\n",
    "            audio.export(wav_filepath, format=\"wav\")\n",
    "            debug_print(f\"WAV file created: {os.path.basename(wav_filepath)}\", 3)\n",
    "            audio_generated = True # Set flag if WAV is successfully created\n",
    "\n",
    "            # --- Get Lip Sync Data from Rhubarb ---\n",
    "            debug_print(f\"Getting lip sync data for {os.path.basename(wav_filepath)}...\", 3)\n",
    "            lip_sync_cues = get_lip_sync_data(wav_filepath, sentence)\n",
    "\n",
    "            if lip_sync_cues is None:\n",
    "                print(f\"⚠️ Warning: Could not get lip sync cues for sentence {i+1}. Lip sync will be static during this sentence.\")\n",
    "\n",
    "        except FileNotFoundError as e:\n",
    "            print(f\"❌ Error: FFmpeg/Libav not found or required file missing? ({e}). Cannot generate/convert audio to WAV for sentence {i+1}.\")\n",
    "            print(\"    Please ensure FFmpeg or Libav is installed and accessible in your system's PATH.\")\n",
    "            interrupted_mid_speech = True; # Flag error, but don't break yet, proceed to cleanup attempt\n",
    "        except Exception as e:\n",
    "            print(f\"❌ Error during audio generation/conversion/rhubarb for sentence {i+1}: {e}\")\n",
    "            interrupted_mid_speech = True; # Flag error, but don't break yet\n",
    "\n",
    "\n",
    "        # --- Playback and Lip Sync Animation ---\n",
    "        # Only attempt playback if WAV file was successfully created AND no interrupt was signaled during generation\n",
    "        if audio_generated and not interrupt_flag.is_set():\n",
    "            try:\n",
    "                debug_print(f\"Loading and playing {os.path.basename(wav_filepath)}...\", 3)\n",
    "                pygame.mixer.music.load(wav_filepath)\n",
    "                pygame.mixer.music.play()\n",
    "\n",
    "                # --- Playback and Lip Sync Monitor Loop ---\n",
    "                set_mouth_pose(\"X\") # Start with Rest before sound begins\n",
    "\n",
    "                while pygame.mixer.music.get_busy() and not interrupt_flag.is_set():\n",
    "                    playback_time_sec = pygame.mixer.music.get_pos() / 1000.0\n",
    "\n",
    "                    # --- Lip Sync Logic ---\n",
    "                    active_cue_found = False\n",
    "                    if lip_sync_cues:\n",
    "                        for cue in lip_sync_cues:\n",
    "                            if cue[\"start\"] <= playback_time_sec < cue[\"end\"]:\n",
    "                                mapped_code = rhubarb_map.get(cue[\"value\"], \"X\")\n",
    "                                set_mouth_pose(mapped_code)\n",
    "                                active_cue_found = True\n",
    "                                break\n",
    "                    if not active_cue_found:\n",
    "                        set_mouth_pose(\"X\") # Default to Rest\n",
    "\n",
    "                    # --- Interrupt Check --- (Remains the same)\n",
    "                    try:\n",
    "                        interrupt_signal = interrupt_queue.get_nowait()\n",
    "                        if interrupt_signal == \"INTERRUPT\": interrupt_flag.set()\n",
    "                    except queue.Empty: pass\n",
    "\n",
    "                    # --- Pygame Display Update ---\n",
    "                    update_display() # Update display while speaking\n",
    "\n",
    "                    # --- Handle Pygame Events (Crucial) ---\n",
    "                    for event in pygame.event.get():\n",
    "                        if event.type == pygame.QUIT:\n",
    "                            print(\"QUIT event detected in speak() playback loop. Signaling exit.\")\n",
    "                            global running\n",
    "                            if 'running' in globals(): running = False\n",
    "                            interrupt_flag.set()\n",
    "                            stop_speech() # This also unloads the audio\n",
    "                            interrupted_mid_speech = True\n",
    "                            break\n",
    "                    if interrupted_mid_speech: break # Exit playback loop if QUIT\n",
    "\n",
    "                # --- End of Playback/Monitor Loop ---\n",
    "\n",
    "                # --- Post Sentence Playback ---\n",
    "                # Ensure audio is stopped and unloaded after playback finishes naturally\n",
    "                # If interrupted, stop_speech() handles this. If finished naturally, do it explicitly.\n",
    "                if not pygame.mixer.music.get_busy(): # Check if music finished playing naturally\n",
    "                    debug_print(f\"Sentence {i+1} playback finished naturally.\", 3)\n",
    "                    try:\n",
    "                        pygame.mixer.music.stop() # Ensure stopped\n",
    "                        pygame.mixer.music.unload() # Explicitly unload the audio file\n",
    "                        debug_print(f\"Unloaded {os.path.basename(wav_filepath)} after natural finish.\", 3)\n",
    "                    except pygame.error as e:\n",
    "                        print(f\"⚠️ Warning: Pygame error unloading {os.path.basename(wav_filepath)}: {e}\")\n",
    "                    except Exception as e:\n",
    "                        print(f\"❌ Unexpected error unloading {os.path.basename(wav_filepath)}: {e}\")\n",
    "\n",
    "                # Reset mouth to Rest when sentence audio finishes or is interrupted\n",
    "                set_mouth_pose(\"X\")\n",
    "                update_display() # Draw final Rest pose\n",
    "\n",
    "                # If loop exited because of interruption flag being set\n",
    "                if interrupt_flag.is_set():\n",
    "                    debug_print(f\"Interrupt detected while speaking sentence {i+1}.\", 1)\n",
    "                    # stop_speech() was already called by the interrupt logic or QUIT handler\n",
    "                    interrupted_mid_speech = True # Confirm interruption occurred\n",
    "                    break # Exit the sentence loop\n",
    "\n",
    "            except pygame.error as e:\n",
    "                print(f\"❌ Error during pygame playback/drawing for sentence {i+1}: {e}\")\n",
    "                interrupted_mid_speech = True\n",
    "                break\n",
    "            except Exception as e:\n",
    "                print(f\"❌ Unexpected error during sentence playback/drawing loop {i+1}: {e}\")\n",
    "                interrupted_mid_speech = True\n",
    "                break\n",
    "\n",
    "        # --- Clean up temp audio files for this specific sentence ---\n",
    "        # Attempt cleanup *after* playback loop AND unloading\n",
    "        # This is where the WinError 32 likely occurs if unload didn't work\n",
    "        try:\n",
    "            if os.path.exists(mp3_filepath): os.remove(mp3_filepath)\n",
    "            debug_print(f\"Cleaned up {os.path.basename(mp3_filepath)}\", 4)\n",
    "        except Exception as e: debug_print(f\"Error cleaning up mp3 {os.path.basename(mp3_filepath)}: {e}\", 4)\n",
    "\n",
    "        try:\n",
    "            # This is the WAV file that might be locked\n",
    "            if os.path.exists(wav_filepath): os.remove(wav_filepath)\n",
    "            debug_print(f\"Cleaned up {os.path.basename(wav_filepath)}\", 4)\n",
    "        except Exception as e:\n",
    "            # Catch and report the error but continue\n",
    "            debug_print(f\"⚠️ Error cleaning up wav {os.path.basename(wav_filepath)}: {e}\", 3)\n",
    "            # The file might be cleaned up by a subsequent call to cleanup_temp_files if it gets unlocked later\n",
    "\n",
    "        # Rhubarb output file (.json) and dialog file (.txt) cleanup handled in get_lip_sync_data finally block\n",
    "\n",
    "        # If interrupted while processing or speaking this sentence (or error occurred)\n",
    "        if interrupted_mid_speech:\n",
    "            # --- SAVE CONTEXT IF IT WAS AN EXPLANATION ---\n",
    "            if current_state == STATE_SPEAKING_EXPLANATION:\n",
    "                debug_print(\"Saving explanation context for resume...\", 2)\n",
    "                interrupted_context[\"type\"] = \"explanation\"\n",
    "                interrupted_context[\"topic\"] = topic # Save the original topic query passed to speak\n",
    "                interrupted_context[\"full_text\"] = full_original_text # Save the full text\n",
    "                interrupted_context[\"sentences\"] = sentences # Save the list of sentences\n",
    "                # Save the index of the *next* sentence to speak\n",
    "                interrupted_context[\"resume_index\"] = i + 1\n",
    "                interrupted_context[\"saved\"] = True\n",
    "                debug_print(f\"Explanation context saved. Resume index: {interrupted_context['resume_index']}\", 2)\n",
    "            else:\n",
    "                # Clear context if interrupted during non-explanation speech or on error\n",
    "                debug_print(f\"Interrupted/Error during non-explanation speech ({current_state}). Clearing context.\", 2)\n",
    "                interrupted_context.clear()\n",
    "                interrupted_context[\"saved\"] = False\n",
    "            break # Exit the main sentence iteration loop as we've handled the interruption/error\n",
    "\n",
    "\n",
    "    # --- Post-Loop Handling ---\n",
    "    if not interrupted_mid_speech:\n",
    "        debug_print(\"Finished speaking all sentences naturally.\", 2)\n",
    "        tts_finished_event.set() # Signal that TTS is finished normally\n",
    "        # Clear context after successfully completing an explanation\n",
    "        if current_state == STATE_SPEAKING_EXPLANATION:\n",
    "            debug_print(\"Explanation completed naturally. Clearing context.\", 2)\n",
    "            interrupted_context.clear()\n",
    "            interrupted_context[\"saved\"] = False\n",
    "        # Transition to IDLE state after finishing speaking normally\n",
    "        # The state is set *after* the speak call returns in the main loop logic flow\n",
    "        # For now, let speak handle setting IDLE if it finishes normally\n",
    "        # current_state = STATE_IDLE # Let the logic *after* the speak call set the next state\n",
    "\n",
    "    else:\n",
    "        debug_print(f\"Exited speak function due to interruption/error (Flag: {interrupt_flag.is_set()}).\", 2)\n",
    "        # If interrupted, the state was set by the interrupt handler or QUIT event handler\n",
    "        # The main loop logic after the speak call will handle the state transition based on interrupt_flag.\n",
    "\n",
    "# --- Placeholder for transition phrase generation ---\n",
    "def generate_transition_phrase(topic=None):\n",
    "    \"\"\"Generates a simple transition phrase.\"\"\"\n",
    "    phrases = [\n",
    "        \"Okay, getting back to it.\",\n",
    "        \"Resuming our discussion.\",\n",
    "        \"Let's continue.\",\n",
    "        \"Picking up where we left off.\"\n",
    "    ]\n",
    "    if topic:\n",
    "        phrases.extend([\n",
    "            f\"Okay, getting back to {topic}.\",\n",
    "            f\"Let's continue our lesson on {topic}.\"\n",
    "            ])\n",
    "    return random.choice(phrases)\n",
    "\n",
    "# --- Pygame Display Update Function ---\n",
    "def update_display():\n",
    "    \"\"\"Clears the screen and draws the current visual elements.\"\"\"\n",
    "    global screen, current_mouth_image, current_mouth_rect # Access global display variables\n",
    "\n",
    "    if screen is None:\n",
    "        # Screen hasn't been initialized yet\n",
    "        return\n",
    "\n",
    "    # Check for QUIT event during drawing update loop - redundant if main loop checks, but safer\n",
    "    for event in pygame.event.get():\n",
    "        if event.type == pygame.QUIT:\n",
    "            global running # Access main loop flag\n",
    "            if 'running' in globals():\n",
    "                running = False # Signal main loop to exit\n",
    "            pygame.quit() # Quit pygame subsystems immediately\n",
    "            # This will likely cause errors later if the loop continues,\n",
    "            # but ensures the window closes. Main loop should handle graceful exit.\n",
    "            return # Stop drawing update if QUIT\n",
    "\n",
    "    screen.fill(WHITE) # Clear screen each frame\n",
    "\n",
    "    # Draw optional head image here (if you have one loaded)\n",
    "    # if 'head_image' in globals() and 'head_rect' in globals() and head_image and head_rect:\n",
    "    #      screen.blit(head_image, head_rect)\n",
    "\n",
    "    # Draw the current mouth image (updated by set_mouth_pose)\n",
    "    if current_mouth_image and current_mouth_rect:\n",
    "        # Center the mouth image on the screen at MOUTH_POS\n",
    "        # current_mouth_rect = current_mouth_image.get_rect(center=MOUTH_POS) # Update rect center each time? Or once on image change? Doing it once on change is better.\n",
    "        screen.blit(current_mouth_image, current_mouth_rect)\n",
    "\n",
    "    # Draw status text (optional)\n",
    "    # status_text_surface = font.render(f\"State: {current_state}\", True, BLACK)\n",
    "    # screen.blit(status_text_surface, (10, 10))\n",
    "\n",
    "    pygame.display.flip() # Update the entire screen\n",
    "\n",
    "\n",
    "# --- Function to set the current mouth pose ---\n",
    "def set_mouth_pose(code):\n",
    "    \"\"\"Sets the global current_mouth_image based on a mapped code.\"\"\"\n",
    "    global current_mouth_image, current_mouth_rect, mouth_images, missing_mouth_image # Access global variables\n",
    "\n",
    "    # Get the corresponding image, default to Rest ('X') or the fallback if the code or 'X' image is missing\n",
    "    img_to_set = mouth_images.get(code, mouth_images.get(\"X\", missing_mouth_image))\n",
    "\n",
    "    if current_mouth_image != img_to_set:\n",
    "        # Only update if the image is actually changing\n",
    "        current_mouth_image = img_to_set\n",
    "        # Update the rectangle's position to keep it centered at MOUTH_POS\n",
    "        if current_mouth_image:\n",
    "            current_mouth_rect = current_mouth_image.get_rect(center=MOUTH_POS)\n",
    "\n",
    "\n",
    "\n",
    "# --- The Main Application Loop ---\n",
    "def run_voice_teacher():\n",
    "    \"\"\"\n",
    "    Runs the main state-driven interaction loop for the AI voice teacher.\n",
    "    Handles user input, processing, speaking, interruptions, and display updates.\n",
    "    \"\"\"\n",
    "    global current_state, interrupt_flag, interrupted_context, running\n",
    "    global screen, font, WHITE, BLACK # Access pygame variables\n",
    "\n",
    "    # --- Initial Setup (called from __main__) ---\n",
    "    # Pygame initialized in __main__\n",
    "    # Keyboard listener started in __main__\n",
    "    # Mouth images loaded in __main__\n",
    "    # Initial state is STATE_IDLE\n",
    "\n",
    "    debug_print(\"Starting AI Teacher main loop...\", 1)\n",
    "\n",
    "    interrupted_context = {\"saved\": False} # Ensure context is initially clear\n",
    "    running = True # Flag to control the main loop\n",
    "\n",
    "\n",
    "    # --- Initial Greeting ---\n",
    "    # The speak function sets the state and handles its own duration/interrupts\n",
    "    speak(\"Hello! Press SPACE to interrupt. What topic today?\", speech_type=\"greeting\")\n",
    "\n",
    "    # After speak() returns, check the interrupt flag to determine the next state\n",
    "    if interrupt_flag.is_set():\n",
    "        debug_print(\"Initial greeting interrupted.\", 1)\n",
    "        # If interrupted, clear flag and go straight to handling interruption\n",
    "        interrupt_flag.clear()\n",
    "        current_state = STATE_HANDLING_INTERRUPTION # Go to interrupt handling state\n",
    "    else:\n",
    "        debug_print(\"Initial greeting finished normally.\", 1)\n",
    "        current_state = STATE_IDLE # Return to idle after greeting\n",
    "\n",
    "    # Prompt the user after the greeting\n",
    "    print(\"\\nAI is ready. What science topic would you like to learn about or ask a question?\")\n",
    "    # Initial state after greeting is IDLE or HANDLING_INTERRUPTION\n",
    "\n",
    "\n",
    "    # --- Main State-Driven Loop ---\n",
    "    while running:\n",
    "        # --- Pygame Event Handling ---\n",
    "        # Handle events like closing the window - CRUCIAL for responsiveness\n",
    "        for event in pygame.event.get():\n",
    "            if event.type == pygame.QUIT:\n",
    "                print(\"QUIT event detected in main loop. Signaling exit.\")\n",
    "                running = False # Signal loop to stop\n",
    "                interrupt_flag.set() # Signal any active speak() or listen() to stop\n",
    "                stop_speech() # Ensure audio is stopped\n",
    "                break # Exit event loop\n",
    "            # You can add other event handling here (e.g., mouse clicks, other key presses)\n",
    "            # elif event.type == pygame.KEYDOWN:\n",
    "            #     debug_print(f\"Key pressed: {event.key}\", 4)\n",
    "            #     pass # Handle other key presses if needed\n",
    "\n",
    "        if not running: break # Exit main loop if QUIT detected\n",
    "\n",
    "        # --- Update Pygame Display ---\n",
    "        # This handles drawing when speak() is NOT running (speak draws while it's active)\n",
    "        # It also handles drawing the final pose after speak() finishes.\n",
    "        update_display()\n",
    "\n",
    "\n",
    "        # --- Check for Interruptions ---\n",
    "        # This block is triggered if the interrupt key was pressed *while not already in HANDLING_INTERRUPTION*\n",
    "        if interrupt_flag.is_set() and current_state != STATE_HANDLING_INTERRUPTION:\n",
    "            debug_print(\"Main loop detected interrupt flag set. Transitioning to HANDLING_INTERRUPTION.\", 1)\n",
    "            stop_speech() # Ensure audio stopped if speak was running\n",
    "            interrupt_flag.clear() # Clear the flag as we are starting to handle it\n",
    "            current_state = STATE_HANDLING_INTERRUPTION # Transition to the handling state\n",
    "            # The logic for *what happens in* HANDLING_INTERRUPTION is below\n",
    "\n",
    "\n",
    "        # --- Handle States ---\n",
    "        # --- STATE: IDLE ---\n",
    "        if current_state == STATE_IDLE:\n",
    "            debug_print(\"State: IDLE. Transitioning to LISTENING.\", 2)\n",
    "            # In IDLE, we are waiting for the user to start a new interaction.\n",
    "            # Immediately transition to LISTENING to get user input.\n",
    "            # The prompt message was printed earlier, and will be printed again if we return to IDLE\n",
    "            current_state = STATE_LISTENING\n",
    "\n",
    "\n",
    "        # --- STATE: LISTENING ---\n",
    "        elif current_state == STATE_LISTENING:\n",
    "            debug_print(\"State: LISTENING. Waiting for input.\", 2)\n",
    "            # Ensure previous context is cleared if we're starting a new conversation phase\n",
    "            if interrupted_context.get(\"saved\"):\n",
    "                debug_print(\"Clearing old interruption context before listening for new command.\", 2)\n",
    "                interrupted_context.clear()\n",
    "                interrupted_context[\"saved\"] = False\n",
    "\n",
    "            # Only listen if the mixer is NOT busy (shouldn't be in LISTENING, but defensive)\n",
    "            if not pygame.mixer.music.get_busy():\n",
    "                # Call the listen function - it blocks until speech or timeout\n",
    "                student_input = listen_to_student() # This function sets mouth pose\n",
    "\n",
    "                # --- After listen_to_student returns, process the input ---\n",
    "                if student_input is not None: # Check if speech was recognized (not None)\n",
    "                    debug_print(f\"Student input received: '{student_input}'. Understanding intent...\", 2)\n",
    "                    # Process the input and understand intent\n",
    "                    intent, topic_or_question = understand_intent_and_topic(student_input)\n",
    "\n",
    "                    # --- Handle Input Intents (No Saved Context) ---\n",
    "                    # This block is for entirely new requests when not in an interrupted state\n",
    "                    debug_print(f\"Handling new request intent: {intent}, topic: {topic_or_question}\", 1)\n",
    "\n",
    "                    # Reset interrupt flag and tts_finished_event before starting a new speaking task\n",
    "                    interrupt_flag.clear()\n",
    "                    tts_finished_event.clear()\n",
    "\n",
    "                    if intent == \"REQUEST_EXPLANATION\":\n",
    "                        if topic_or_question:\n",
    "                            debug_print(f\"Handling new REQUEST_EXPLANATION for topic: {topic_or_question}\", 1)\n",
    "                            # Decide between in-syllabus detailed or general explanation\n",
    "                            explanation_text, cleaned_topic, in_syllabus = generate_spoken_explanation(topic_or_question)\n",
    "\n",
    "                            if not in_syllabus:\n",
    "                                speak(f\"That topic doesn't seem to be in our current syllabus, but here's a general overview.\", speech_type=\"transition\")\n",
    "                                # After speak returns, check interrupt flag\n",
    "                                if interrupt_flag.is_set(): debug_print(\"Out-of-syllabus transition interrupted.\", 1); current_state = STATE_HANDLING_INTERRUPTION; continue # Go to interrupt handling\n",
    "                                else: debug_print(\"Out-of-syllabus transition finished.\", 1) # State remains LISTENING until speak is called next\n",
    "\n",
    "                                # Now speak the explanation text (pass original query as topic for context saving)\n",
    "                                speak(explanation_text, speech_type=\"explanation\", topic=topic_query, start_sentence_index=0)\n",
    "                            else: # In syllabus\n",
    "                                speak(f\"Okay, let's learn about {cleaned_topic}.\", speech_type=\"transition\")\n",
    "                                # After speak returns, check interrupt flag\n",
    "                                if interrupt_flag.is_set(): debug_print(\"In-syllabus transition interrupted.\", 1); current_state = STATE_HANDLING_INTERRUPTION; continue\n",
    "                                else: debug_print(\"In-syllabus transition finished.\", 1)\n",
    "\n",
    "                                # Now speak the explanation text (generate_full_lesson_text includes intro/hook)\n",
    "                                speak(explanation_text, speech_type=\"explanation\", topic=cleaned_topic, start_sentence_index=0) # Pass cleaned topic\n",
    "\n",
    "\n",
    "                            # After speaking the explanation (either general or detailed), check the flag\n",
    "                            if interrupt_flag.is_set():\n",
    "                                debug_print(\"Explanation spoken after new request was interrupted.\", 1)\n",
    "                                # Context is saved inside speak(). State is now SPEAKING_EXPLANATION (correct).\n",
    "                                # Main loop will transition to HANDLING_INTERRUPTION because flag is set.\n",
    "                                pass # Handled by the interrupt check at top of loop\n",
    "                            else:\n",
    "                                debug_print(\"Explanation spoken after new request finished normally.\", 1)\n",
    "                                # Explanation finished, clear context as it wasn't interrupted mid-speak\n",
    "                                interrupted_context.clear()\n",
    "                                interrupted_context[\"saved\"] = False\n",
    "                                # Transition to IDLE\n",
    "                                current_state = STATE_IDLE\n",
    "                                debug_print(\"Transitioning to IDLE after explanation.\", 2)\n",
    "\n",
    "                        else: # REQUEST_EXPLANATION but no topic extracted\n",
    "                            debug_print(\"REQUEST_EXPLANATION intent with no topic extracted.\", 1)\n",
    "                            speak(\"Please tell me what topic you'd like to learn about.\", speech_type=\"answer\")\n",
    "                            if interrupt_flag.is_set(): debug_print(\"Prompt interrupted.\", 1); current_state = STATE_HANDLING_INTERRUPTION; continue\n",
    "                            else: debug_print(\"Prompt finished.\", 1); current_state = STATE_IDLE\n",
    "\n",
    "\n",
    "                    elif intent == \"ASK_QUESTION\":\n",
    "                        if topic_or_question:\n",
    "                            debug_print(f\"Handling new ASK_QUESTION: {topic_or_question}\", 1)\n",
    "                            speak(\"Let me see...\", speech_type=\"transition\")\n",
    "                            if interrupt_flag.is_set(): debug_print(\"Answer transition interrupted.\", 1); current_state = STATE_HANDLING_INTERRUPTION; continue\n",
    "                            else: debug_print(\"Answer transition finished.\", 1)\n",
    "\n",
    "                            # Generate and speak the answer (no specific context needed for a new question)\n",
    "                            # Check syllabus relevance even for questions if you want to use KB context\n",
    "                            in_syllabus, syllabus_content, _ = is_in_syllabus(topic_or_question)\n",
    "                            answer_context = syllabus_content if in_syllabus else None\n",
    "\n",
    "                            answer = generate_spoken_answer(topic_or_question, answer_context)\n",
    "                            speak(answer, speech_type=\"answer\")\n",
    "\n",
    "                            # After speaking the answer, check the flag\n",
    "                            if interrupt_flag.is_set():\n",
    "                                debug_print(\"Answer spoken after new request was interrupted.\", 1)\n",
    "                                # Context is NOT saved for answers. State is SPEAKING_ANSWER (correct).\n",
    "                                # Main loop will transition to HANDLING_INTERRUPTION because flag is set.\n",
    "                                pass # Handled by the interrupt check at top of loop\n",
    "                            else:\n",
    "                                debug_print(\"Answer spoken after new request finished normally.\", 1)\n",
    "                                # Transition to IDLE\n",
    "                                current_state = STATE_IDLE\n",
    "                                debug_print(\"Transitioning to IDLE after answer.\", 2)\n",
    "\n",
    "                        else: # ASK_QUESTION but no topic extracted\n",
    "                            debug_print(\"ASK_QUESTION intent with no topic extracted.\", 1)\n",
    "                            speak(\"Please ask me a specific question.\", speech_type=\"answer\")\n",
    "                            if interrupt_flag.is_set(): debug_print(\"Prompt interrupted.\", 1); current_state = STATE_HANDLING_INTERRUPTION; continue\n",
    "                            else: debug_print(\"Prompt finished.\", 1); current_state = STATE_IDLE\n",
    "\n",
    "\n",
    "                    elif intent == \"GREETING\":\n",
    "                        debug_print(\"Handling GREETING intent.\", 1)\n",
    "                        speak(random.choice([\"Hello!\", \"Hi there!\", \"Greetings!\"]), speech_type=\"greeting\")\n",
    "                        if interrupt_flag.is_set(): debug_print(\"Greeting interrupted.\", 1); current_state = STATE_HANDLING_INTERRUPTION; continue\n",
    "                        else: debug_print(\"Greeting finished.\", 1); current_state = STATE_IDLE\n",
    "\n",
    "                    elif intent == \"FAREWELL\":\n",
    "                        debug_print(\"Handling FAREWELL intent. Exiting.\", 1)\n",
    "                        speak(random.choice([\"Goodbye!\", \"See you later!\", \"Farewell!\"]), speech_type=\"farewell\")\n",
    "                        # The speak function will handle the final audio. After speak returns, exit.\n",
    "                        running = False # Signal main loop to exit\n",
    "\n",
    "                    elif intent == \"RESUME\":\n",
    "                        debug_print(\"Handling RESUME intent with no saved context.\", 1)\n",
    "                        # Resume command when no context exists (user error)\n",
    "                        speak(\"There is no explanation saved to resume.\", speech_type=\"answer\")\n",
    "                        if interrupt_flag.is_set(): debug_print(\"Resume failed message interrupted.\", 1); current_state = STATE_HANDLING_INTERRUPTION; continue\n",
    "                        else: debug_print(\"Resume failed message finished.\", 1); current_state = STATE_IDLE\n",
    "\n",
    "                    elif intent == \"REPHRASE\":\n",
    "                        debug_print(\"Handling REPHRASE intent.\", 1)\n",
    "                        # Rephrase command when no context exists (user error or feature not implemented)\n",
    "                        speak(\"Sorry, I don't have the previous phrase saved to rephrase.\", speech_type=\"answer\") # Or implement rephrase logic\n",
    "                        if interrupt_flag.is_set(): debug_print(\"Rephrase failed message interrupted.\", 1); current_state = STATE_HANDLING_INTERRUPTION; continue\n",
    "                        else: debug_print(\"Rephrase failed message finished.\", 1); current_state = STATE_IDLE\n",
    "\n",
    "\n",
    "                    elif intent == \"OTHER\":\n",
    "                        debug_print(\"Handling OTHER intent.\", 1)\n",
    "                        speak(\"Hmm, I'm not sure how to respond to that. Could you try rephrasing?\", speech_type=\"answer\")\n",
    "                        if interrupt_flag.is_set(): debug_print(\"Generic response interrupted.\", 1); current_state = STATE_HANDLING_INTERRUPTION; continue\n",
    "                        else: debug_print(\"Generic response finished.\", 1); current_state = STATE_IDLE\n",
    "\n",
    "                    elif intent == \"ERROR\" or intent == \"NO_INPUT\": # NLU failed or listen timed out/failed\n",
    "                        debug_print(f\"Handling NLU/Listen ERROR/NO_INPUT intent: {intent}\", 1)\n",
    "                        speak(\"Sorry, I had trouble understanding that. Could you repeat or rephrase?\", speech_type=\"answer\")\n",
    "                        if interrupt_flag.is_set(): debug_print(\"Error response interrupted.\", 1); current_state = STATE_HANDLING_INTERRUPTION; continue\n",
    "                        else: debug_print(\"Error response finished.\", 1); current_state = STATE_IDLE\n",
    "\n",
    "\n",
    "            time.sleep(0.05)\n",
    "\n",
    "\n",
    "        # --- STATE: HANDLING_INTERRUPTION ---\n",
    "        elif current_state == STATE_HANDLING_INTERRUPTION:\n",
    "            debug_print(\"State: HANDLING_INTERRUPTION.\", 2)\n",
    "            # This state is entered when an interrupt flag is set in other states.\n",
    "            # We need to listen for the student's command after they interrupted.\n",
    "\n",
    "            # Check if we were interrupted *while* handling the interruption (e.g., while speaking \"Yes?\")\n",
    "            # If the flag is set upon entering this state, it means the previous action was interrupted.\n",
    "            if interrupt_flag.is_set():\n",
    "                debug_print(\"Interrupt flag set upon entering HANDLING_INTERRUPTION. Clearing and re-processing.\", 2)\n",
    "                stop_speech() # Ensure audio is stopped again\n",
    "                interrupt_flag.clear() # Clear flag as we are starting to handle it\n",
    "                # Proceed to listen for the command immediately below in this state's logic\n",
    "                pass # Continue\n",
    "\n",
    "            else:\n",
    "                # This is the standard flow: interrupt detected, speak was stopped,\n",
    "                # flag was cleared *before* entering this state. Now prompt the user.\n",
    "                debug_print(\"Prompting student after interruption.\", 2)\n",
    "                speak(\"Yes?\", speech_type=\"transition\")\n",
    "\n",
    "                # After speak(\"Yes?\") returns, check the flag again\n",
    "                if interrupt_flag.is_set():\n",
    "                    debug_print(\"'Yes?' response was interrupted.\", 1)\n",
    "                    # If 'Yes?' was interrupted, stay in HANDLING_INTERRUPTION.\n",
    "                    # Flag is already set by keyboard listener. Next loop checks flag.\n",
    "                    interrupt_flag.clear() # Clear flag for next handling cycle\n",
    "                    # State remains HANDLING_INTERRUPTION\n",
    "                    debug_print(\"Staying in HANDLING_INTERRUPTION.\", 2)\n",
    "                    pass # Continue to the listen logic below\n",
    "\n",
    "                else:\n",
    "                    # If 'Yes?' finished normally, listen for the student's command\n",
    "                    debug_print(\"'Yes?' response finished normally. Listening for interruption command.\", 2)\n",
    "                    print(f\"\\n🎤 (Listening for your command after interruption)\") # User feedback\n",
    "                    interruption_input = listen_to_student() # This blocks until speech or timeout\n",
    "\n",
    "                    # --- Process the interruption input ---\n",
    "                    if interruption_input is not None:\n",
    "                        debug_print(f\"Interruption input received: '{interruption_input}'. Understanding command.\", 2)\n",
    "                        intent, topic_or_question = understand_intent_and_topic(interruption_input)\n",
    "\n",
    "                        # Reset interrupt flag and tts_finished_event before starting a new speaking task\n",
    "                        interrupt_flag.clear()\n",
    "                        tts_finished_event.clear()\n",
    "\n",
    "                        # --- Handle Interruption Command Intents (With Saved Context Check) ---\n",
    "                        # This logic is adapted from the main_interaction_loop provided previously\n",
    "\n",
    "                        # Handle input when SAVED context exists (most common after interrupting explanation)\n",
    "                        if interrupted_context.get(\"saved\"):\n",
    "                            debug_print(\"Saved context found. Evaluating interruption input.\", 1)\n",
    "\n",
    "                            if intent == \"ASK_QUESTION\" and topic_or_question:\n",
    "                                debug_print(\"Interruption input is a question. Answering and preparing to resume.\", 1)\n",
    "                                # Handle the question - Integrate syllabus check and concise answer\n",
    "                                # Use the *interrupted explanation topic* as context for the answer if available\n",
    "                                context_for_answer = interrupted_context.get(\"topic\")\n",
    "                                answer = generate_spoken_answer(topic_or_question, context_for_answer)\n",
    "                                speak(answer, speech_type=\"answer\")\n",
    "                                # After speaking the answer, transition to CHECK_RESUME (unless interrupted)\n",
    "                                # The transition happens after the speak call returns.\n",
    "\n",
    "                            elif intent == \"RESUME\":\n",
    "                                debug_print(\"Interruption input is an explicit resume command. Proceeding to resume.\", 1)\n",
    "                                # No speech needed here, just transition directly\n",
    "                                current_state = STATE_CHECK_RESUME\n",
    "                                # Skip remaining logic in this block and go straight to CHECK_RESUME state in next loop\n",
    "                                continue # Skip to the next iteration\n",
    "\n",
    "                            elif intent == \"REQUEST_EXPLANATION\" and topic_or_question:\n",
    "                                debug_print(f\"Interruption input is request for NEW explanation topic ('{topic_or_question}'). Acknowledging and will then resume original.\", 1)\n",
    "                                speak(f\"Okay, I can make a note about {topic_or_question}. Let's get back to...\", speech_type=\"transition\")\n",
    "                                # Saved context is NOT cleared here.\n",
    "                                # Transition to CHECK_RESUME after speak returns.\n",
    "\n",
    "                            elif intent in [\"GREETING\", \"FAREWELL\", \"REPHRASE\", \"OTHER\", \"ERROR\", \"NO_INPUT\"]:\n",
    "                                # Handle greetings, farewells, inability to understand, etc. when context is saved.\n",
    "                                # Provide a response but preserve the context and then transition to CHECK_RESUME (unless FAREWELL).\n",
    "                                if intent == \"GREETING\":\n",
    "                                        speak(random.choice([\"Hello again!\", \"Hi!\", \"Greetings!\"]), speech_type=\"greeting\")\n",
    "                                elif intent == \"FAREWELL\":\n",
    "                                        speak(random.choice([\"Okay, goodbye!\", \"See you later!\"]), speech_type=\"farewell\")\n",
    "                                        running = False # Signal exit\n",
    "                                elif intent == \"REPHRASE\":\n",
    "                                        speak(\"Could you please repeat what you said before?\", speech_type=\"answer\")\n",
    "                                elif intent == \"ERROR\" or intent == \"NO_INPUT\":\n",
    "                                        speak(\"Sorry, I didn't get that. Could you please repeat your command?\", speech_type=\"answer\")\n",
    "                                elif intent == \"OTHER\":\n",
    "                                        speak(\"Hmm, I'm not sure about that command right now. Were you trying to ask a question or resume?\", speech_type=\"answer\")\n",
    "\n",
    "                                # For most of these (except FAREWELL), transition to CHECK_RESUME after speaking.\n",
    "                                if intent != \"FAREWELL\":\n",
    "                                        # Transition happens after speak call returns.\n",
    "                                        pass # Handled by the state check after speak\n",
    "\n",
    "                            # --- State Transition after handling interruption input (when saved context) ---\n",
    "                            # After processing the input and speaking a response (if any),\n",
    "                            # check if the *response speech* was interrupted.\n",
    "                            if running and intent != \"FAREWELL\": # Only transition if not exiting\n",
    "                                if interrupt_flag.is_set():\n",
    "                                        debug_print(\"Speech following interruption input was interrupted. Staying in HANDLING_INTERRUPTION.\", 1)\n",
    "                                        # Flag is already set. Next loop will re-enter HANDLING_INTERRUPTION.\n",
    "                                        stop_speech() # Ensure stopped\n",
    "                                        interrupt_flag.clear() # Clear flag for the next cycle\n",
    "                                        # State remains HANDLING_INTERRUPTION\n",
    "                                        debug_print(\"Staying in HANDLING_INTERRUPTION.\", 2)\n",
    "                                        pass # Continue to the start of HANDLING_INTERRUPTION logic in next loop\n",
    "                                else:\n",
    "                                        debug_print(\"Speech following interruption input finished normally. Transitioning to CHECK_RESUME.\", 1)\n",
    "                                        # If response speech finished, proceed to check if resume is needed\n",
    "                                        current_state = STATE_CHECK_RESUME # Go to check resume state\n",
    "\n",
    "\n",
    "                        # Handle interruption input when NO saved context exists\n",
    "                        else:\n",
    "                            debug_print(\"No saved context found. Handling interruption input as a new command.\", 1)\n",
    "                            # This is similar to the main IDLE -> LISTENING -> PROCESSING flow, but triggered by interrupt\n",
    "\n",
    "                            if intent == \"REQUEST_EXPLANATION\" and topic_or_question:\n",
    "                                debug_print(f\"Handling new REQUEST_EXPLANATION from interruption: {topic_or_question}\", 1)\n",
    "                                explanation_text, cleaned_topic, in_syllabus = generate_spoken_explanation(topic_or_question)\n",
    "\n",
    "                                if not in_syllabus:\n",
    "                                    speak(f\"That topic doesn't seem to be in our current syllabus, but here's a general overview.\", speech_type=\"transition\")\n",
    "                                    if interrupt_flag.is_set(): debug_print(\"Out-of-syllabus transition interrupted.\", 1); stop_speech(); interrupt_flag.clear(); current_state = STATE_HANDLING_INTERRUPTION; continue\n",
    "                                    else: debug_print(\"Out-of-syllabus transition finished.\", 1)\n",
    "                                    speak(explanation_text, speech_type=\"explanation\", topic=topic_query, start_sentence_index=0)\n",
    "                                else:\n",
    "                                    speak(f\"Okay, let's learn about {cleaned_topic}.\", speech_type=\"transition\")\n",
    "                                    if interrupt_flag.is_set(): debug_print(\"In-syllabus transition interrupted.\", 1); stop_speech(); interrupt_flag.clear(); current_state = STATE_HANDLING_INTERRUPTION; continue\n",
    "                                    else: debug_print(\"In-syllabus transition finished.\", 1)\n",
    "                                    speak(explanation_text, speech_type=\"explanation\", topic=cleaned_topic, start_sentence_index=0)\n",
    "\n",
    "                                # After speaking the explanation, check the flag\n",
    "                                    if interrupt_flag.is_set():\n",
    "                                        debug_print(\"Explanation spoken after interruption was interrupted.\", 1)\n",
    "                                        # Context is saved inside speak(). State is now SPEAKING_EXPLANATION (correct).\n",
    "                                        # Main loop will transition to HANDLING_INTERRUPTION.\n",
    "                                        stop_speech()\n",
    "                                        interrupt_flag.clear() # Clear flag\n",
    "                                        debug_print(\"Staying in HANDLING_INTERRUPTION after interrupted explanation.\", 2)\n",
    "                                        pass\n",
    "                                    else:\n",
    "                                        debug_print(\"Explanation spoken after interruption finished normally.\", 1)\n",
    "                                        # Explanation finished, clear context as it wasn't interrupted mid-speak\n",
    "                                        interrupted_context.clear()\n",
    "                                        interrupted_context[\"saved\"] = False\n",
    "                                        # Transition to IDLE\n",
    "                                        current_state = STATE_IDLE\n",
    "                                        debug_print(\"Transitioning to IDLE after explanation.\", 2)\n",
    "\n",
    "                            elif intent == \"ASK_QUESTION\" and topic_or_question:\n",
    "                                debug_print(\"Handling new ASK_QUESTION from interruption.\", 1)\n",
    "                                speak(\"Let me see...\", speech_type=\"transition\")\n",
    "                                if interrupt_flag.is_set(): debug_print(\"Answer transition interrupted.\", 1); stop_speech(); interrupt_flag.clear(); current_state = STATE_HANDLING_INTERRUPTION; continue\n",
    "                                else: debug_print(\"Answer transition finished.\", 1)\n",
    "\n",
    "                                in_syllabus, syllabus_content, _ = is_in_syllabus(topic_or_question)\n",
    "                                answer_context = syllabus_content if in_syllabus else None\n",
    "                                answer = generate_spoken_answer(topic_or_question, answer_context)\n",
    "                                speak(answer, speech_type=\"answer\")\n",
    "\n",
    "                                if interrupt_flag.is_set():\n",
    "                                        debug_print(\"Answer spoken after interruption was interrupted.\", 1)\n",
    "                                        stop_speech()\n",
    "                                        interrupt_flag.clear()\n",
    "                                        current_state = STATE_HANDLING_INTERRUPTION\n",
    "                                        debug_print(\"Staying in HANDLING_INTERRUPTION after interrupted answer.\", 2)\n",
    "                                        pass\n",
    "                                else:\n",
    "                                        debug_print(\"Answer spoken after interruption finished normally.\", 1)\n",
    "                                        current_state = STATE_IDLE\n",
    "                                        debug_print(\"Transitioning to IDLE after answer.\", 2)\n",
    "\n",
    "                            elif intent == \"GREETING\":\n",
    "                                debug_print(\"Handling GREETING from interruption.\", 1)\n",
    "                                speak(random.choice([\"Hello!\", \"Hi there!\", \"Greetings!\"]), speech_type=\"greeting\")\n",
    "                                if interrupt_flag.is_set(): debug_print(\"Greeting interrupted.\", 1); stop_speech(); interrupt_flag.clear(); current_state = STATE_HANDLING_INTERRUPTION; continue\n",
    "                                else: debug_print(\"Greeting finished.\", 1); current_state = STATE_IDLE\n",
    "\n",
    "                            elif intent == \"FAREWELL\":\n",
    "                                debug_print(\"Handling FAREWELL from interruption. Exiting.\", 1)\n",
    "                                speak(random.choice([\"Goodbye!\", \"See you later!\", \"Farewell!\"]), speech_type=\"farewell\")\n",
    "                                running = False\n",
    "\n",
    "                            elif intent == \"RESUME\":\n",
    "                                debug_print(\"Handling RESUME from interruption with no saved context.\", 1)\n",
    "                                speak(\"There is no explanation saved to resume.\", speech_type=\"answer\")\n",
    "                                if interrupt_flag.is_set(): debug_print(\"Resume failed message interrupted.\", 1); stop_speech(); interrupt_flag.clear(); current_state = STATE_HANDLING_INTERRUPTION; continue\n",
    "                                else: debug_print(\"Resume failed message finished.\", 1); current_state = STATE_IDLE\n",
    "\n",
    "                            elif intent == \"REPHRASE\":\n",
    "                                debug_print(\"Handling REPHRASE from interruption.\", 1)\n",
    "                                speak(\"Sorry, I don't have the previous phrase saved to rephrase.\", speech_type=\"answer\")\n",
    "                                if interrupt_flag.is_set(): debug_print(\"Rephrase failed message interrupted.\", 1); stop_speech(); interrupt_flag.clear(); current_state = STATE_HANDLING_INTERRUPTION; continue\n",
    "                                else: debug_print(\"Rephrase failed message finished.\", 1); current_state = STATE_IDLE\n",
    "\n",
    "                            elif intent in [\"OTHER\", \"ERROR\", \"NO_INPUT\"]:\n",
    "                                debug_print(f\"Handling OTHER/ERROR/NO_INPUT from interruption: {intent}\", 1)\n",
    "                                speak(\"Sorry, I didn't get that. Could you try rephrasing?\", speech_type=\"answer\")\n",
    "                                if interrupt_flag.is_set(): debug_print(\"Generic response interrupted.\", 1); stop_speech(); interrupt_flag.clear(); current_state = STATE_HANDLING_INTERRUPTION; continue\n",
    "                                else: debug_print(\"Generic response finished.\", 1); current_state = STATE_IDLE\n",
    "\n",
    "                        # End of handling interruption input\n",
    "\n",
    "                    else: # listen_to_student returned None after interruption prompt (\"Yes?\")\n",
    "                        debug_print(\"Listen failed after interruption prompt ('Yes?'). Asking for clarification or attempting resume if context saved.\", 2)\n",
    "                        # If listening fails after 'Yes?', ask again or attempt resume if context exists\n",
    "                        if interrupted_context.get(\"saved\"):\n",
    "                            # Assume they might have meant to resume if they interrupted\n",
    "                            debug_print(\"Context saved. Assuming attempt to resume. Transitioning to CHECK_RESUME.\", 2)\n",
    "                            # No speak needed here, transition directly\n",
    "                            current_state = STATE_CHECK_RESUME # Go check resume state\n",
    "                        else:\n",
    "                            # No context, listen failed, just go back to IDLE to prompt again\n",
    "                            debug_print(\"No context saved. Listen failed. Transitioning to IDLE.\", 2)\n",
    "                            speak(\"I didn't catch your command.\", speech_type=\"answer\")\n",
    "                            if interrupt_flag.is_set(): debug_print(\"Didn't catch message interrupted.\", 1); stop_speech(); interrupt_flag.clear(); current_state = STATE_HANDLING_INTERRUPTION; continue\n",
    "                            else: debug_print(\"Didn't catch message finished.\", 1); current_state = STATE_IDLE\n",
    "\n",
    "\n",
    "        # --- STATE: CHECK_RESUME ---\n",
    "        elif current_state == STATE_CHECK_RESUME:\n",
    "            debug_print(\"State: CHECK_RESUME.\", 2)\n",
    "            # This state is entered after successfully handling an interruption command\n",
    "            # and the system needs to decide if it should resume the previous explanation.\n",
    "\n",
    "            if interrupted_context.get(\"saved\"):\n",
    "                debug_print(f\"Saved context found. Resuming explanation from index: {interrupted_context.get('resume_index')}\", 1)\n",
    "                # Add a transition phrase before resuming\n",
    "                transition_text = generate_transition_phrase(interrupted_context.get(\"topic\"))\n",
    "                speak(transition_text, speech_type=\"transition\")\n",
    "\n",
    "                # After transition speak returns, check interrupt flag\n",
    "                if interrupt_flag.is_set():\n",
    "                    debug_print(\"Resume transition interrupted.\", 1)\n",
    "                    stop_speech()\n",
    "                    interrupt_flag.clear()\n",
    "                    current_state = STATE_HANDLING_INTERRUPTION\n",
    "                    continue # Go to next loop iteration to handle interruption\n",
    "                else:\n",
    "                    debug_print(\"Resume transition finished normally. Proceeding with resume.\", 1)\n",
    "                    # State remains CHECK_RESUME until resume speak starts\n",
    "\n",
    "                # Speak the saved sentences, starting from the resume index\n",
    "                # The speak function will handle state transition to SPEAKING_EXPLANATION internally\n",
    "                # It will also update the resume_index within interrupted_context if interrupted mid-speak\n",
    "                speak(interrupted_context[\"sentences\"], speech_type=\"explanation\", topic=interrupted_context.get(\"topic\"), start_sentence_index=interrupted_context.get(\"resume_index\", 0))\n",
    "\n",
    "                # After speak returns, check interrupt flag\n",
    "                if interrupt_flag.is_set():\n",
    "                    debug_print(\"Resumed explanation was interrupted.\", 1)\n",
    "                    # Context is already saved inside speak(). State is now SPEAKING_EXPLANATION (correct).\n",
    "                    # Main loop will transition to HANDLING_INTERRUPTION because flag is set.\n",
    "                    stop_speech()\n",
    "                    interrupt_flag.clear() # Clear flag\n",
    "                    debug_print(\"Staying in HANDLING_INTERRUPTION after interrupted resume.\", 2)\n",
    "                    pass\n",
    "                else:\n",
    "                    debug_print(\"Resumed explanation finished normally.\", 1)\n",
    "                    debug_print(\"Explanation resume completed.\", 1)\n",
    "                    # Clear context after successful resume completion\n",
    "                    interrupted_context.clear()\n",
    "                    interrupted_context[\"saved\"] = False # Explicitly mark as not saved\n",
    "                    # Transition to IDLE\n",
    "                    current_state = STATE_IDLE\n",
    "                    debug_print(\"Transitioning to IDLE after successful resume.\", 2)\n",
    "\n",
    "            else:\n",
    "                # This state should theoretically only be reached if saved context is expected but missing (logic error)\n",
    "                debug_print(\"Error: Entered CHECK_RESUME state but no saved context found.\", 1)\n",
    "                # Respond that there's nothing to resume and go to IDLE\n",
    "                speak(\"It seems there was no explanation saved to resume.\", speech_type=\"answer\")\n",
    "                if interrupt_flag.is_set(): debug_print(\"No resume message interrupted.\", 1); stop_speech(); interrupt_flag.clear(); current_state = STATE_HANDLING_INTERRUPTION; continue\n",
    "                else: debug_print(\"No resume message finished normally.\", 1); current_state = STATE_IDLE\n",
    "\n",
    "\n",
    "        # --- STATES: SPEAKING ---\n",
    "        # These states mean the speak() function is currently active.\n",
    "        # The main loop should just breathe and let speak() handle its internal loop\n",
    "        # (audio playback, lip-sync, event handling, interruption checking while speaking).\n",
    "        # Transitions from these states happen *inside* or *immediately after* the speak() call returns\n",
    "        # (to IDLE if finishes normally, to HANDLING_INTERRUPTION if interrupted).\n",
    "        elif current_state in [STATE_SPEAKING_EXPLANATION, STATE_SPEAKING_ANSWER, STATE_SPEAKING_GREETING, STATE_SPEAKING_TRANSITION]:\n",
    "            # debug_print(f\"State: {current_state}. Speak function is active.\", 4) # Very verbose\n",
    "            # Add a small sleep to prevent the loop from consuming too much CPU\n",
    "            time.sleep(0.01) # Main loop sleep\n",
    "\n",
    "        else:\n",
    "            # Should not happen, handle unexpected states\n",
    "            print(f\"❗ Unexpected state: {current_state}. Resetting to IDLE.\")\n",
    "            current_state = STATE_IDLE\n",
    "            time.sleep(1) # Prevent rapid looping on error\n",
    "\n",
    "\n",
    "    # --- End of Main Loop (when running is False) ---\n",
    "    debug_print(\"Exiting main application loop.\", 1)\n",
    "    # Final cleanup handled in the finally block outside this function\n",
    "\n",
    "\n",
    "\n",
    "# --- Start the AI Teacher ---\n",
    "if __name__ == \"__main__\":\n",
    "    # --- Global Pygame Display Variables ---\n",
    "    # Initialize these here so they are accessible to functions like update_display\n",
    "    screen = None\n",
    "    font = None\n",
    "    WHITE = (255, 255, 255)\n",
    "    BLACK = (0, 0, 0)\n",
    "    # current_mouth_image and current_mouth_rect are global and set during loading/speaking\n",
    "\n",
    "    print(\"Initializing AI Teacher...\")\n",
    "\n",
    "    # --- NLTK Download Check ---\n",
    "    # Ensure punkt tokenizer is downloaded before splitting sentences\n",
    "    try:\n",
    "        nltk.data.find('tokenizers/punkt')\n",
    "        debug_print(\"NLTK 'punkt' tokenizer found.\", 2)\n",
    "    except nltk.downloader.DownloadError:\n",
    "        debug_print(\"NLTK 'punkt' tokenizer not found. Downloading...\", 2)\n",
    "        try:\n",
    "            nltk.download('punkt')\n",
    "            debug_print(\"NLTK 'punkt' tokenizer downloaded successfully.\", 2)\n",
    "        except Exception as e:\n",
    "            print(f\"❌ Error downloading NLTK 'punkt' tokenizer: {e}. Sentence splitting may not work correctly.\")\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Unexpected error during NLTK check: {e}. Sentence splitting may not work correctly.\")\n",
    "\n",
    "\n",
    "    # --- Pygame Initialization ---\n",
    "    try:\n",
    "        pygame.init() # Initialize all pygame modules (mixer, display, font, etc.)\n",
    "        screen = pygame.display.set_mode((SCREEN_WIDTH, SCREEN_HEIGHT))\n",
    "        pygame.display.set_caption(\"AI Teacher Voice Agent\")\n",
    "        font = pygame.font.Font(None, 28) # Initialize default font\n",
    "        pygame.mixer.init() # Explicitly initialize mixer again for clarity\n",
    "        debug_print(\"Pygame initialized successfully (Display, Mixer, Font).\", 2)\n",
    "    except pygame.error as e:\n",
    "        print(f\"❌ Critical Error: Failed to initialize pygame: {e}. Cannot run visual or audio components.\")\n",
    "        # Exit if pygame fails to initialize\n",
    "        exit()\n",
    "\n",
    "\n",
    "    # --- Load Mouth Images ---\n",
    "    # This sets the global mouth_images dictionary and the initial current_mouth_image\n",
    "    initial_mouth_image = load_mouth_images()\n",
    "    if initial_mouth_image:\n",
    "        current_mouth_image = initial_mouth_image\n",
    "        current_mouth_rect = current_mouth_image.get_rect(center=MOUTH_POS)\n",
    "        debug_print(\"Mouth images loaded and initial pose set.\", 2)\n",
    "    else:\n",
    "        print(\"❌ Critical Error: Could not load any mouth images. Cannot run visual component.\")\n",
    "        # Decide if you want to exit or run voice-only. Let's exit for now.\n",
    "        # exit() # Exiting might be too harsh, the app might still work voice-only.\n",
    "        # Let's just ensure current_mouth_image/rect are None if loading failed critically.\n",
    "        current_mouth_image = None\n",
    "        current_mouth_rect = None\n",
    "\n",
    "\n",
    "    # --- Initial cleanup of temp files on startup ---\n",
    "    cleanup_temp_files()\n",
    "    debug_print(\"Initial temp file cleanup completed.\", 2)\n",
    "\n",
    "    # --- Start keyboard listener in a separate thread ---\n",
    "    # Only start the thread ONCE in the main execution block\n",
    "    keyboard_thread = threading.Thread(target=keyboard_listener, daemon=True)\n",
    "    keyboard_thread.start()\n",
    "    debug_print(\"Keyboard listener thread started.\", 2)\n",
    "\n",
    "\n",
    "    # --- Start the main AI Teacher interaction loop ---\n",
    "    try:\n",
    "        # Call the main function that contains the state loop\n",
    "        run_voice_teacher()\n",
    "    except KeyboardInterrupt:\n",
    "        # Handle Ctrl+C from the console\n",
    "        print(\"\\nExiting AI Teacher (Ctrl+C detected)...\")\n",
    "    except Exception as e:\n",
    "        # Catch any unhandled exception in the main loop\n",
    "        print(f\"\\n❌ An unexpected error occurred in the main loop: {e}\")\n",
    "\n",
    "    finally:\n",
    "        # --- Final Cleanup ---\n",
    "        debug_print(\"Starting final cleanup...\", 1)\n",
    "        stop_speech() # Ensure audio is stopped just in case\n",
    "        # Clean up all temp files one last time\n",
    "        cleanup_temp_files(extensions=('.mp3', '.wav', '.json', '.tsv', '.txt')) # Add txt for dialog file cleanup\n",
    "        debug_print(\"Final temp file cleanup completed.\", 2)\n",
    "\n",
    "        # Quit Pygame subsystems\n",
    "        if pygame.get_init(): # Check if pygame was initialized before quitting\n",
    "            pygame.quit()\n",
    "            print(\"Pygame quit.\")\n",
    "        else:\n",
    "            debug_print(\"Pygame was not initialized, skipping pygame.quit().\", 2)\n",
    "\n",
    "        print(\"AI Teacher session ended.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84d8b144-5d9f-47bc-9ece-871b0456e310",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10 (Jupyter)",
   "language": "python",
   "name": "python310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
